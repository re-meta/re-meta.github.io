<!DOCTYPE html><html lang="en" class="" style="scroll-padding:60px"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width,initial-scale=1"/><title>Group estimation and priors - Guide</title><meta property="og:title" content="Group estimation and priors - Guide"/><meta name="generator" content="mystmd"/><meta name="keywords" content=""/><link rel="stylesheet" href="/build/_assets/app-2K3KGISG.css"/><link rel="stylesheet" href="/build/_assets/thebe-core-VKVHG5VY.css"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/jupyter-matplotlib@0.11.3/css/mpl_widget.css"/><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.css"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.css" integrity="sha384-MlJdn/WNKDGXveldHDdyRP1R4CTHr3FeuDNfhsLPYrq2t0UBkUdK2jyTnXPEK1NQ" crossorigin="anonymous"/><link rel="icon" href="/favicon.ico"/><link rel="stylesheet" href="/myst-theme.css"/><script>
  const savedTheme = localStorage.getItem("myst:theme");
  const theme = window.matchMedia("(prefers-color-scheme: light)").matches ? 'light' : 'dark';
  const classes = document.documentElement.classList;
  const hasAnyTheme = classes.contains('light') || classes.contains('dark');
  if (!hasAnyTheme) classes.add(savedTheme ?? theme);
</script></head><body class="m-0 transition-colors duration-500 bg-white dark:bg-stone-900"><div class="myst-skip-to-article fixed top-1 left-1 h-[0px] w-[0px] focus-within:z-40 focus-within:h-auto focus-within:w-auto bg-white overflow-hidden focus-within:p-2 focus-within:ring-1" aria-label="skip to content options"><a href="#skip-to-frontmatter" class="myst-skip-to-link block px-2 py-1 text-black underline">Skip to article frontmatter</a><a href="#skip-to-article" class="myst-skip-to-link block px-2 py-1 text-black underline">Skip to article content</a></div><dialog id="myst-no-css" style="position:fixed;left:0px;top:0px;width:100%;height:100vh;font-size:4rem;padding:1rem;color:black;background:white"><strong>Site not loading correctly?</strong><p>This may be due to an incorrect <code>BASE_URL</code> configuration. See<!-- --> <a href="https://mystmd.org/guide/deployment#deploy-base-url">the MyST Documentation</a> <!-- -->for reference.</p><script>
    (() => {
            // Test for has-styling variable set by the MyST stylesheet
            const node = document.currentScript.parentNode;
            const hasCSS = window.getComputedStyle(node).getPropertyValue("--has-styling");
            if (hasCSS === ""){
                    node.showModal();
            }

    })()
</script></dialog><div class="myst-top-nav bg-white/80 backdrop-blur dark:bg-stone-900/80 shadow dark:shadow-stone-700 p-3 md:px-8 sticky w-full top-0 z-30 h-[60px]"><nav class="myst-top-nav-bar flex items-center justify-between flex-nowrap max-w-[1440px] mx-auto"><div class="flex flex-row xl:min-w-[19.5rem] mr-2 sm:mr-7 justify-start items-center shrink-0"><div class="block xl:hidden"><button class="myst-top-nav-menu-button flex items-center justify-center border-stone-400 text-stone-800 hover:text-stone-900 dark:text-stone-200 hover:dark:text-stone-100 w-10 h-10"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" width="1.5rem" height="1.5rem"><path fill-rule="evenodd" d="M3 6.75A.75.75 0 0 1 3.75 6h16.5a.75.75 0 0 1 0 1.5H3.75A.75.75 0 0 1 3 6.75ZM3 12a.75.75 0 0 1 .75-.75h16.5a.75.75 0 0 1 0 1.5H3.75A.75.75 0 0 1 3 12Zm0 5.25a.75.75 0 0 1 .75-.75h16.5a.75.75 0 0 1 0 1.5H3.75a.75.75 0 0 1-.75-.75Z" clip-rule="evenodd"></path></svg><span class="sr-only">Open Menu</span></button></div><a class="myst-home-link flex items-center ml-3 dark:text-white w-fit md:ml-5 xl:ml-7" href="/"><div class="myst-home-link-logo mr-3 flex items-center dark:bg-white dark:rounded px-1"><img src="/build/logo-dcba10266a9311fcddffdac07a48fd18.png" class="h-9" height="2.25rem"/></div><span class="text-md sm:text-xl tracking-tight sm:mr-5 sr-only">Made with MyST</span></a></div><div class="flex items-center flex-grow w-auto"><div class="flex-grow hidden text-md lg:block"></div><div class="flex-grow block"></div><button type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-:R75cp:" data-state="closed" class="myst-search-bar flex items-center h-10 aspect-square sm:w-64 text-left text-gray-600 dark:text-gray-300 border border-gray-300 dark:border-gray-600 rounded-lg bg-gray-50 dark:bg-gray-700 myst-search-bar-disabled hover:ring-blue-500 dark:hover:ring-blue-500 hover:border-blue-500 dark:hover:border-blue-500"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="p-2.5 h-10 w-10 aspect-square"><path fill-rule="evenodd" d="M10.5 3.75a6.75 6.75 0 1 0 0 13.5 6.75 6.75 0 0 0 0-13.5ZM2.25 10.5a8.25 8.25 0 1 1 14.59 5.28l4.69 4.69a.75.75 0 1 1-1.06 1.06l-4.69-4.69A8.25 8.25 0 0 1 2.25 10.5Z" clip-rule="evenodd"></path></svg><span class="myst-search-text-placeholder hidden sm:block grow">Search</span><div aria-hidden="true" class="myst-search-shortcut items-center hidden mx-1 font-mono text-sm text-gray-600 dark:text-gray-300 sm:flex gap-x-1"><kbd class="px-2 py-1 border border-gray-300 dark:border-gray-600 rounded-md shadow-[0px_2px_0px_0px_rgba(0,0,0,0.08)] dark:shadow-none hide-mac">CTRL</kbd><kbd class="px-2 py-1 border border-gray-300 dark:border-gray-600 rounded-md shadow-[0px_2px_0px_0px_rgba(0,0,0,0.08)] dark:shadow-none show-mac">⌘</kbd><kbd class="px-2 py-1 border border-gray-300 dark:border-gray-600 rounded-md shadow-[0px_2px_0px_0px_rgba(0,0,0,0.08)] dark:shadow-none ">K</kbd><script>
;(() => {
const script = document.currentScript;
const root = script.parentElement;

const isMac = /mac/i.test(
      window.navigator.userAgentData?.platform ?? window.navigator.userAgent,
    );
root.querySelectorAll(".hide-mac").forEach(node => {node.classList.add(isMac ? "hidden" : "block")});
root.querySelectorAll(".show-mac").forEach(node => {node.classList.add(!isMac ? "hidden" : "block")});
})()</script></div></button><button class="myst-theme-button theme rounded-full aspect-square border border-stone-700 dark:border-white hover:bg-neutral-100 border-solid overflow-hidden text-stone-700 dark:text-white hover:text-stone-500 dark:hover:text-neutral-800 w-10 h-10 mx-3" title="Toggle theme between light and dark mode" aria-label="Toggle theme between light and dark mode"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="myst-theme-moon-icon h-full w-full p-0.5 hidden dark:block"><path fill-rule="evenodd" d="M9.528 1.718a.75.75 0 0 1 .162.819A8.97 8.97 0 0 0 9 6a9 9 0 0 0 9 9 8.97 8.97 0 0 0 3.463-.69.75.75 0 0 1 .981.98 10.503 10.503 0 0 1-9.694 6.46c-5.799 0-10.5-4.7-10.5-10.5 0-4.368 2.667-8.112 6.46-9.694a.75.75 0 0 1 .818.162Z" clip-rule="evenodd"></path></svg><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="myst-theme-sun-icon h-full w-full p-0.5 dark:hidden"><path stroke-linecap="round" stroke-linejoin="round" d="M12 3v2.25m6.364.386-1.591 1.591M21 12h-2.25m-.386 6.364-1.591-1.591M12 18.75V21m-4.773-4.227-1.591 1.591M5.25 12H3m4.227-4.773L5.636 5.636M15.75 12a3.75 3.75 0 1 1-7.5 0 3.75 3.75 0 0 1 7.5 0Z"></path></svg></button><div class="block sm:hidden"><div class="myst-action-menu relative" data-headlessui-state=""><div><button class="myst-action-menu-button flex text-sm bg-transparent rounded-full focus:outline-none" id="headlessui-menu-button-:Rr5cp:" type="button" aria-haspopup="menu" aria-expanded="false" data-headlessui-state=""><span class="sr-only">Open Menu</span><div class="flex items-center text-stone-200 hover:text-white"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" width="2rem" height="2rem" class="p-1"><path fill-rule="evenodd" d="M10.5 6a1.5 1.5 0 1 1 3 0 1.5 1.5 0 0 1-3 0Zm0 6a1.5 1.5 0 1 1 3 0 1.5 1.5 0 0 1-3 0Zm0 6a1.5 1.5 0 1 1 3 0 1.5 1.5 0 0 1-3 0Z" clip-rule="evenodd"></path></svg></div></button></div></div></div><div class="hidden sm:block"><a href="https://github.com/coconeuro/remeta" target="_blank" rel="noopener noreferrer" class="inline-block px-4 py-2 mx-1 mt-0 leading-none border rounded text-md border-stone-700 dark:border-white text-stone-700 dark:text-white hover:text-stone-500 dark:hover:text-neutral-800 hover:bg-neutral-100">GitHub</a></div></div></nav></div><div class="myst-primary-sidebar fixed xl:article-grid grid-gap xl:w-full xl:pointer-events-none overflow-auto max-xl:w-[75vw] max-xl:max-w-[350px] max-xl:!top-0 max-xl:h-screen hidden z-10" style="top:60px"><div class="myst-primary-sidebar-pointer pointer-events-auto xl:col-margin-left flex-col overflow-hidden max-xl:h-full hidden xl:flex"><div class="myst-primary-sidebar-nav flex-grow py-6 overflow-y-auto primary-scrollbar"><nav aria-label="Navigation" class="myst-primary-sidebar-topnav overflow-y-hidden transition-opacity lg:hidden ml-3 xl:ml-0 mr-3 max-w-[350px]"><div class="w-full px-1 dark:text-white font-medium"></div></nav><div class="my-3 border-b-2 lg:hidden"></div><nav aria-label="Table of Contents" class="myst-primary-sidebar-toc flex-grow overflow-y-hidden transition-opacity ml-3 xl:ml-0 mr-3 max-w-[350px]"><div class="myst-toc w-full px-1 dark:text-white"><a title="Guide" class="block break-words focus:outline outline-blue-200 outline-2 rounded myst-toc-item p-2 my-1 rounded-lg hover:bg-slate-300/30 font-bold" href="/">Guide</a><a title="Installation" class="block break-words focus:outline outline-blue-200 outline-2 rounded myst-toc-item p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/install">Installation</a><a title="General idea and terminology" class="block break-words focus:outline outline-blue-200 outline-2 rounded myst-toc-item p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/intro">General idea and terminology</a><a title="Getting started" class="block break-words focus:outline outline-blue-200 outline-2 rounded myst-toc-item p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/start">Getting started</a><a title="Type 1: the decision making stage" class="block break-words focus:outline outline-blue-200 outline-2 rounded myst-toc-item p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/type1">Type 1: the decision making stage</a><a title="Type 2: the metacognitive stage" class="block break-words focus:outline outline-blue-200 outline-2 rounded myst-toc-item p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/type2">Type 2: the metacognitive stage</a><a title="Group estimation and priors" aria-current="page" class="block break-words focus:outline outline-blue-200 outline-2 rounded myst-toc-item p-2 my-1 rounded-lg myst-toc-item-exact bg-blue-300/30 active" href="/group-estimation-priors">Group estimation and priors</a><a title="Parameter estimates and model evidence" class="block break-words focus:outline outline-blue-200 outline-2 rounded myst-toc-item p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/results">Parameter estimates and model evidence</a><a title="Configuration" class="block break-words focus:outline outline-blue-200 outline-2 rounded myst-toc-item p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/configuration">Configuration</a><a title="Plotting" class="block break-words focus:outline outline-blue-200 outline-2 rounded myst-toc-item p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/plotting">Plotting</a><a title="API" class="myst-toc-heading block break-words focus:outline outline-blue-200 outline-2 rounded myst-toc-item p-2 my-1 rounded-lg hover:bg-slate-300/30" href="https://re-meta.github.io/api/" target="_blank"><span class="inline align-middle">API</span><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="inline h-4 w-4 align-middle ml-[0.2rem]"><path fill-rule="evenodd" d="M15.75 2.25H21a.75.75 0 0 1 .75.75v5.25a.75.75 0 0 1-1.5 0V4.81L8.03 17.03a.75.75 0 0 1-1.06-1.06L19.19 3.75h-3.44a.75.75 0 0 1 0-1.5Zm-10.5 4.5a1.5 1.5 0 0 0-1.5 1.5v10.5a1.5 1.5 0 0 0 1.5 1.5h10.5a1.5 1.5 0 0 0 1.5-1.5V10.5a.75.75 0 0 1 1.5 0v8.25a3 3 0 0 1-3 3H5.25a3 3 0 0 1-3-3V8.25a3 3 0 0 1 3-3h8.25a.75.75 0 0 1 0 1.5H5.25Z" clip-rule="evenodd"></path></svg></a></div></nav></div><div class="myst-primary-sidebar-footer flex-none py-6 transition-all duration-700 translate-y-6 opacity-0 ml-3 xl:ml-0 mr-3 max-w-[350px]"><div class="article footer myst-primary-sidebar-footer"></div></div></div></div><main class="article-grid grid-gap"><article class="article-grid subgrid-gap col-screen article content"><div class="hidden"></div><div id="skip-to-frontmatter" aria-label="article frontmatter" class="myst-fm-block mb-8 pt-9"><div class="myst-fm-block-header flex items-center mb-5 h-6 text-sm font-light"><div class="flex-grow"></div><div class="myst-fm-block-badges"></div><div class="myst-fm-downloads-dropdown relative flex inline-block mx-1 grow-0" data-headlessui-state=""><button class="myst-fm-downloads-button relative ml-2 -mr-1" id="headlessui-menu-button-:Rs8ucp:" type="button" aria-haspopup="menu" aria-expanded="false" data-headlessui-state=""><span class="sr-only">Downloads</span><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.25rem" height="1.25rem" class="myst-fm-downloads-icon"><title>Download</title><path stroke-linecap="round" stroke-linejoin="round" d="M3 16.5v2.25A2.25 2.25 0 0 0 5.25 21h13.5A2.25 2.25 0 0 0 21 18.75V16.5M16.5 12 12 16.5m0 0L7.5 12m4.5 4.5V3"></path></svg></button></div></div><h1 class="myst-fm-block-title mb-0">Group estimation and priors</h1></div><div class="block my-10 lg:sticky lg:z-10 lg:h-0 lg:pt-0 lg:my-0 lg:ml-10 lg:col-margin-right" style="top:60px"><nav></nav></div><div id="skip-to-article"></div><div id="H35Xqw2tX1" class="myst-jp-nb-block relative group/block hidden"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">import remeta
import numpy as np
%load_ext autoreload
%autoreload 2</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="MWcvwphA-pG3E0fy3aloc" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-stream"><div><pre class="myst-jp-stream-output text-sm font-thin font-system"><code><span>The autoreload extension is already loaded. To reload it, use:
  %reload_ext autoreload
</span></code></pre></div></div></div></div><div id="THB3k0kjsE" class="myst-jp-nb-block relative group/block"><p>Often, data from single participants are not sufficient for precise parameter estimation. In this section, we introduce to methods to address this: <strong>group estimation</strong> (random effects or group-level fixed effects) and <strong>priors</strong>.</p></div><div id="Y7BPyPkfLH" class="myst-jp-nb-block relative group/block"><h2 id="group-estimation" class="relative group"><span class="heading-text">Group estimation</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#group-estimation" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><p>To use group-level information we need to pass 2d data to ReMeta (<code>n_subjects</code> x <code>n_samples</code>) and specify the <code>group</code> attribute for parameters.</p><p>The <code>fit</code> method of ReMeta accepts data as either 1d arrays (single participant) or as 2d arrays (group data). To this aim, we simulate type 1 data for 4 participants:</p></div><div id="AxbV2XaJB9" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">np.random.seed(42)
cfg = remeta.Configuration()
cfg.skip_type2 = True
params_true = dict(
    type1_noise=0.5,
    type1_bias=0.1,
)
cfg.true_params = params_true
data = remeta.simulate(nsubjects=5, nsamples=200, params=params_true, cfg=cfg)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="_kEbOoYY3EkN33OELISMI" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-stream"><div><pre class="myst-jp-stream-output text-sm font-thin font-system"><code><span>----------------------------------
..Generative parameters:
    Type 1 noise distribution: normal
    type1_noise: 0.5
    type1_bias: 0.1
..Descriptive statistics:
    No. subjects: 5
    No. samples: 200
    Accuracy: 82.1% correct
    d&#x27;: 1.9
    Choice bias: 5.1%
----------------------------------
</span></code></pre></div></div></div></div><div id="MJeCDvoksU" class="myst-jp-nb-block relative group/block"><p>Note that</p></div><div id="O9Evdpjynv" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">data.stimuli.shape</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="FJWTU7YnCrEA-yWEk7stX" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-text" class="font-mono text-sm whitespace-pre-wrap myst-jp-safe-output-text"><code><span>(5, 200)</span></code></div></div></div><div id="Gv43JFOxgb" class="myst-jp-nb-block relative group/block"><p>We fit a default ReMeta model:</p></div><div id="a1S8Snna2X" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">rem = remeta.ReMeta(cfg=cfg)
rem.fit(data.stimuli, data.choices, data.confidence)
result = rem.summary()</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="TpkDXfha6GZ8zwGixX6MC" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5 hidden"><div data-name="safe-output-stream"><div><pre class="myst-jp-stream-output text-sm font-thin font-system"><code><span>Dataset characteristics:
    No. subjects: 5
    No. samples: [200, 200, 200, 200, 200]
    Accuracy: 82.1% correct
    d&#x27;: 1.908
    Choice bias: 5.1%

+++ Type 1 level +++
  Subject-level estimation (MLE)
     Subject 1 / 5
     Subject 2 / 5
     Subject 3 / 5
     Subject 4 / 5
     Subject 5 / 5
    .. finished (0.6 secs).
  Final report
    Subject 1 / 5
        Parameters estimates (subject-level fit)
            [subject] type1_noise: 0.604 ± 0.073 (true: 0.500)
            [subject] type1_bias: 0.169 ± 0.065 (true: 0.100)
        [subject] Log-likelihood: -90.64 (per sample: -0.4532)
        [subject] Fitting time: 0.23 secs
        Log-likelihood using true params: -92.56 (per sample: -0.4628)
    Subject 2 / 5
        Parameters estimates (subject-level fit)
            [subject] type1_noise: 0.403 ± 0.030 (true: 0.500)
            [subject] type1_bias: 0.077 ± 0.048 (true: 0.100)
        [subject] Log-likelihood: -64.10 (per sample: -0.3205)
        [subject] Fitting time: 0.09 secs
        Log-likelihood using true params: -65.84 (per sample: -0.3292)
    Subject 3 / 5
        Parameters estimates (subject-level fit)
            [subject] type1_noise: 0.510 ± 0.049 (true: 0.500)
            [subject] type1_bias: 0.161 ± 0.057 (true: 0.100)
        [subject] Log-likelihood: -79.39 (per sample: -0.3969)
        [subject] Fitting time: 0.07 secs
        Log-likelihood using true params: -79.97 (per sample: -0.3998)
    Subject 4 / 5
        Parameters estimates (subject-level fit)
            [subject] type1_noise: 0.636 ± 0.083 (true: 0.500)
            [subject] type1_bias: 0.070 ± 0.067 (true: 0.100)
        [subject] Log-likelihood: -94.99 (per sample: -0.4749)
        [subject] Fitting time: 0.07 secs
        Log-likelihood using true params: -97.54 (per sample: -0.4877)
    Subject 5 / 5
        Parameters estimates (subject-level fit)
            [subject] type1_noise: 0.508 ± 0.048 (true: 0.500)
            [subject] type1_bias: 0.081 ± 0.056 (true: 0.100)
        [subject] Log-likelihood: -80.71 (per sample: -0.4036)
        [subject] Fitting time: 0.07 secs
        Log-likelihood using true params: -80.78 (per sample: -0.4039)
Type 1 level finished
</span></code></pre></div></div></div></div><div id="v6UDsYrn9k" class="myst-jp-nb-block relative group/block"><p>In case of a group-level fit, the result returned by the <code>summary()</code> method is a list of length <code>nsubjects</code>. We can print the final parameter estimates more cleanly as follows:</p></div><div id="Vrw3ppFtwl" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">for s in range(result.nsubjects):
    print(f&#x27;Subject {s}&#x27;)
    for k, v in result.type1.params[s].items():
        print(f&#x27;\t{k}: {v:.3f} ± {result.type1.params_se[s][k]:.3f}&#x27;)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="WcUEvLhtlHXzH93vreM8K" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-stream"><div><pre class="myst-jp-stream-output text-sm font-thin font-system"><code><span>Subject 0
	type1_noise: 0.604 ± 0.073
	type1_bias: 0.169 ± 0.065
Subject 1
	type1_noise: 0.403 ± 0.030
	type1_bias: 0.077 ± 0.048
Subject 2
	type1_noise: 0.510 ± 0.049
	type1_bias: 0.161 ± 0.057
Subject 3
	type1_noise: 0.636 ± 0.083
	type1_bias: 0.070 ± 0.067
Subject 4
	type1_noise: 0.508 ± 0.048
	type1_bias: 0.081 ± 0.056
</span></code></pre></div></div></div></div><div id="JZmD5zCbY3" class="myst-jp-nb-block relative group/block"><p>In this section, we exemplarily focus on the <code>type1_bias</code> parameter which was set to <code>0.1</code> in the simulated data. The fitted parameters for <code>type1_bias</code> vary strongly around <code>0.1</code>. In line with this variability, the standard errors of the parameter estimates are big.</p><p>Yet, this is no fitting error, since the empirical log-likelihood is always hight than one for the true parameters. We can verify this as follows:</p></div><div id="ACdBr7kV6f" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">for s in range(result.nsubjects):
    print(f&#x27;Subject {s}&#x27;)
    print(f&#x27;\tLog likelihood of true parameters: {result.type1.loglik_true[s]:.2f}&#x27;)
    print(f&#x27;\tLog likelihood of estimated parameters: {result.type1.loglik[s]:.2f}&#x27;)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="2gbQFLKyDvHhws7HXHP5m" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-stream"><div><pre class="myst-jp-stream-output text-sm font-thin font-system"><code><span>Subject 0
	Log likelihood of true parameters: -92.56
	Log likelihood of estimated parameters: -90.64
Subject 1
	Log likelihood of true parameters: -65.84
	Log likelihood of estimated parameters: -64.10
Subject 2
	Log likelihood of true parameters: -79.97
	Log likelihood of estimated parameters: -79.39
Subject 3
	Log likelihood of true parameters: -97.54
	Log likelihood of estimated parameters: -94.99
Subject 4
	Log likelihood of true parameters: -80.78
	Log likelihood of estimated parameters: -80.71
</span></code></pre></div></div></div></div><div id="Oc60vDJI88" class="myst-jp-nb-block relative group/block"><p>The issue is rather that few samples are often not representative of the ground truth. By contrast, the more samples, the less likely that the data — in aggregate — behave substantially different than the ground truth.</p></div><div id="GhRWWdPfVy" class="myst-jp-nb-block relative group/block"><h3 id="random-effects" class="relative group"><span class="heading-text">Random effects</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#random-effects" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><p>An elegant way to regularize unreliable parameter estimates at the individual level are hierarchical random effect models. For random effects parameters, the likelihood computation comprises not only the likelihood given the individual data of a participant, but also the likelihood under a population distribution.</p><p>What is elegant about random effects models is that this population distribution is itself learned from the data, with the only “prio”&quot; that the distribution is Gaussian (at least in the frequentist domain).</p><p>In this way, extreme estimates for individual subjects are “tamed” (regularized), since they tend to be unlikely under the population distribution. Nevertheless, random effects models leave enough room for interindividual variability between participants.</p><p>In our example above, we specify the type 1 bias parameter as a random effects group parameter:</p></div><div id="A9U3fwBIos" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">cfg.param_type1_bias.group = &#x27;random&#x27;</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="gyYuU5Zaq3L6uw9F9N5uo" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="cARiMYTo0g" class="myst-jp-nb-block relative group/block"><p>We restart the fitting procedure with this new setting:</p></div><div id="X8NRQrAFWT" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">rem = remeta.ReMeta(cfg=cfg)
rem.fit(data.stimuli, data.choices, data.confidence)
result = rem.summary()</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="WeqBBa57RlYP4Op9WOUCM" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5 hidden"><div data-name="safe-output-stream"><div><pre class="myst-jp-stream-output text-sm font-thin font-system"><code><span>Dataset characteristics:
    No. subjects: 5
    No. samples: [200, 200, 200, 200, 200]
    Accuracy: 82.1% correct
    d&#x27;: 1.908
    Choice bias: 5.1%

+++ Type 1 level +++
  Subject-level estimation (MLE)
     Subject 1 / 5
     Subject 2 / 5
     Subject 3 / 5
     Subject 4 / 5
     Subject 5 / 5
    .. finished (0.4 secs).

  Group-level optimization (MLE / MAP)
        [20:31:46] Iteration 1 / 30 (Convergence: 0.00059327)
        [20:31:47] Iteration 11 / 30 (Convergence: 0.00011138)
        [20:31:47] Iteration 21 / 30 (Convergence: 0.00004453)
    .. finished (0.4 secs).
  Final report
    Subject 1 / 5
        Parameters estimates (subject-level fit)
            [subject] type1_noise: 0.604 ± 0.073 (true: 0.500)
            [subject] type1_bias: 0.169 ± 0.065 (true: 0.100)
        [subject] Log-likelihood: -90.64 (per sample: -0.4532)
        [subject] Fitting time: 0.08 secs
        Parameters estimates (group-level fit)
            [subject] type1_noise: 0.600 ± 0.071 (true: 0.500)
            [group=random] type1_bias: 0.115 ± 0.019 (true: 0.100)
        [final] Log-likelihood: -91.00 (per sample: -0.455)
        Log-likelihood using true params: -92.56 (per sample: -0.4628)
    Subject 2 / 5
        Parameters estimates (subject-level fit)
            [subject] type1_noise: 0.403 ± 0.030 (true: 0.500)
            [subject] type1_bias: 0.077 ± 0.048 (true: 0.100)
        [subject] Log-likelihood: -64.10 (per sample: -0.3205)
        [subject] Fitting time: 0.07 secs
        Parameters estimates (group-level fit)
            [subject] type1_noise: 0.406 ± 0.045 (true: 0.500)
            [group=random] type1_bias: 0.106 ± 0.018 (true: 0.100)
        [final] Log-likelihood: -64.26 (per sample: -0.3213)
        Log-likelihood using true params: -65.84 (per sample: -0.3292)
    Subject 3 / 5
        Parameters estimates (subject-level fit)
            [subject] type1_noise: 0.510 ± 0.049 (true: 0.500)
            [subject] type1_bias: 0.161 ± 0.057 (true: 0.100)
        [subject] Log-likelihood: -79.39 (per sample: -0.3969)
        [subject] Fitting time: 0.07 secs
        Parameters estimates (group-level fit)
            [subject] type1_noise: 0.508 ± 0.057 (true: 0.500)
            [group=random] type1_bias: 0.115 ± 0.019 (true: 0.100)
        [final] Log-likelihood: -79.71 (per sample: -0.3985)
        Log-likelihood using true params: -79.97 (per sample: -0.3998)
    Subject 4 / 5
        Parameters estimates (subject-level fit)
            [subject] type1_noise: 0.636 ± 0.083 (true: 0.500)
            [subject] type1_bias: 0.070 ± 0.067 (true: 0.100)
        [subject] Log-likelihood: -94.99 (per sample: -0.4749)
        [subject] Fitting time: 0.06 secs
        Parameters estimates (group-level fit)
            [subject] type1_noise: 0.641 ± 0.078 (true: 0.500)
            [group=random] type1_bias: 0.107 ± 0.019 (true: 0.100)
        [final] Log-likelihood: -95.14 (per sample: -0.4757)
        Log-likelihood using true params: -97.54 (per sample: -0.4877)
    Subject 5 / 5
        Parameters estimates (subject-level fit)
            [subject] type1_noise: 0.508 ± 0.048 (true: 0.500)
            [subject] type1_bias: 0.081 ± 0.056 (true: 0.100)
        [subject] Log-likelihood: -80.71 (per sample: -0.4036)
        [subject] Fitting time: 0.06 secs
        Parameters estimates (group-level fit)
            [subject] type1_noise: 0.509 ± 0.058 (true: 0.500)
            [group=random] type1_bias: 0.107 ± 0.019 (true: 0.100)
        [final] Log-likelihood: -80.81 (per sample: -0.4041)
        Log-likelihood using true params: -80.78 (per sample: -0.4039)
Type 1 level finished
</span></code></pre></div></div></div></div><div id="xMH18YwXoG" class="myst-jp-nb-block relative group/block"><p>In the current example, all participant estimates for <code>type1_bias</code> are pretty similar, reflecting the fact that the data were in fact generated by the same ground truth model:</p></div><div id="Ahcxj6hNbI" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">for s in range(result.nsubjects):
    print(f&#x27;Subject {s}&#x27;)
    for k, v in result.type1.params[s].items():
        print(f&#x27;\t{k}: {v:.6f}&#x27;)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="ikQ6sTX4gXfK0VNC01E0_" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-stream"><div><pre class="myst-jp-stream-output text-sm font-thin font-system"><code><span>Subject 0
	type1_noise: 0.600090
	type1_bias: 0.114900
Subject 1
	type1_noise: 0.405529
	type1_bias: 0.105509
Subject 2
	type1_noise: 0.508127
	type1_bias: 0.115239
Subject 3
	type1_noise: 0.641339
	type1_bias: 0.106636
Subject 4
	type1_noise: 0.509449
	type1_bias: 0.106799
</span></code></pre></div></div></div></div><div id="Jw16ezuvCk" class="myst-jp-nb-block relative group/block"><p>This observation is matched by an inspection of the population estimate for <code>type1_nonlinear_gain</code>:</p></div><div id="iXZuwHUqIc" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">print(f&#x27;Estimated population mean: {result.params_random_effect.mean[&#x27;type1_bias&#x27;]:.3f}&#x27;)
print(f&#x27;Estimated population SD: {result.params_random_effect.std[&#x27;type1_bias&#x27;]:.3f}&#x27;)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="-hBjfVWusglDVNO4w8NZc" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-stream"><div><pre class="myst-jp-stream-output text-sm font-thin font-system"><code><span>Estimated population mean: 0.110
Estimated population SD: 0.019
</span></code></pre></div></div></div></div><div id="d6aphSNmSq" class="myst-jp-nb-block relative group/block"><h3 id="fixed-effects" class="relative group"><span class="heading-text">Fixed effects</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#fixed-effects" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><p>Another option to tackle unreliable individual parameter estimates is to fit a single parameter to the entire group. In ReMeta, this is possible by setting the <code>group</code> attribute of the parameter to <code>&#x27;fixed&#x27;</code>:</p></div><div id="yezCgrJnew" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">cfg.param_type1_bias.group = &#x27;fixed&#x27;</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="jSNsXEpq3QMTZ0e0sM3Wc" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="pohp10WCIv" class="myst-jp-nb-block relative group/block"><p>We fit the model as usual:</p></div><div id="dZ1oXnxEz7" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">rem = remeta.ReMeta(cfg=cfg)
rem.fit(data.stimuli, data.choices, data.confidence)
result = rem.summary()</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="j_KVqD-_Fl8O5OpLc10Bz" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5 hidden"><div data-name="safe-output-stream"><div><pre class="myst-jp-stream-output text-sm font-thin font-system"><code><span>Dataset characteristics:
    No. subjects: 5
    No. samples: [200, 200, 200, 200, 200]
    Accuracy: 82.1% correct
    d&#x27;: 1.908
    Choice bias: 5.1%

+++ Type 1 level +++
  Subject-level estimation (MLE)
     Subject 1 / 5
     Subject 2 / 5
     Subject 3 / 5
     Subject 4 / 5
     Subject 5 / 5
    .. finished (0.4 secs).

  Group-level optimization (MLE / MAP)
        [20:31:47] Iteration 1 / 30
        [20:31:47] Iteration 11 / 30
        [20:31:47] Iteration 21 / 30
    .. finished (0.2 secs).
  Final report
    Subject 1 / 5
        Parameters estimates (subject-level fit)
            [subject] type1_noise: 0.604 ± 0.073 (true: 0.500)
            [subject] type1_bias: 0.169 ± 0.065 (true: 0.100)
        [subject] Log-likelihood: -90.64 (per sample: -0.4532)
        [subject] Fitting time: 0.07 secs
        Parameters estimates (group-level fit)
            [subject] type1_noise: 0.600 ± 0.071 (true: 0.500)
            [group=fixed] type1_bias: 0.109 ± 0.026 (true: 0.100)
        [final] Log-likelihood: -91.07 (per sample: -0.4554)
        Log-likelihood using true params: -92.56 (per sample: -0.4628)
    Subject 2 / 5
        Parameters estimates (subject-level fit)
            [subject] type1_noise: 0.403 ± 0.030 (true: 0.500)
            [subject] type1_bias: 0.077 ± 0.048 (true: 0.100)
        [subject] Log-likelihood: -64.10 (per sample: -0.3205)
        [subject] Fitting time: 0.07 secs
        Parameters estimates (group-level fit)
            [subject] type1_noise: 0.406 ± 0.045 (true: 0.500)
            [group=fixed] type1_bias: 0.109 ± 0.026 (true: 0.100)
        [final] Log-likelihood: -64.31 (per sample: -0.3215)
        Log-likelihood using true params: -65.84 (per sample: -0.3292)
    Subject 3 / 5
        Parameters estimates (subject-level fit)
            [subject] type1_noise: 0.510 ± 0.049 (true: 0.500)
            [subject] type1_bias: 0.161 ± 0.057 (true: 0.100)
        [subject] Log-likelihood: -79.39 (per sample: -0.3969)
        [subject] Fitting time: 0.07 secs
        Parameters estimates (group-level fit)
            [subject] type1_noise: 0.508 ± 0.057 (true: 0.500)
            [group=fixed] type1_bias: 0.109 ± 0.026 (true: 0.100)
        [final] Log-likelihood: -79.79 (per sample: -0.399)
        Log-likelihood using true params: -79.97 (per sample: -0.3998)
    Subject 4 / 5
        Parameters estimates (subject-level fit)
            [subject] type1_noise: 0.636 ± 0.083 (true: 0.500)
            [subject] type1_bias: 0.070 ± 0.067 (true: 0.100)
        [subject] Log-likelihood: -94.99 (per sample: -0.4749)
        [subject] Fitting time: 0.07 secs
        Parameters estimates (group-level fit)
            [subject] type1_noise: 0.642 ± 0.078 (true: 0.500)
            [group=fixed] type1_bias: 0.109 ± 0.026 (true: 0.100)
        [final] Log-likelihood: -95.17 (per sample: -0.4758)
        Log-likelihood using true params: -97.54 (per sample: -0.4877)
    Subject 5 / 5
        Parameters estimates (subject-level fit)
            [subject] type1_noise: 0.508 ± 0.048 (true: 0.500)
            [subject] type1_bias: 0.081 ± 0.056 (true: 0.100)
        [subject] Log-likelihood: -80.71 (per sample: -0.4036)
        [subject] Fitting time: 0.07 secs
        Parameters estimates (group-level fit)
            [subject] type1_noise: 0.510 ± 0.058 (true: 0.500)
            [group=fixed] type1_bias: 0.109 ± 0.026 (true: 0.100)
        [final] Log-likelihood: -80.83 (per sample: -0.4042)
        Log-likelihood using true params: -80.78 (per sample: -0.4039)
Type 1 level finished
</span></code></pre></div></div></div></div><div id="TwJJxO7Siv" class="myst-jp-nb-block relative group/block"><p>Now, the parameter <code>type1_bias</code> is fitted to the entire group dataset and thus the parameter is identical for each participant. The final estimate of <code>0.109</code> much closer to the ground truth value of <code>0.1</code>. We once again print the final parameter more cleanly:</p></div><div id="jXJAAx26bR" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">for s in range(result.nsubjects):
    print(f&#x27;Subject {s}&#x27;)
    for k, v in result.type1.params[s].items():
        print(f&#x27;\t{k}: {v:.3f}&#x27;)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="Aq73zv4XlSIf99l6W-OI9" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-stream"><div><pre class="myst-jp-stream-output text-sm font-thin font-system"><code><span>Subject 0
	type1_noise: 0.600
	type1_bias: 0.109
Subject 1
	type1_noise: 0.406
	type1_bias: 0.109
Subject 2
	type1_noise: 0.508
	type1_bias: 0.109
Subject 3
	type1_noise: 0.642
	type1_bias: 0.109
Subject 4
	type1_noise: 0.510
	type1_bias: 0.109
</span></code></pre></div></div></div></div><div id="P6EqUXSm1v" class="myst-jp-nb-block relative group/block"><p>Note that even though parameter recovery improved, the log-likelihood of this group fit is worse (i.e. lower) than the single-subject fit:</p></div><div id="sQS0iePIVF" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">for s in range(result.nsubjects):
    print(f&#x27;Subject {s}&#x27;)
    print(f&#x27;\tnegll(subject fit): {result.type1.subject.loglik[s]:.3f}&#x27;)
    print(f&#x27;\tnegll(group fit): {result.type1.group.loglik[s]:.3f}&#x27;)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="uiP2xtQmsI07HkQp0v_Fs" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-stream"><div><pre class="myst-jp-stream-output text-sm font-thin font-system"><code><span>Subject 0
	negll(subject fit): -90.645
	negll(group fit): -91.072
Subject 1
	negll(subject fit): -64.101
	negll(group fit): -64.308
Subject 2
	negll(subject fit): -79.385
	negll(group fit): -79.794
Subject 3
	negll(subject fit): -94.989
	negll(group fit): -95.167
Subject 4
	negll(subject fit): -80.711
	negll(group fit): -80.834
</span></code></pre></div></div></div></div><div id="WvBIq9uTq9" class="myst-jp-nb-block relative group/block"><p>Yet, in this case this effectively means that the model is not overfit to random peculiarities of each subject’s data and better fits the broad trends in the group data.</p></div><div id="HxMdAD7EFY" class="myst-jp-nb-block relative group/block"><h2 id="priors" class="relative group"><span class="heading-text">Priors</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#priors" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><p>Priors present another way to inform and regularize point estimates of participants. If there is good reason from prior literature or a prior study to assume a prior distribution for a parameter, one can perform Maximum A Posteriori estimation (MAP) instead of Maximum Likelihood estimation (MLE). In Remeta this is possible by specifying the <code>prior</code> attribute of a parameter. In the following example, we delete the previous random effect for <code>type1_bias</code> and specify a prior instead - a tuple of the form (prior_mean, prior_std).</p><p>Specifically, we assume that the bias will be on average 0 with a standard deviation 0.05 (under a normal model). This is a unrealistically strong prior, but it serves for demonstration.</p></div><div id="uoWOfCXAot" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">cfg.param_type1_bias.group = None
cfg.param_type1_bias.prior = (0, 0.05)
rem = remeta.ReMeta(cfg=cfg)
rem.fit(data.stimuli, data.choices, data.confidence)
result = rem.summary()</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="n5YlBb9UDPKYLtjXdZXTO" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5 hidden"><div data-name="safe-output-stream"><div><pre class="myst-jp-stream-output text-sm font-thin font-system"><code><span>Dataset characteristics:
    No. subjects: 5
    No. samples: [200, 200, 200, 200, 200]
    Accuracy: 82.1% correct
    d&#x27;: 1.908
    Choice bias: 5.1%

+++ Type 1 level +++
  Subject-level estimation (MLE)
     Subject 1 / 5
     Subject 2 / 5
     Subject 3 / 5
     Subject 4 / 5
     Subject 5 / 5
    .. finished (0.4 secs).
  Final report
    Subject 1 / 5
        Parameters estimates (subject-level fit)
            [subject] type1_noise: 0.605 ± 0.072 (true: 0.500)
            [subject+prior=N(0,0.05)] type1_bias: 0.064 ± 0.040 (true: 0.100)
        [subject] Log-likelihood: -92.80 (per sample: -0.464)
        [subject] Fitting time: 0.05 secs
        Log-likelihood using true params: -94.56 (per sample: -0.4728)
    Subject 2 / 5
        Parameters estimates (subject-level fit)
            [subject] type1_noise: 0.403 ± 0.030 (true: 0.500)
            [subject+prior=N(0,0.05)] type1_bias: 0.038 ± 0.035 (true: 0.100)
        [subject] Log-likelihood: -64.69 (per sample: -0.3235)
        [subject] Fitting time: 0.07 secs
        Log-likelihood using true params: -67.84 (per sample: -0.3392)
    Subject 3 / 5
        Parameters estimates (subject-level fit)
            [subject] type1_noise: 0.512 ± 0.049 (true: 0.500)
            [subject+prior=N(0,0.05)] type1_bias: 0.070 ± 0.037 (true: 0.100)
        [subject] Log-likelihood: -81.63 (per sample: -0.4082)
        [subject] Fitting time: 0.04 secs
        Log-likelihood using true params: -81.97 (per sample: -0.4098)
    Subject 4 / 5
        Parameters estimates (subject-level fit)
            [subject] type1_noise: 0.636 ± 0.082 (true: 0.500)
            [subject+prior=N(0,0.05)] type1_bias: 0.025 ± 0.040 (true: 0.100)
        [subject] Log-likelihood: -95.34 (per sample: -0.4767)
        [subject] Fitting time: 0.10 secs
        Log-likelihood using true params: -99.54 (per sample: -0.4977)
    Subject 5 / 5
        Parameters estimates (subject-level fit)
            [subject] type1_noise: 0.509 ± 0.048 (true: 0.500)
            [subject+prior=N(0,0.05)] type1_bias: 0.035 ± 0.038 (true: 0.100)
        [subject] Log-likelihood: -81.29 (per sample: -0.4064)
        [subject] Fitting time: 0.11 secs
        Log-likelihood using true params: -82.78 (per sample: -0.4139)
Type 1 level finished
</span></code></pre></div></div></div></div><div id="XP8ihCpF9D" class="myst-jp-nb-block relative group/block"><p>According to our prior, a null effect for the <code>type1_bias</code> should be most likely. Indeed, as seen in the following output, the <code>type1_bias</code> is biased towards 0 compared to the original estimates without a prior:</p></div><div id="JtKt3VQANn" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">for s in range(result.nsubjects):
    print(f&#x27;Subject {s}&#x27;)
    for k, v in result.type1.params[s].items():
        print(f&#x27;\t{k}: {v:.3f}&#x27;)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="e-BryZ4o94OtiBEbhfiMi" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-stream"><div><pre class="myst-jp-stream-output text-sm font-thin font-system"><code><span>Subject 0
	type1_noise: 0.605
	type1_bias: 0.064
Subject 1
	type1_noise: 0.403
	type1_bias: 0.038
Subject 2
	type1_noise: 0.512
	type1_bias: 0.070
Subject 3
	type1_noise: 0.636
	type1_bias: 0.025
Subject 4
	type1_noise: 0.509
	type1_bias: 0.035
</span></code></pre></div></div></div></div><div class="myst-backmatter-parts"></div></article></main><script>((a,l)=>{if(!window.history.state||!window.history.state.key){let u=Math.random().toString(32).slice(2);window.history.replaceState({key:u},"")}try{let d=JSON.parse(sessionStorage.getItem(a)||"{}")[l||window.history.state.key];typeof d=="number"&&window.scrollTo(0,d)}catch(u){console.error(u),sessionStorage.removeItem(a)}})("positions", null)</script><link rel="modulepreload" href="/build/entry.client-PCJPW7TK.js"/><link rel="modulepreload" href="/build/_shared/chunk-AQ2CODAG.js"/><link rel="modulepreload" href="/build/_shared/chunk-JJXTQVMA.js"/><link rel="modulepreload" href="/build/_shared/chunk-OZE3FFNP.js"/><link rel="modulepreload" href="/build/_shared/chunk-G62B6HZR.js"/><link rel="modulepreload" href="/build/_shared/chunk-C4DFGG5C.js"/><link rel="modulepreload" href="/build/_shared/chunk-J7TUH54J.js"/><link rel="modulepreload" href="/build/_shared/chunk-FZ2S7OYD.js"/><link rel="modulepreload" href="/build/_shared/chunk-JEM6JXYA.js"/><link rel="modulepreload" href="/build/_shared/chunk-34XIY2DH.js"/><link rel="modulepreload" href="/build/_shared/chunk-KQM5FBHR.js"/><link rel="modulepreload" href="/build/_shared/chunk-OCWQY3HK.js"/><link rel="modulepreload" href="/build/_shared/chunk-7HNKBP4B.js"/><link rel="modulepreload" href="/build/_shared/chunk-CUKUDK3R.js"/><link rel="modulepreload" href="/build/_shared/chunk-3EBOCCHJ.js"/><link rel="modulepreload" href="/build/_shared/chunk-O4VQNZ62.js"/><link rel="modulepreload" href="/build/_shared/chunk-4OEDG4JQ.js"/><link rel="modulepreload" href="/build/_shared/chunk-GUCIBHGO.js"/><link rel="modulepreload" href="/build/root-PMP5BIHC.js"/><link rel="modulepreload" href="/build/_shared/chunk-IX5KPAHP.js"/><link rel="modulepreload" href="/build/routes/$-5ZLZ2O3Y.js"/><script>window.__remixContext = {"url":"/group-estimation-priors","state":{"loaderData":{"root":{"config":{"version":3,"myst":"1.8.0","options":{"hide_footer_links":true,"hide_outline":false,"favicon":"/build/favicon-e17a87f8221bef4bf7770e1beca691c0.svg","logo":"/build/logo-dcba10266a9311fcddffdac07a48fd18.png","numbered_references":true,"style":"/build/custom-92a93196ef1eb95667a9dc999d85b54b.css"},"parts":{"primary_sidebar_footer":{"mdast":{"type":"root","children":[{"type":"block","data":{"part":"primary_sidebar_footer"},"children":[],"key":"IW9xfxLbct"}],"key":"Hwl10VpeU5"},"frontmatter":{"edit_url":null,"source_url":null}}},"nav":[],"actions":[{"title":"GitHub","url":"https://github.com/coconeuro/remeta","internal":false,"static":false}],"projects":[{"downloads":[],"edit_url":null,"source_url":null,"title":"Guide","id":"855d6cd8-a251-4f69-ab26-18b1dc5659b6","toc":[{"file":"content/index.md","title":"Guide"},{"file":"content/install.md"},{"file":"content/intro.md"},{"file":"content/start.ipynb"},{"file":"content/type1.ipynb"},{"file":"content/type2.ipynb"},{"file":"content/group_estimation_priors.ipynb"},{"file":"content/results.ipynb"},{"file":"content/configuration.ipynb"},{"file":"content/plotting.ipynb"},{"url":"https://re-meta.github.io/api/","title":"API"}],"exports":[],"bibliography":[],"index":"index","pages":[{"slug":"install","title":"Installation","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"intro","title":"General idea and terminology","description":"","date":"","thumbnail":"/build/model-6b108f6d98afce3e8d23ba35a5aa2bbe.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"start","title":"Getting started","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"type1","title":"Type 1: the decision making stage","description":"","date":"","thumbnail":"/build/model_type1-d4bdb05fca82dad69d47e05a58b98d37.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"type2","title":"Type 2: the metacognitive stage","description":"","date":"","thumbnail":"/build/model_type2-26d2bf3a36fbd1e7c02e3f1d3532c230.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"group-estimation-priors","title":"Group estimation and priors","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"results","title":"Parameter estimates and model evidence","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"configuration","title":"Configuration","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"plotting","title":"Plotting","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"title":"API","url":"https://re-meta.github.io/api/","level":1}]}]},"CONTENT_CDN_PORT":"3100","MODE":"static"},"routes/$":{"config":{"version":3,"myst":"1.8.0","options":{"hide_footer_links":true,"hide_outline":false,"favicon":"/build/favicon-e17a87f8221bef4bf7770e1beca691c0.svg","logo":"/build/logo-dcba10266a9311fcddffdac07a48fd18.png","numbered_references":true,"style":"/build/custom-92a93196ef1eb95667a9dc999d85b54b.css"},"parts":{"primary_sidebar_footer":{"mdast":{"type":"root","children":[{"type":"block","data":{"part":"primary_sidebar_footer"},"children":[],"key":"IW9xfxLbct"}],"key":"Hwl10VpeU5"},"frontmatter":{"edit_url":null,"source_url":null}}},"nav":[],"actions":[{"title":"GitHub","url":"https://github.com/coconeuro/remeta","internal":false,"static":false}],"projects":[{"downloads":[],"edit_url":null,"source_url":null,"title":"Guide","id":"855d6cd8-a251-4f69-ab26-18b1dc5659b6","toc":[{"file":"content/index.md","title":"Guide"},{"file":"content/install.md"},{"file":"content/intro.md"},{"file":"content/start.ipynb"},{"file":"content/type1.ipynb"},{"file":"content/type2.ipynb"},{"file":"content/group_estimation_priors.ipynb"},{"file":"content/results.ipynb"},{"file":"content/configuration.ipynb"},{"file":"content/plotting.ipynb"},{"url":"https://re-meta.github.io/api/","title":"API"}],"exports":[],"bibliography":[],"index":"index","pages":[{"slug":"install","title":"Installation","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"intro","title":"General idea and terminology","description":"","date":"","thumbnail":"/build/model-6b108f6d98afce3e8d23ba35a5aa2bbe.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"start","title":"Getting started","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"type1","title":"Type 1: the decision making stage","description":"","date":"","thumbnail":"/build/model_type1-d4bdb05fca82dad69d47e05a58b98d37.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"type2","title":"Type 2: the metacognitive stage","description":"","date":"","thumbnail":"/build/model_type2-26d2bf3a36fbd1e7c02e3f1d3532c230.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"group-estimation-priors","title":"Group estimation and priors","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"results","title":"Parameter estimates and model evidence","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"configuration","title":"Configuration","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"plotting","title":"Plotting","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"title":"API","url":"https://re-meta.github.io/api/","level":1}]}]},"page":{"version":3,"kind":"Notebook","sha256":"57afcbb248d6c6d9b6e8dd37eba7bc8585e84cb5282911e735bbf2fd4b1439ea","slug":"group-estimation-priors","location":"/content/group_estimation_priors.ipynb","dependencies":[],"frontmatter":{"title":"Group estimation and priors","content_includes_title":false,"kernelspec":{"name":"python3","display_name":"3.13","language":"python"},"edit_url":null,"source_url":null,"exports":[{"format":"ipynb","filename":"group_estimation_priors.ipynb","url":"/build/group_estimation_pri-7e278e8eb40c60a786fe79bf65012de3.ipynb"}]},"widgets":{},"mdast":{"type":"root","children":[{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"import remeta\nimport numpy as np\n%load_ext autoreload\n%autoreload 2","visibility":"show","key":"VxLynGzxw9"},{"type":"outputs","id":"MWcvwphA-pG3E0fy3aloc","children":[{"type":"output","jupyter_data":{"name":"stdout","output_type":"stream","text":"The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n"},"children":[],"key":"nCkcEKXUNN"}],"visibility":"show","key":"eTqB2e56hL"}],"visibility":"remove","key":"H35Xqw2tX1"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Often, data from single participants are not sufficient for precise parameter estimation. In this section, we introduce to methods to address this: ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"XquhL6j6j6"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"group estimation","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"iDWgZjzBa0"}],"key":"WKYVZxG8bN"},{"type":"text","value":" (random effects or group-level fixed effects) and ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"dhmBurG3Gv"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"priors","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"n7avzg7TyU"}],"key":"ZHiBnLCUjz"},{"type":"text","value":".","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"VC7EIdoO5F"}],"key":"VqHxrduDkL"}],"key":"THB3k0kjsE"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Group estimation","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"uqqpq0KJtN"}],"identifier":"group-estimation","label":"Group estimation","html_id":"group-estimation","implicit":true,"key":"mms5ObDBGA"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"To use group-level information we need to pass 2d data to ReMeta (","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"axvYgWdEZW"},{"type":"inlineCode","value":"n_subjects","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"ftjQu7uI0b"},{"type":"text","value":" x ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"u8LDljPtiB"},{"type":"inlineCode","value":"n_samples","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"MQipsZF7HO"},{"type":"text","value":") and specify the ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"tIpjPamW9v"},{"type":"inlineCode","value":"group","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"jK9EEqikJ4"},{"type":"text","value":" attribute for parameters.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"DXCCOJPohu"}],"key":"M1J91IMq9A"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"The ","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"EjMYnXjI0I"},{"type":"inlineCode","value":"fit","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"zMecVXPIlT"},{"type":"text","value":" method of ReMeta accepts data as either 1d arrays (single participant) or as 2d arrays (group data). To this aim, we simulate type 1 data for 4 participants:","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"dJD2lcmmGd"}],"key":"xpmuIIhSk0"}],"key":"Y7BPyPkfLH"},{"type":"block","kind":"notebook-code","data":{"ExecuteTime":{"end_time":"2026-02-09T15:58:07.968487793Z","start_time":"2026-02-09T15:58:07.884109140Z"}},"children":[{"type":"code","lang":"python","executable":true,"value":"np.random.seed(42)\ncfg = remeta.Configuration()\ncfg.skip_type2 = True\nparams_true = dict(\n    type1_noise=0.5,\n    type1_bias=0.1,\n)\ncfg.true_params = params_true\ndata = remeta.simulate(nsubjects=5, nsamples=200, params=params_true, cfg=cfg)","key":"uZcqoqJxtI"},{"type":"outputs","id":"_kEbOoYY3EkN33OELISMI","children":[{"type":"output","jupyter_data":{"name":"stdout","output_type":"stream","text":"----------------------------------\n..Generative parameters:\n    Type 1 noise distribution: normal\n    type1_noise: 0.5\n    type1_bias: 0.1\n..Descriptive statistics:\n    No. subjects: 5\n    No. samples: 200\n    Accuracy: 82.1% correct\n    d': 1.9\n    Choice bias: 5.1%\n----------------------------------\n"},"children":[],"key":"tHWFeEnfHg"}],"key":"wIHsuAHfp7"}],"key":"AxbV2XaJB9"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Note that","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Hmby6r1M0S"}],"key":"CUEDX3Rzga"}],"key":"MJeCDvoksU"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"data.stimuli.shape","key":"FJCd1DsUJc"},{"type":"outputs","id":"FJWTU7YnCrEA-yWEk7stX","children":[{"type":"output","jupyter_data":{"output_type":"execute_result","execution_count":30,"metadata":{},"data":{"text/plain":{"content":"(5, 200)","content_type":"text/plain"}}},"children":[],"key":"mqzm2qGqPv"}],"key":"dULlrJVfCy"}],"key":"O9Evdpjynv"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"We fit a default ReMeta model:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"MGJquuVH53"}],"key":"eQuQLUK8cv"}],"key":"Gv43JFOxgb"},{"type":"block","kind":"notebook-code","data":{"ExecuteTime":{"end_time":"2026-02-09T15:58:08.918326085Z","start_time":"2026-02-09T15:58:08.002139017Z"},"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"rem = remeta.ReMeta(cfg=cfg)\nrem.fit(data.stimuli, data.choices, data.confidence)\nresult = rem.summary()","visibility":"show","key":"ogrDMR5hmA"},{"type":"outputs","id":"TpkDXfha6GZ8zwGixX6MC","children":[{"type":"output","jupyter_data":{"name":"stdout","output_type":"stream","text":["Dataset characteristics:\n","    No. subjects: 5\n","    No. samples: [200, 200, 200, 200, 200]\n","    Accuracy: 82.1% correct\n","    d': 1.908\n","    Choice bias: 5.1%\n","\n","+++ Type 1 level +++\n","  Subject-level estimation (MLE)\n","     Subject 1 / 5\n","     Subject 2 / 5\n","     Subject 3 / 5\n","     Subject 4 / 5\n","     Subject 5 / 5\n","    .. finished (0.6 secs).\n","  Final report\n","    Subject 1 / 5\n","        Parameters estimates (subject-level fit)\n","            [subject] type1_noise: 0.604 ± 0.073 (true: 0.500)\n","            [subject] type1_bias: 0.169 ± 0.065 (true: 0.100)\n","        [subject] Log-likelihood: -90.64 (per sample: -0.4532)\n","        [subject] Fitting time: 0.23 secs\n","        Log-likelihood using true params: -92.56 (per sample: -0.4628)\n","    Subject 2 / 5\n","        Parameters estimates (subject-level fit)\n","            [subject] type1_noise: 0.403 ± 0.030 (true: 0.500)\n","            [subject] type1_bias: 0.077 ± 0.048 (true: 0.100)\n","        [subject] Log-likelihood: -64.10 (per sample: -0.3205)\n","        [subject] Fitting time: 0.09 secs\n","        Log-likelihood using true params: -65.84 (per sample: -0.3292)\n","    Subject 3 / 5\n","        Parameters estimates (subject-level fit)\n","            [subject] type1_noise: 0.510 ± 0.049 (true: 0.500)\n","            [subject] type1_bias: 0.161 ± 0.057 (true: 0.100)\n","        [subject] Log-likelihood: -79.39 (per sample: -0.3969)\n","        [subject] Fitting time: 0.07 secs\n","        Log-likelihood using true params: -79.97 (per sample: -0.3998)\n","    Subject 4 / 5\n","        Parameters estimates (subject-level fit)\n","            [subject] type1_noise: 0.636 ± 0.083 (true: 0.500)\n","            [subject] type1_bias: 0.070 ± 0.067 (true: 0.100)\n","        [subject] Log-likelihood: -94.99 (per sample: -0.4749)\n","        [subject] Fitting time: 0.07 secs\n","        Log-likelihood using true params: -97.54 (per sample: -0.4877)\n","    Subject 5 / 5\n","        Parameters estimates (subject-level fit)\n","            [subject] type1_noise: 0.508 ± 0.048 (true: 0.500)\n","            [subject] type1_bias: 0.081 ± 0.056 (true: 0.100)\n","        [subject] Log-likelihood: -80.71 (per sample: -0.4036)\n","        [subject] Fitting time: 0.07 secs\n","        Log-likelihood using true params: -80.78 (per sample: -0.4039)\n","Type 1 level finished\n"]},"children":[],"key":"SigUdpY5z2"}],"visibility":"remove","key":"SJDIr0Dsyq"}],"visibility":"show","key":"a1S8Snna2X"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"In case of a group-level fit, the result returned by the ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"vQEnFa4Wlm"},{"type":"inlineCode","value":"summary()","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"wXXUBK4U0z"},{"type":"text","value":" method is a list of length ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"PySJttlSSW"},{"type":"inlineCode","value":"nsubjects","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"INgU9V4j6l"},{"type":"text","value":". We can print the final parameter estimates more cleanly as follows:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"GBJsAMVndB"}],"key":"PVJ7PAzCY7"}],"key":"v6UDsYrn9k"},{"type":"block","kind":"notebook-code","data":{"ExecuteTime":{"end_time":"2026-02-09T15:58:09.056867317Z","start_time":"2026-02-09T15:58:08.973769782Z"}},"children":[{"type":"code","lang":"python","executable":true,"value":"for s in range(result.nsubjects):\n    print(f'Subject {s}')\n    for k, v in result.type1.params[s].items():\n        print(f'\\t{k}: {v:.3f} ± {result.type1.params_se[s][k]:.3f}')","key":"FIzg8kPvne"},{"type":"outputs","id":"WcUEvLhtlHXzH93vreM8K","children":[{"type":"output","jupyter_data":{"name":"stdout","output_type":"stream","text":"Subject 0\n\ttype1_noise: 0.604 ± 0.073\n\ttype1_bias: 0.169 ± 0.065\nSubject 1\n\ttype1_noise: 0.403 ± 0.030\n\ttype1_bias: 0.077 ± 0.048\nSubject 2\n\ttype1_noise: 0.510 ± 0.049\n\ttype1_bias: 0.161 ± 0.057\nSubject 3\n\ttype1_noise: 0.636 ± 0.083\n\ttype1_bias: 0.070 ± 0.067\nSubject 4\n\ttype1_noise: 0.508 ± 0.048\n\ttype1_bias: 0.081 ± 0.056\n"},"children":[],"key":"upPw2f4op0"}],"key":"pg2VJxakFU"}],"key":"Vrw3ppFtwl"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"In this section, we exemplarily focus on the ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"cTjPcFMHdH"},{"type":"inlineCode","value":"type1_bias","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"csf95ktdmN"},{"type":"text","value":" parameter which was set to ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"IMBjL28xCM"},{"type":"inlineCode","value":"0.1","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"X1BKhb0rMs"},{"type":"text","value":" in the simulated data. The fitted parameters for ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"HhwQwQvEtU"},{"type":"inlineCode","value":"type1_bias","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"iYnhI6iYjc"},{"type":"text","value":" vary strongly around ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"G13FceqFKH"},{"type":"inlineCode","value":"0.1","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"IA3mpM5qAR"},{"type":"text","value":". In line with this variability, the standard errors of the parameter estimates are big.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"agschoBWz6"}],"key":"ZNrbH1iO2t"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Yet, this is no fitting error, since the empirical log-likelihood is always hight than one for the true parameters. We can verify this as follows:","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"sCmY5ahJO6"}],"key":"I0qRV30x9G"}],"key":"JZmD5zCbY3"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"for s in range(result.nsubjects):\n    print(f'Subject {s}')\n    print(f'\\tLog likelihood of true parameters: {result.type1.loglik_true[s]:.2f}')\n    print(f'\\tLog likelihood of estimated parameters: {result.type1.loglik[s]:.2f}')","key":"lLTQo5mrXx"},{"type":"outputs","id":"2gbQFLKyDvHhws7HXHP5m","children":[{"type":"output","jupyter_data":{"name":"stdout","output_type":"stream","text":"Subject 0\n\tLog likelihood of true parameters: -92.56\n\tLog likelihood of estimated parameters: -90.64\nSubject 1\n\tLog likelihood of true parameters: -65.84\n\tLog likelihood of estimated parameters: -64.10\nSubject 2\n\tLog likelihood of true parameters: -79.97\n\tLog likelihood of estimated parameters: -79.39\nSubject 3\n\tLog likelihood of true parameters: -97.54\n\tLog likelihood of estimated parameters: -94.99\nSubject 4\n\tLog likelihood of true parameters: -80.78\n\tLog likelihood of estimated parameters: -80.71\n"},"children":[],"key":"L6hWwb6ccS"}],"key":"PXOqfwyssN"}],"key":"ACdBr7kV6f"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"The issue is rather that few samples are often not representative of the ground truth. By contrast, the more samples, the less likely that the data — in aggregate — behave substantially different than the ground truth.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"iT7Ztjs7tD"}],"key":"xOWXAlhDNy"}],"key":"Oc60vDJI88"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Random effects","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"GYKbODVer1"}],"identifier":"random-effects","label":"Random effects","html_id":"random-effects","implicit":true,"key":"qSA5g0VJdc"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"An elegant way to regularize unreliable parameter estimates at the individual level are hierarchical random effect models. For random effects parameters, the likelihood computation comprises not only the likelihood given the individual data of a participant, but also the likelihood under a population distribution.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"BLxKouZSRj"}],"key":"n3oPwuZ3Fc"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"What is elegant about random effects models is that this population distribution is itself learned from the data, with the only “prio”\" that the distribution is Gaussian (at least in the frequentist domain).","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"IcNRykHcaq"}],"key":"jklqUosOs1"},{"type":"paragraph","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"In this way, extreme estimates for individual subjects are “tamed” (regularized), since they tend to be unlikely under the population distribution. Nevertheless, random effects models leave enough room for interindividual variability between participants.","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"pNpFDVmIXU"}],"key":"IEzSdZomUq"},{"type":"paragraph","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"In our example above, we specify the type 1 bias parameter as a random effects group parameter:","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"TPnOm4TyEQ"}],"key":"SrfRFpUzJz"}],"key":"GhRWWdPfVy"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"cfg.param_type1_bias.group = 'random'","key":"ehg3W5Xl9x"},{"type":"outputs","id":"gyYuU5Zaq3L6uw9F9N5uo","children":[],"key":"dUi8Wnpt0H"}],"key":"A9U3fwBIos"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"We restart the fitting procedure with this new setting:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"nRfL7GxJ9s"}],"key":"JwJlrEXgfl"}],"key":"cARiMYTo0g"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"rem = remeta.ReMeta(cfg=cfg)\nrem.fit(data.stimuli, data.choices, data.confidence)\nresult = rem.summary()","visibility":"show","key":"EVBmqRUmqj"},{"type":"outputs","id":"WeqBBa57RlYP4Op9WOUCM","children":[{"type":"output","jupyter_data":{"name":"stdout","output_type":"stream","text":["Dataset characteristics:\n","    No. subjects: 5\n","    No. samples: [200, 200, 200, 200, 200]\n","    Accuracy: 82.1% correct\n","    d': 1.908\n","    Choice bias: 5.1%\n","\n","+++ Type 1 level +++\n","  Subject-level estimation (MLE)\n","     Subject 1 / 5\n","     Subject 2 / 5\n","     Subject 3 / 5\n","     Subject 4 / 5\n","     Subject 5 / 5\n","    .. finished (0.4 secs).\n","\n","  Group-level optimization (MLE / MAP)\n","        [20:31:46] Iteration 1 / 30 (Convergence: 0.00059327)\n","        [20:31:47] Iteration 11 / 30 (Convergence: 0.00011138)\n","        [20:31:47] Iteration 21 / 30 (Convergence: 0.00004453)\n","    .. finished (0.4 secs).\n","  Final report\n","    Subject 1 / 5\n","        Parameters estimates (subject-level fit)\n","            [subject] type1_noise: 0.604 ± 0.073 (true: 0.500)\n","            [subject] type1_bias: 0.169 ± 0.065 (true: 0.100)\n","        [subject] Log-likelihood: -90.64 (per sample: -0.4532)\n","        [subject] Fitting time: 0.08 secs\n","        Parameters estimates (group-level fit)\n","            [subject] type1_noise: 0.600 ± 0.071 (true: 0.500)\n","            [group=random] type1_bias: 0.115 ± 0.019 (true: 0.100)\n","        [final] Log-likelihood: -91.00 (per sample: -0.455)\n","        Log-likelihood using true params: -92.56 (per sample: -0.4628)\n","    Subject 2 / 5\n","        Parameters estimates (subject-level fit)\n","            [subject] type1_noise: 0.403 ± 0.030 (true: 0.500)\n","            [subject] type1_bias: 0.077 ± 0.048 (true: 0.100)\n","        [subject] Log-likelihood: -64.10 (per sample: -0.3205)\n","        [subject] Fitting time: 0.07 secs\n","        Parameters estimates (group-level fit)\n","            [subject] type1_noise: 0.406 ± 0.045 (true: 0.500)\n","            [group=random] type1_bias: 0.106 ± 0.018 (true: 0.100)\n","        [final] Log-likelihood: -64.26 (per sample: -0.3213)\n","        Log-likelihood using true params: -65.84 (per sample: -0.3292)\n","    Subject 3 / 5\n","        Parameters estimates (subject-level fit)\n","            [subject] type1_noise: 0.510 ± 0.049 (true: 0.500)\n","            [subject] type1_bias: 0.161 ± 0.057 (true: 0.100)\n","        [subject] Log-likelihood: -79.39 (per sample: -0.3969)\n","        [subject] Fitting time: 0.07 secs\n","        Parameters estimates (group-level fit)\n","            [subject] type1_noise: 0.508 ± 0.057 (true: 0.500)\n","            [group=random] type1_bias: 0.115 ± 0.019 (true: 0.100)\n","        [final] Log-likelihood: -79.71 (per sample: -0.3985)\n","        Log-likelihood using true params: -79.97 (per sample: -0.3998)\n","    Subject 4 / 5\n","        Parameters estimates (subject-level fit)\n","            [subject] type1_noise: 0.636 ± 0.083 (true: 0.500)\n","            [subject] type1_bias: 0.070 ± 0.067 (true: 0.100)\n","        [subject] Log-likelihood: -94.99 (per sample: -0.4749)\n","        [subject] Fitting time: 0.06 secs\n","        Parameters estimates (group-level fit)\n","            [subject] type1_noise: 0.641 ± 0.078 (true: 0.500)\n","            [group=random] type1_bias: 0.107 ± 0.019 (true: 0.100)\n","        [final] Log-likelihood: -95.14 (per sample: -0.4757)\n","        Log-likelihood using true params: -97.54 (per sample: -0.4877)\n","    Subject 5 / 5\n","        Parameters estimates (subject-level fit)\n","            [subject] type1_noise: 0.508 ± 0.048 (true: 0.500)\n","            [subject] type1_bias: 0.081 ± 0.056 (true: 0.100)\n","        [subject] Log-likelihood: -80.71 (per sample: -0.4036)\n","        [subject] Fitting time: 0.06 secs\n","        Parameters estimates (group-level fit)\n","            [subject] type1_noise: 0.509 ± 0.058 (true: 0.500)\n","            [group=random] type1_bias: 0.107 ± 0.019 (true: 0.100)\n","        [final] Log-likelihood: -80.81 (per sample: -0.4041)\n","        Log-likelihood using true params: -80.78 (per sample: -0.4039)\n","Type 1 level finished\n"]},"children":[],"key":"FHtsbhVxf9"}],"visibility":"remove","key":"MxTpXeuIau"}],"visibility":"show","key":"X8NRQrAFWT"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"In the current example, all participant estimates for ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"NJ782xuTDc"},{"type":"inlineCode","value":"type1_bias","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"ANMb4Sw5XH"},{"type":"text","value":" are pretty similar, reflecting the fact that the data were in fact generated by the same ground truth model:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"tKssIAQ7yp"}],"key":"W6tXERYAL9"}],"key":"xMH18YwXoG"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"for s in range(result.nsubjects):\n    print(f'Subject {s}')\n    for k, v in result.type1.params[s].items():\n        print(f'\\t{k}: {v:.6f}')","key":"Pt0p4kGDeN"},{"type":"outputs","id":"ikQ6sTX4gXfK0VNC01E0_","children":[{"type":"output","jupyter_data":{"name":"stdout","output_type":"stream","text":"Subject 0\n\ttype1_noise: 0.600090\n\ttype1_bias: 0.114900\nSubject 1\n\ttype1_noise: 0.405529\n\ttype1_bias: 0.105509\nSubject 2\n\ttype1_noise: 0.508127\n\ttype1_bias: 0.115239\nSubject 3\n\ttype1_noise: 0.641339\n\ttype1_bias: 0.106636\nSubject 4\n\ttype1_noise: 0.509449\n\ttype1_bias: 0.106799\n"},"children":[],"key":"S4OAvFCIEp"}],"key":"aM5nKf4ORE"}],"key":"Ahcxj6hNbI"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"This observation is matched by an inspection of the population estimate for ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"uUXJEtwPta"},{"type":"inlineCode","value":"type1_nonlinear_gain","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"HxmZqgOkvZ"},{"type":"text","value":":","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"anauZ2yIdK"}],"key":"xr3XdQvNOm"}],"key":"Jw16ezuvCk"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"print(f'Estimated population mean: {result.params_random_effect.mean['type1_bias']:.3f}')\nprint(f'Estimated population SD: {result.params_random_effect.std['type1_bias']:.3f}')","key":"kHjP3rkFLJ"},{"type":"outputs","id":"-hBjfVWusglDVNO4w8NZc","children":[{"type":"output","jupyter_data":{"name":"stdout","output_type":"stream","text":"Estimated population mean: 0.110\nEstimated population SD: 0.019\n"},"children":[],"key":"qrw02oIlnv"}],"key":"xrEuBzewO7"}],"key":"iXZuwHUqIc"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Fixed effects","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"h2JD64ynNE"}],"identifier":"fixed-effects","label":"Fixed effects","html_id":"fixed-effects","implicit":true,"key":"UK2uIhGgfr"},{"type":"paragraph","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"Another option to tackle unreliable individual parameter estimates is to fit a single parameter to the entire group. In ReMeta, this is possible by setting the ","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"NKmbmohxCi"},{"type":"inlineCode","value":"group","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"Uwcc8ka82S"},{"type":"text","value":" attribute of the parameter to ","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"ojE7lmEssC"},{"type":"inlineCode","value":"'fixed'","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"dzEU8yiiRv"},{"type":"text","value":":","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"rzJD2zvnsY"}],"key":"hDo8SxqDMV"}],"key":"d6aphSNmSq"},{"type":"block","kind":"notebook-code","data":{"ExecuteTime":{"end_time":"2026-02-09T15:58:09.105460074Z","start_time":"2026-02-09T15:58:09.058441881Z"}},"children":[{"type":"code","lang":"python","executable":true,"value":"cfg.param_type1_bias.group = 'fixed'","key":"G9X8LJ1no3"},{"type":"outputs","id":"jSNsXEpq3QMTZ0e0sM3Wc","children":[],"key":"AGre9dpySu"}],"key":"yezCgrJnew"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"We fit the model as usual:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"mJdWbk6G26"}],"key":"u5wPNPLjBS"}],"key":"pohp10WCIv"},{"type":"block","kind":"notebook-code","data":{"ExecuteTime":{"end_time":"2026-02-09T15:58:10.410517175Z","start_time":"2026-02-09T15:58:09.107292794Z"},"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"rem = remeta.ReMeta(cfg=cfg)\nrem.fit(data.stimuli, data.choices, data.confidence)\nresult = rem.summary()","visibility":"show","key":"DREA5ppg4W"},{"type":"outputs","id":"j_KVqD-_Fl8O5OpLc10Bz","children":[{"type":"output","jupyter_data":{"name":"stdout","output_type":"stream","text":["Dataset characteristics:\n","    No. subjects: 5\n","    No. samples: [200, 200, 200, 200, 200]\n","    Accuracy: 82.1% correct\n","    d': 1.908\n","    Choice bias: 5.1%\n","\n","+++ Type 1 level +++\n","  Subject-level estimation (MLE)\n","     Subject 1 / 5\n","     Subject 2 / 5\n","     Subject 3 / 5\n","     Subject 4 / 5\n","     Subject 5 / 5\n","    .. finished (0.4 secs).\n","\n","  Group-level optimization (MLE / MAP)\n","        [20:31:47] Iteration 1 / 30\n","        [20:31:47] Iteration 11 / 30\n","        [20:31:47] Iteration 21 / 30\n","    .. finished (0.2 secs).\n","  Final report\n","    Subject 1 / 5\n","        Parameters estimates (subject-level fit)\n","            [subject] type1_noise: 0.604 ± 0.073 (true: 0.500)\n","            [subject] type1_bias: 0.169 ± 0.065 (true: 0.100)\n","        [subject] Log-likelihood: -90.64 (per sample: -0.4532)\n","        [subject] Fitting time: 0.07 secs\n","        Parameters estimates (group-level fit)\n","            [subject] type1_noise: 0.600 ± 0.071 (true: 0.500)\n","            [group=fixed] type1_bias: 0.109 ± 0.026 (true: 0.100)\n","        [final] Log-likelihood: -91.07 (per sample: -0.4554)\n","        Log-likelihood using true params: -92.56 (per sample: -0.4628)\n","    Subject 2 / 5\n","        Parameters estimates (subject-level fit)\n","            [subject] type1_noise: 0.403 ± 0.030 (true: 0.500)\n","            [subject] type1_bias: 0.077 ± 0.048 (true: 0.100)\n","        [subject] Log-likelihood: -64.10 (per sample: -0.3205)\n","        [subject] Fitting time: 0.07 secs\n","        Parameters estimates (group-level fit)\n","            [subject] type1_noise: 0.406 ± 0.045 (true: 0.500)\n","            [group=fixed] type1_bias: 0.109 ± 0.026 (true: 0.100)\n","        [final] Log-likelihood: -64.31 (per sample: -0.3215)\n","        Log-likelihood using true params: -65.84 (per sample: -0.3292)\n","    Subject 3 / 5\n","        Parameters estimates (subject-level fit)\n","            [subject] type1_noise: 0.510 ± 0.049 (true: 0.500)\n","            [subject] type1_bias: 0.161 ± 0.057 (true: 0.100)\n","        [subject] Log-likelihood: -79.39 (per sample: -0.3969)\n","        [subject] Fitting time: 0.07 secs\n","        Parameters estimates (group-level fit)\n","            [subject] type1_noise: 0.508 ± 0.057 (true: 0.500)\n","            [group=fixed] type1_bias: 0.109 ± 0.026 (true: 0.100)\n","        [final] Log-likelihood: -79.79 (per sample: -0.399)\n","        Log-likelihood using true params: -79.97 (per sample: -0.3998)\n","    Subject 4 / 5\n","        Parameters estimates (subject-level fit)\n","            [subject] type1_noise: 0.636 ± 0.083 (true: 0.500)\n","            [subject] type1_bias: 0.070 ± 0.067 (true: 0.100)\n","        [subject] Log-likelihood: -94.99 (per sample: -0.4749)\n","        [subject] Fitting time: 0.07 secs\n","        Parameters estimates (group-level fit)\n","            [subject] type1_noise: 0.642 ± 0.078 (true: 0.500)\n","            [group=fixed] type1_bias: 0.109 ± 0.026 (true: 0.100)\n","        [final] Log-likelihood: -95.17 (per sample: -0.4758)\n","        Log-likelihood using true params: -97.54 (per sample: -0.4877)\n","    Subject 5 / 5\n","        Parameters estimates (subject-level fit)\n","            [subject] type1_noise: 0.508 ± 0.048 (true: 0.500)\n","            [subject] type1_bias: 0.081 ± 0.056 (true: 0.100)\n","        [subject] Log-likelihood: -80.71 (per sample: -0.4036)\n","        [subject] Fitting time: 0.07 secs\n","        Parameters estimates (group-level fit)\n","            [subject] type1_noise: 0.510 ± 0.058 (true: 0.500)\n","            [group=fixed] type1_bias: 0.109 ± 0.026 (true: 0.100)\n","        [final] Log-likelihood: -80.83 (per sample: -0.4042)\n","        Log-likelihood using true params: -80.78 (per sample: -0.4039)\n","Type 1 level finished\n"]},"children":[],"key":"u9fkbM1h1Y"}],"visibility":"remove","key":"MKzWmrPHl4"}],"visibility":"show","key":"dZ1oXnxEz7"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Now, the parameter ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"ro0L5sT7v9"},{"type":"inlineCode","value":"type1_bias","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"WW6Oj4DvWq"},{"type":"text","value":" is fitted to the entire group dataset and thus the parameter is identical for each participant. The final estimate of ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Qb27lagvVk"},{"type":"inlineCode","value":"0.109","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"waEcaQ9N2i"},{"type":"text","value":" much closer to the ground truth value of ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"NP5wFVLNOS"},{"type":"inlineCode","value":"0.1","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"VFKhY8D2AY"},{"type":"text","value":". We once again print the final parameter more cleanly:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"FOeeyuF0BA"}],"key":"RPyMBT7zys"}],"key":"TwJJxO7Siv"},{"type":"block","kind":"notebook-code","data":{"ExecuteTime":{"end_time":"2026-02-09T15:58:10.517773446Z","start_time":"2026-02-09T15:58:10.441153308Z"}},"children":[{"type":"code","lang":"python","executable":true,"value":"for s in range(result.nsubjects):\n    print(f'Subject {s}')\n    for k, v in result.type1.params[s].items():\n        print(f'\\t{k}: {v:.3f}')","key":"gG3b3FTK1R"},{"type":"outputs","id":"Aq73zv4XlSIf99l6W-OI9","children":[{"type":"output","jupyter_data":{"name":"stdout","output_type":"stream","text":"Subject 0\n\ttype1_noise: 0.600\n\ttype1_bias: 0.109\nSubject 1\n\ttype1_noise: 0.406\n\ttype1_bias: 0.109\nSubject 2\n\ttype1_noise: 0.508\n\ttype1_bias: 0.109\nSubject 3\n\ttype1_noise: 0.642\n\ttype1_bias: 0.109\nSubject 4\n\ttype1_noise: 0.510\n\ttype1_bias: 0.109\n"},"children":[],"key":"qRSDci8NYp"}],"key":"NWSF6YKOl8"}],"key":"jXJAAx26bR"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Note that even though parameter recovery improved, the log-likelihood of this group fit is worse (i.e. lower) than the single-subject fit:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"O57IEqhuoO"}],"key":"QbGtA3X9tx"}],"key":"P6EqUXSm1v"},{"type":"block","kind":"notebook-code","data":{"ExecuteTime":{"end_time":"2026-02-09T15:58:10.596358678Z","start_time":"2026-02-09T15:58:10.518611429Z"}},"children":[{"type":"code","lang":"python","executable":true,"value":"for s in range(result.nsubjects):\n    print(f'Subject {s}')\n    print(f'\\tnegll(subject fit): {result.type1.subject.loglik[s]:.3f}')\n    print(f'\\tnegll(group fit): {result.type1.group.loglik[s]:.3f}')","key":"iPI5MLHXHs"},{"type":"outputs","id":"uiP2xtQmsI07HkQp0v_Fs","children":[{"type":"output","jupyter_data":{"name":"stdout","output_type":"stream","text":"Subject 0\n\tnegll(subject fit): -90.645\n\tnegll(group fit): -91.072\nSubject 1\n\tnegll(subject fit): -64.101\n\tnegll(group fit): -64.308\nSubject 2\n\tnegll(subject fit): -79.385\n\tnegll(group fit): -79.794\nSubject 3\n\tnegll(subject fit): -94.989\n\tnegll(group fit): -95.167\nSubject 4\n\tnegll(subject fit): -80.711\n\tnegll(group fit): -80.834\n"},"children":[],"key":"buVZKohUy9"}],"key":"RqdhP3hrl3"}],"key":"sQS0iePIVF"},{"type":"block","kind":"notebook-content","data":{"ExecuteTime":{"end_time":"2026-01-27T15:26:46.374615841Z","start_time":"2026-01-27T15:26:46.276004093Z"}},"children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Yet, in this case this effectively means that the model is not overfit to random peculiarities of each subject’s data and better fits the broad trends in the group data.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"hoYw96at2e"}],"key":"P4XofJEFGW"}],"key":"WvBIq9uTq9"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Priors","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"FXbCX1s4rM"}],"identifier":"priors","label":"Priors","html_id":"priors","implicit":true,"key":"RLeBMFwxUp"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Priors present another way to inform and regularize point estimates of participants. If there is good reason from prior literature or a prior study to assume a prior distribution for a parameter, one can perform Maximum A Posteriori estimation (MAP) instead of Maximum Likelihood estimation (MLE). In Remeta this is possible by specifying the ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"frKQw0MVdc"},{"type":"inlineCode","value":"prior","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"f0o0rZZkfD"},{"type":"text","value":" attribute of a parameter. In the following example, we delete the previous random effect for ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"gbeSKIzKhe"},{"type":"inlineCode","value":"type1_bias","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"DTnFloGFho"},{"type":"text","value":" and specify a prior instead - a tuple of the form (prior_mean, prior_std).","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"wVICgTI05W"}],"key":"eoFmFWw76v"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"Specifically, we assume that the bias will be on average 0 with a standard deviation 0.05 (under a normal model). This is a unrealistically strong prior, but it serves for demonstration.","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"J4b84lcXLw"}],"key":"Z6qR07DlA6"}],"key":"HxMdAD7EFY"},{"type":"block","kind":"notebook-code","data":{"ExecuteTime":{"end_time":"2026-02-09T15:58:13.861251950Z","start_time":"2026-02-09T15:58:12.931622202Z"},"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"cfg.param_type1_bias.group = None\ncfg.param_type1_bias.prior = (0, 0.05)\nrem = remeta.ReMeta(cfg=cfg)\nrem.fit(data.stimuli, data.choices, data.confidence)\nresult = rem.summary()","visibility":"show","key":"qdWHA77ZEx"},{"type":"outputs","id":"n5YlBb9UDPKYLtjXdZXTO","children":[{"type":"output","jupyter_data":{"name":"stdout","output_type":"stream","text":["Dataset characteristics:\n","    No. subjects: 5\n","    No. samples: [200, 200, 200, 200, 200]\n","    Accuracy: 82.1% correct\n","    d': 1.908\n","    Choice bias: 5.1%\n","\n","+++ Type 1 level +++\n","  Subject-level estimation (MLE)\n","     Subject 1 / 5\n","     Subject 2 / 5\n","     Subject 3 / 5\n","     Subject 4 / 5\n","     Subject 5 / 5\n","    .. finished (0.4 secs).\n","  Final report\n","    Subject 1 / 5\n","        Parameters estimates (subject-level fit)\n","            [subject] type1_noise: 0.605 ± 0.072 (true: 0.500)\n","            [subject+prior=N(0,0.05)] type1_bias: 0.064 ± 0.040 (true: 0.100)\n","        [subject] Log-likelihood: -92.80 (per sample: -0.464)\n","        [subject] Fitting time: 0.05 secs\n","        Log-likelihood using true params: -94.56 (per sample: -0.4728)\n","    Subject 2 / 5\n","        Parameters estimates (subject-level fit)\n","            [subject] type1_noise: 0.403 ± 0.030 (true: 0.500)\n","            [subject+prior=N(0,0.05)] type1_bias: 0.038 ± 0.035 (true: 0.100)\n","        [subject] Log-likelihood: -64.69 (per sample: -0.3235)\n","        [subject] Fitting time: 0.07 secs\n","        Log-likelihood using true params: -67.84 (per sample: -0.3392)\n","    Subject 3 / 5\n","        Parameters estimates (subject-level fit)\n","            [subject] type1_noise: 0.512 ± 0.049 (true: 0.500)\n","            [subject+prior=N(0,0.05)] type1_bias: 0.070 ± 0.037 (true: 0.100)\n","        [subject] Log-likelihood: -81.63 (per sample: -0.4082)\n","        [subject] Fitting time: 0.04 secs\n","        Log-likelihood using true params: -81.97 (per sample: -0.4098)\n","    Subject 4 / 5\n","        Parameters estimates (subject-level fit)\n","            [subject] type1_noise: 0.636 ± 0.082 (true: 0.500)\n","            [subject+prior=N(0,0.05)] type1_bias: 0.025 ± 0.040 (true: 0.100)\n","        [subject] Log-likelihood: -95.34 (per sample: -0.4767)\n","        [subject] Fitting time: 0.10 secs\n","        Log-likelihood using true params: -99.54 (per sample: -0.4977)\n","    Subject 5 / 5\n","        Parameters estimates (subject-level fit)\n","            [subject] type1_noise: 0.509 ± 0.048 (true: 0.500)\n","            [subject+prior=N(0,0.05)] type1_bias: 0.035 ± 0.038 (true: 0.100)\n","        [subject] Log-likelihood: -81.29 (per sample: -0.4064)\n","        [subject] Fitting time: 0.11 secs\n","        Log-likelihood using true params: -82.78 (per sample: -0.4139)\n","Type 1 level finished\n"]},"children":[],"key":"UuqLOc9q1z"}],"visibility":"remove","key":"pE1J1D3Eye"}],"visibility":"show","key":"uoWOfCXAot"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"According to our prior, a null effect for the ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"UDqiCIigmx"},{"type":"inlineCode","value":"type1_bias","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"n4be0TfIbh"},{"type":"text","value":" should be most likely. Indeed, as seen in the following output, the ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"TmPRCx4qIM"},{"type":"inlineCode","value":"type1_bias","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"vGg0YJxB2z"},{"type":"text","value":" is biased towards 0 compared to the original estimates without a prior:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"LJmGSyyCSU"}],"key":"LENfgeNutJ"}],"key":"XP8ihCpF9D"},{"type":"block","kind":"notebook-code","data":{"ExecuteTime":{"end_time":"2026-02-09T15:58:13.986274966Z","start_time":"2026-02-09T15:58:13.914532665Z"}},"children":[{"type":"code","lang":"python","executable":true,"value":"for s in range(result.nsubjects):\n    print(f'Subject {s}')\n    for k, v in result.type1.params[s].items():\n        print(f'\\t{k}: {v:.3f}')","key":"EmB6hPhlid"},{"type":"outputs","id":"e-BryZ4o94OtiBEbhfiMi","children":[{"type":"output","jupyter_data":{"name":"stdout","output_type":"stream","text":"Subject 0\n\ttype1_noise: 0.605\n\ttype1_bias: 0.064\nSubject 1\n\ttype1_noise: 0.403\n\ttype1_bias: 0.038\nSubject 2\n\ttype1_noise: 0.512\n\ttype1_bias: 0.070\nSubject 3\n\ttype1_noise: 0.636\n\ttype1_bias: 0.025\nSubject 4\n\ttype1_noise: 0.509\n\ttype1_bias: 0.035\n"},"children":[],"key":"R4RyHlXBaN"}],"key":"kg9ieMgZGs"}],"key":"JtKt3VQANn"}],"key":"lCCXhEGfoJ"},"references":{"cite":{"order":[],"data":{}}},"footer":{"navigation":{"prev":{"title":"Type 2: the metacognitive stage","url":"/type2","group":"Guide"},"next":{"title":"Parameter estimates and model evidence","url":"/results","group":"Guide"}}},"domain":"http://localhost:3000"},"project":{"downloads":[],"edit_url":null,"source_url":null,"title":"Guide","id":"855d6cd8-a251-4f69-ab26-18b1dc5659b6","toc":[{"file":"content/index.md","title":"Guide"},{"file":"content/install.md"},{"file":"content/intro.md"},{"file":"content/start.ipynb"},{"file":"content/type1.ipynb"},{"file":"content/type2.ipynb"},{"file":"content/group_estimation_priors.ipynb"},{"file":"content/results.ipynb"},{"file":"content/configuration.ipynb"},{"file":"content/plotting.ipynb"},{"url":"https://re-meta.github.io/api/","title":"API"}],"exports":[],"bibliography":[],"index":"index","pages":[{"slug":"install","title":"Installation","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"intro","title":"General idea and terminology","description":"","date":"","thumbnail":"/build/model-6b108f6d98afce3e8d23ba35a5aa2bbe.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"start","title":"Getting started","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"type1","title":"Type 1: the decision making stage","description":"","date":"","thumbnail":"/build/model_type1-d4bdb05fca82dad69d47e05a58b98d37.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"type2","title":"Type 2: the metacognitive stage","description":"","date":"","thumbnail":"/build/model_type2-26d2bf3a36fbd1e7c02e3f1d3532c230.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"group-estimation-priors","title":"Group estimation and priors","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"results","title":"Parameter estimates and model evidence","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"configuration","title":"Configuration","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"plotting","title":"Plotting","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"title":"API","url":"https://re-meta.github.io/api/","level":1}]}}},"actionData":null,"errors":null},"future":{"unstable_dev":false,"unstable_postcss":false,"unstable_tailwind":false,"v2_errorBoundary":true,"v2_headers":true,"v2_meta":true,"v2_normalizeFormMethod":true,"v2_routeConvention":true}};</script><script type="module" async="">import "/build/manifest-54BD5942.js";
import * as route0 from "/build/root-PMP5BIHC.js";
import * as route1 from "/build/routes/$-5ZLZ2O3Y.js";
window.__remixRouteModules = {"root":route0,"routes/$":route1};

import("/build/entry.client-PCJPW7TK.js");</script></body></html>