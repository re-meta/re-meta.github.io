{"version":3,"kind":"Notebook","sha256":"57afcbb248d6c6d9b6e8dd37eba7bc8585e84cb5282911e735bbf2fd4b1439ea","slug":"group-estimation-priors","location":"/content/group_estimation_priors.ipynb","dependencies":[],"frontmatter":{"title":"Group estimation and priors","content_includes_title":false,"kernelspec":{"name":"python3","display_name":"3.13","language":"python"},"edit_url":null,"source_url":null,"exports":[{"format":"ipynb","filename":"group_estimation_priors.ipynb","url":"/build/group_estimation_pri-7e278e8eb40c60a786fe79bf65012de3.ipynb"}]},"widgets":{},"mdast":{"type":"root","children":[{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"import remeta\nimport numpy as np\n%load_ext autoreload\n%autoreload 2","visibility":"show","key":"VxLynGzxw9"},{"type":"outputs","id":"MWcvwphA-pG3E0fy3aloc","children":[{"type":"output","jupyter_data":{"name":"stdout","output_type":"stream","text":"The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n"},"children":[],"key":"nCkcEKXUNN"}],"visibility":"show","key":"eTqB2e56hL"}],"visibility":"remove","key":"H35Xqw2tX1"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Often, data from single participants are not sufficient for precise parameter estimation. In this section, we introduce to methods to address this: ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"XquhL6j6j6"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"group estimation","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"iDWgZjzBa0"}],"key":"WKYVZxG8bN"},{"type":"text","value":" (random effects or group-level fixed effects) and ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"dhmBurG3Gv"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"priors","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"n7avzg7TyU"}],"key":"ZHiBnLCUjz"},{"type":"text","value":".","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"VC7EIdoO5F"}],"key":"VqHxrduDkL"}],"key":"THB3k0kjsE"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Group estimation","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"uqqpq0KJtN"}],"identifier":"group-estimation","label":"Group estimation","html_id":"group-estimation","implicit":true,"key":"mms5ObDBGA"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"To use group-level information we need to pass 2d data to ReMeta (","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"axvYgWdEZW"},{"type":"inlineCode","value":"n_subjects","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"ftjQu7uI0b"},{"type":"text","value":" x ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"u8LDljPtiB"},{"type":"inlineCode","value":"n_samples","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"MQipsZF7HO"},{"type":"text","value":") and specify the ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"tIpjPamW9v"},{"type":"inlineCode","value":"group","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"jK9EEqikJ4"},{"type":"text","value":" attribute for parameters.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"DXCCOJPohu"}],"key":"M1J91IMq9A"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"The ","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"EjMYnXjI0I"},{"type":"inlineCode","value":"fit","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"zMecVXPIlT"},{"type":"text","value":" method of ReMeta accepts data as either 1d arrays (single participant) or as 2d arrays (group data). To this aim, we simulate type 1 data for 4 participants:","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"dJD2lcmmGd"}],"key":"xpmuIIhSk0"}],"key":"Y7BPyPkfLH"},{"type":"block","kind":"notebook-code","data":{"ExecuteTime":{"end_time":"2026-02-09T15:58:07.968487793Z","start_time":"2026-02-09T15:58:07.884109140Z"}},"children":[{"type":"code","lang":"python","executable":true,"value":"np.random.seed(42)\ncfg = remeta.Configuration()\ncfg.skip_type2 = True\nparams_true = dict(\n    type1_noise=0.5,\n    type1_bias=0.1,\n)\ncfg.true_params = params_true\ndata = remeta.simulate(nsubjects=5, nsamples=200, params=params_true, cfg=cfg)","key":"uZcqoqJxtI"},{"type":"outputs","id":"_kEbOoYY3EkN33OELISMI","children":[{"type":"output","jupyter_data":{"name":"stdout","output_type":"stream","text":"----------------------------------\n..Generative parameters:\n    Type 1 noise distribution: normal\n    type1_noise: 0.5\n    type1_bias: 0.1\n..Descriptive statistics:\n    No. subjects: 5\n    No. samples: 200\n    Accuracy: 82.1% correct\n    d': 1.9\n    Choice bias: 5.1%\n----------------------------------\n"},"children":[],"key":"tHWFeEnfHg"}],"key":"wIHsuAHfp7"}],"key":"AxbV2XaJB9"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Note that","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Hmby6r1M0S"}],"key":"CUEDX3Rzga"}],"key":"MJeCDvoksU"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"data.stimuli.shape","key":"FJCd1DsUJc"},{"type":"outputs","id":"FJWTU7YnCrEA-yWEk7stX","children":[{"type":"output","jupyter_data":{"output_type":"execute_result","execution_count":30,"metadata":{},"data":{"text/plain":{"content":"(5, 200)","content_type":"text/plain"}}},"children":[],"key":"mqzm2qGqPv"}],"key":"dULlrJVfCy"}],"key":"O9Evdpjynv"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"We fit a default ReMeta model:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"MGJquuVH53"}],"key":"eQuQLUK8cv"}],"key":"Gv43JFOxgb"},{"type":"block","kind":"notebook-code","data":{"ExecuteTime":{"end_time":"2026-02-09T15:58:08.918326085Z","start_time":"2026-02-09T15:58:08.002139017Z"},"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"rem = remeta.ReMeta(cfg=cfg)\nrem.fit(data.stimuli, data.choices, data.confidence)\nresult = rem.summary()","visibility":"show","key":"ogrDMR5hmA"},{"type":"outputs","id":"TpkDXfha6GZ8zwGixX6MC","children":[{"type":"output","jupyter_data":{"name":"stdout","output_type":"stream","text":["Dataset characteristics:\n","    No. subjects: 5\n","    No. samples: [200, 200, 200, 200, 200]\n","    Accuracy: 82.1% correct\n","    d': 1.908\n","    Choice bias: 5.1%\n","\n","+++ Type 1 level +++\n","  Subject-level estimation (MLE)\n","     Subject 1 / 5\n","     Subject 2 / 5\n","     Subject 3 / 5\n","     Subject 4 / 5\n","     Subject 5 / 5\n","    .. finished (0.6 secs).\n","  Final report\n","    Subject 1 / 5\n","        Parameters estimates (subject-level fit)\n","            [subject] type1_noise: 0.604 ± 0.073 (true: 0.500)\n","            [subject] type1_bias: 0.169 ± 0.065 (true: 0.100)\n","        [subject] Log-likelihood: -90.64 (per sample: -0.4532)\n","        [subject] Fitting time: 0.23 secs\n","        Log-likelihood using true params: -92.56 (per sample: -0.4628)\n","    Subject 2 / 5\n","        Parameters estimates (subject-level fit)\n","            [subject] type1_noise: 0.403 ± 0.030 (true: 0.500)\n","            [subject] type1_bias: 0.077 ± 0.048 (true: 0.100)\n","        [subject] Log-likelihood: -64.10 (per sample: -0.3205)\n","        [subject] Fitting time: 0.09 secs\n","        Log-likelihood using true params: -65.84 (per sample: -0.3292)\n","    Subject 3 / 5\n","        Parameters estimates (subject-level fit)\n","            [subject] type1_noise: 0.510 ± 0.049 (true: 0.500)\n","            [subject] type1_bias: 0.161 ± 0.057 (true: 0.100)\n","        [subject] Log-likelihood: -79.39 (per sample: -0.3969)\n","        [subject] Fitting time: 0.07 secs\n","        Log-likelihood using true params: -79.97 (per sample: -0.3998)\n","    Subject 4 / 5\n","        Parameters estimates (subject-level fit)\n","            [subject] type1_noise: 0.636 ± 0.083 (true: 0.500)\n","            [subject] type1_bias: 0.070 ± 0.067 (true: 0.100)\n","        [subject] Log-likelihood: -94.99 (per sample: -0.4749)\n","        [subject] Fitting time: 0.07 secs\n","        Log-likelihood using true params: -97.54 (per sample: -0.4877)\n","    Subject 5 / 5\n","        Parameters estimates (subject-level fit)\n","            [subject] type1_noise: 0.508 ± 0.048 (true: 0.500)\n","            [subject] type1_bias: 0.081 ± 0.056 (true: 0.100)\n","        [subject] Log-likelihood: -80.71 (per sample: -0.4036)\n","        [subject] Fitting time: 0.07 secs\n","        Log-likelihood using true params: -80.78 (per sample: -0.4039)\n","Type 1 level finished\n"]},"children":[],"key":"SigUdpY5z2"}],"visibility":"remove","key":"SJDIr0Dsyq"}],"visibility":"show","key":"a1S8Snna2X"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"In case of a group-level fit, the result returned by the ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"vQEnFa4Wlm"},{"type":"inlineCode","value":"summary()","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"wXXUBK4U0z"},{"type":"text","value":" method is a list of length ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"PySJttlSSW"},{"type":"inlineCode","value":"nsubjects","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"INgU9V4j6l"},{"type":"text","value":". We can print the final parameter estimates more cleanly as follows:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"GBJsAMVndB"}],"key":"PVJ7PAzCY7"}],"key":"v6UDsYrn9k"},{"type":"block","kind":"notebook-code","data":{"ExecuteTime":{"end_time":"2026-02-09T15:58:09.056867317Z","start_time":"2026-02-09T15:58:08.973769782Z"}},"children":[{"type":"code","lang":"python","executable":true,"value":"for s in range(result.nsubjects):\n    print(f'Subject {s}')\n    for k, v in result.type1.params[s].items():\n        print(f'\\t{k}: {v:.3f} ± {result.type1.params_se[s][k]:.3f}')","key":"FIzg8kPvne"},{"type":"outputs","id":"WcUEvLhtlHXzH93vreM8K","children":[{"type":"output","jupyter_data":{"name":"stdout","output_type":"stream","text":"Subject 0\n\ttype1_noise: 0.604 ± 0.073\n\ttype1_bias: 0.169 ± 0.065\nSubject 1\n\ttype1_noise: 0.403 ± 0.030\n\ttype1_bias: 0.077 ± 0.048\nSubject 2\n\ttype1_noise: 0.510 ± 0.049\n\ttype1_bias: 0.161 ± 0.057\nSubject 3\n\ttype1_noise: 0.636 ± 0.083\n\ttype1_bias: 0.070 ± 0.067\nSubject 4\n\ttype1_noise: 0.508 ± 0.048\n\ttype1_bias: 0.081 ± 0.056\n"},"children":[],"key":"upPw2f4op0"}],"key":"pg2VJxakFU"}],"key":"Vrw3ppFtwl"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"In this section, we exemplarily focus on the ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"cTjPcFMHdH"},{"type":"inlineCode","value":"type1_bias","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"csf95ktdmN"},{"type":"text","value":" parameter which was set to ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"IMBjL28xCM"},{"type":"inlineCode","value":"0.1","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"X1BKhb0rMs"},{"type":"text","value":" in the simulated data. The fitted parameters for ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"HhwQwQvEtU"},{"type":"inlineCode","value":"type1_bias","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"iYnhI6iYjc"},{"type":"text","value":" vary strongly around ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"G13FceqFKH"},{"type":"inlineCode","value":"0.1","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"IA3mpM5qAR"},{"type":"text","value":". In line with this variability, the standard errors of the parameter estimates are big.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"agschoBWz6"}],"key":"ZNrbH1iO2t"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Yet, this is no fitting error, since the empirical log-likelihood is always hight than one for the true parameters. We can verify this as follows:","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"sCmY5ahJO6"}],"key":"I0qRV30x9G"}],"key":"JZmD5zCbY3"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"for s in range(result.nsubjects):\n    print(f'Subject {s}')\n    print(f'\\tLog likelihood of true parameters: {result.type1.loglik_true[s]:.2f}')\n    print(f'\\tLog likelihood of estimated parameters: {result.type1.loglik[s]:.2f}')","key":"lLTQo5mrXx"},{"type":"outputs","id":"2gbQFLKyDvHhws7HXHP5m","children":[{"type":"output","jupyter_data":{"name":"stdout","output_type":"stream","text":"Subject 0\n\tLog likelihood of true parameters: -92.56\n\tLog likelihood of estimated parameters: -90.64\nSubject 1\n\tLog likelihood of true parameters: -65.84\n\tLog likelihood of estimated parameters: -64.10\nSubject 2\n\tLog likelihood of true parameters: -79.97\n\tLog likelihood of estimated parameters: -79.39\nSubject 3\n\tLog likelihood of true parameters: -97.54\n\tLog likelihood of estimated parameters: -94.99\nSubject 4\n\tLog likelihood of true parameters: -80.78\n\tLog likelihood of estimated parameters: -80.71\n"},"children":[],"key":"L6hWwb6ccS"}],"key":"PXOqfwyssN"}],"key":"ACdBr7kV6f"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"The issue is rather that few samples are often not representative of the ground truth. By contrast, the more samples, the less likely that the data — in aggregate — behave substantially different than the ground truth.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"iT7Ztjs7tD"}],"key":"xOWXAlhDNy"}],"key":"Oc60vDJI88"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Random effects","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"GYKbODVer1"}],"identifier":"random-effects","label":"Random effects","html_id":"random-effects","implicit":true,"key":"qSA5g0VJdc"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"An elegant way to regularize unreliable parameter estimates at the individual level are hierarchical random effect models. For random effects parameters, the likelihood computation comprises not only the likelihood given the individual data of a participant, but also the likelihood under a population distribution.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"BLxKouZSRj"}],"key":"n3oPwuZ3Fc"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"What is elegant about random effects models is that this population distribution is itself learned from the data, with the only “prio”\" that the distribution is Gaussian (at least in the frequentist domain).","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"IcNRykHcaq"}],"key":"jklqUosOs1"},{"type":"paragraph","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"In this way, extreme estimates for individual subjects are “tamed” (regularized), since they tend to be unlikely under the population distribution. Nevertheless, random effects models leave enough room for interindividual variability between participants.","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"pNpFDVmIXU"}],"key":"IEzSdZomUq"},{"type":"paragraph","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"In our example above, we specify the type 1 bias parameter as a random effects group parameter:","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"TPnOm4TyEQ"}],"key":"SrfRFpUzJz"}],"key":"GhRWWdPfVy"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"cfg.param_type1_bias.group = 'random'","key":"ehg3W5Xl9x"},{"type":"outputs","id":"gyYuU5Zaq3L6uw9F9N5uo","children":[],"key":"dUi8Wnpt0H"}],"key":"A9U3fwBIos"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"We restart the fitting procedure with this new setting:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"nRfL7GxJ9s"}],"key":"JwJlrEXgfl"}],"key":"cARiMYTo0g"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"rem = remeta.ReMeta(cfg=cfg)\nrem.fit(data.stimuli, data.choices, data.confidence)\nresult = rem.summary()","visibility":"show","key":"EVBmqRUmqj"},{"type":"outputs","id":"WeqBBa57RlYP4Op9WOUCM","children":[{"type":"output","jupyter_data":{"name":"stdout","output_type":"stream","text":["Dataset characteristics:\n","    No. subjects: 5\n","    No. samples: [200, 200, 200, 200, 200]\n","    Accuracy: 82.1% correct\n","    d': 1.908\n","    Choice bias: 5.1%\n","\n","+++ Type 1 level +++\n","  Subject-level estimation (MLE)\n","     Subject 1 / 5\n","     Subject 2 / 5\n","     Subject 3 / 5\n","     Subject 4 / 5\n","     Subject 5 / 5\n","    .. finished (0.4 secs).\n","\n","  Group-level optimization (MLE / MAP)\n","        [20:31:46] Iteration 1 / 30 (Convergence: 0.00059327)\n","        [20:31:47] Iteration 11 / 30 (Convergence: 0.00011138)\n","        [20:31:47] Iteration 21 / 30 (Convergence: 0.00004453)\n","    .. finished (0.4 secs).\n","  Final report\n","    Subject 1 / 5\n","        Parameters estimates (subject-level fit)\n","            [subject] type1_noise: 0.604 ± 0.073 (true: 0.500)\n","            [subject] type1_bias: 0.169 ± 0.065 (true: 0.100)\n","        [subject] Log-likelihood: -90.64 (per sample: -0.4532)\n","        [subject] Fitting time: 0.08 secs\n","        Parameters estimates (group-level fit)\n","            [subject] type1_noise: 0.600 ± 0.071 (true: 0.500)\n","            [group=random] type1_bias: 0.115 ± 0.019 (true: 0.100)\n","        [final] Log-likelihood: -91.00 (per sample: -0.455)\n","        Log-likelihood using true params: -92.56 (per sample: -0.4628)\n","    Subject 2 / 5\n","        Parameters estimates (subject-level fit)\n","            [subject] type1_noise: 0.403 ± 0.030 (true: 0.500)\n","            [subject] type1_bias: 0.077 ± 0.048 (true: 0.100)\n","        [subject] Log-likelihood: -64.10 (per sample: -0.3205)\n","        [subject] Fitting time: 0.07 secs\n","        Parameters estimates (group-level fit)\n","            [subject] type1_noise: 0.406 ± 0.045 (true: 0.500)\n","            [group=random] type1_bias: 0.106 ± 0.018 (true: 0.100)\n","        [final] Log-likelihood: -64.26 (per sample: -0.3213)\n","        Log-likelihood using true params: -65.84 (per sample: -0.3292)\n","    Subject 3 / 5\n","        Parameters estimates (subject-level fit)\n","            [subject] type1_noise: 0.510 ± 0.049 (true: 0.500)\n","            [subject] type1_bias: 0.161 ± 0.057 (true: 0.100)\n","        [subject] Log-likelihood: -79.39 (per sample: -0.3969)\n","        [subject] Fitting time: 0.07 secs\n","        Parameters estimates (group-level fit)\n","            [subject] type1_noise: 0.508 ± 0.057 (true: 0.500)\n","            [group=random] type1_bias: 0.115 ± 0.019 (true: 0.100)\n","        [final] Log-likelihood: -79.71 (per sample: -0.3985)\n","        Log-likelihood using true params: -79.97 (per sample: -0.3998)\n","    Subject 4 / 5\n","        Parameters estimates (subject-level fit)\n","            [subject] type1_noise: 0.636 ± 0.083 (true: 0.500)\n","            [subject] type1_bias: 0.070 ± 0.067 (true: 0.100)\n","        [subject] Log-likelihood: -94.99 (per sample: -0.4749)\n","        [subject] Fitting time: 0.06 secs\n","        Parameters estimates (group-level fit)\n","            [subject] type1_noise: 0.641 ± 0.078 (true: 0.500)\n","            [group=random] type1_bias: 0.107 ± 0.019 (true: 0.100)\n","        [final] Log-likelihood: -95.14 (per sample: -0.4757)\n","        Log-likelihood using true params: -97.54 (per sample: -0.4877)\n","    Subject 5 / 5\n","        Parameters estimates (subject-level fit)\n","            [subject] type1_noise: 0.508 ± 0.048 (true: 0.500)\n","            [subject] type1_bias: 0.081 ± 0.056 (true: 0.100)\n","        [subject] Log-likelihood: -80.71 (per sample: -0.4036)\n","        [subject] Fitting time: 0.06 secs\n","        Parameters estimates (group-level fit)\n","            [subject] type1_noise: 0.509 ± 0.058 (true: 0.500)\n","            [group=random] type1_bias: 0.107 ± 0.019 (true: 0.100)\n","        [final] Log-likelihood: -80.81 (per sample: -0.4041)\n","        Log-likelihood using true params: -80.78 (per sample: -0.4039)\n","Type 1 level finished\n"]},"children":[],"key":"FHtsbhVxf9"}],"visibility":"remove","key":"MxTpXeuIau"}],"visibility":"show","key":"X8NRQrAFWT"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"In the current example, all participant estimates for ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"NJ782xuTDc"},{"type":"inlineCode","value":"type1_bias","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"ANMb4Sw5XH"},{"type":"text","value":" are pretty similar, reflecting the fact that the data were in fact generated by the same ground truth model:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"tKssIAQ7yp"}],"key":"W6tXERYAL9"}],"key":"xMH18YwXoG"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"for s in range(result.nsubjects):\n    print(f'Subject {s}')\n    for k, v in result.type1.params[s].items():\n        print(f'\\t{k}: {v:.6f}')","key":"Pt0p4kGDeN"},{"type":"outputs","id":"ikQ6sTX4gXfK0VNC01E0_","children":[{"type":"output","jupyter_data":{"name":"stdout","output_type":"stream","text":"Subject 0\n\ttype1_noise: 0.600090\n\ttype1_bias: 0.114900\nSubject 1\n\ttype1_noise: 0.405529\n\ttype1_bias: 0.105509\nSubject 2\n\ttype1_noise: 0.508127\n\ttype1_bias: 0.115239\nSubject 3\n\ttype1_noise: 0.641339\n\ttype1_bias: 0.106636\nSubject 4\n\ttype1_noise: 0.509449\n\ttype1_bias: 0.106799\n"},"children":[],"key":"S4OAvFCIEp"}],"key":"aM5nKf4ORE"}],"key":"Ahcxj6hNbI"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"This observation is matched by an inspection of the population estimate for ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"uUXJEtwPta"},{"type":"inlineCode","value":"type1_nonlinear_gain","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"HxmZqgOkvZ"},{"type":"text","value":":","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"anauZ2yIdK"}],"key":"xr3XdQvNOm"}],"key":"Jw16ezuvCk"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"print(f'Estimated population mean: {result.params_random_effect.mean['type1_bias']:.3f}')\nprint(f'Estimated population SD: {result.params_random_effect.std['type1_bias']:.3f}')","key":"kHjP3rkFLJ"},{"type":"outputs","id":"-hBjfVWusglDVNO4w8NZc","children":[{"type":"output","jupyter_data":{"name":"stdout","output_type":"stream","text":"Estimated population mean: 0.110\nEstimated population SD: 0.019\n"},"children":[],"key":"qrw02oIlnv"}],"key":"xrEuBzewO7"}],"key":"iXZuwHUqIc"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Fixed effects","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"h2JD64ynNE"}],"identifier":"fixed-effects","label":"Fixed effects","html_id":"fixed-effects","implicit":true,"key":"UK2uIhGgfr"},{"type":"paragraph","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"Another option to tackle unreliable individual parameter estimates is to fit a single parameter to the entire group. In ReMeta, this is possible by setting the ","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"NKmbmohxCi"},{"type":"inlineCode","value":"group","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"Uwcc8ka82S"},{"type":"text","value":" attribute of the parameter to ","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"ojE7lmEssC"},{"type":"inlineCode","value":"'fixed'","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"dzEU8yiiRv"},{"type":"text","value":":","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"rzJD2zvnsY"}],"key":"hDo8SxqDMV"}],"key":"d6aphSNmSq"},{"type":"block","kind":"notebook-code","data":{"ExecuteTime":{"end_time":"2026-02-09T15:58:09.105460074Z","start_time":"2026-02-09T15:58:09.058441881Z"}},"children":[{"type":"code","lang":"python","executable":true,"value":"cfg.param_type1_bias.group = 'fixed'","key":"G9X8LJ1no3"},{"type":"outputs","id":"jSNsXEpq3QMTZ0e0sM3Wc","children":[],"key":"AGre9dpySu"}],"key":"yezCgrJnew"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"We fit the model as usual:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"mJdWbk6G26"}],"key":"u5wPNPLjBS"}],"key":"pohp10WCIv"},{"type":"block","kind":"notebook-code","data":{"ExecuteTime":{"end_time":"2026-02-09T15:58:10.410517175Z","start_time":"2026-02-09T15:58:09.107292794Z"},"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"rem = remeta.ReMeta(cfg=cfg)\nrem.fit(data.stimuli, data.choices, data.confidence)\nresult = rem.summary()","visibility":"show","key":"DREA5ppg4W"},{"type":"outputs","id":"j_KVqD-_Fl8O5OpLc10Bz","children":[{"type":"output","jupyter_data":{"name":"stdout","output_type":"stream","text":["Dataset characteristics:\n","    No. subjects: 5\n","    No. samples: [200, 200, 200, 200, 200]\n","    Accuracy: 82.1% correct\n","    d': 1.908\n","    Choice bias: 5.1%\n","\n","+++ Type 1 level +++\n","  Subject-level estimation (MLE)\n","     Subject 1 / 5\n","     Subject 2 / 5\n","     Subject 3 / 5\n","     Subject 4 / 5\n","     Subject 5 / 5\n","    .. finished (0.4 secs).\n","\n","  Group-level optimization (MLE / MAP)\n","        [20:31:47] Iteration 1 / 30\n","        [20:31:47] Iteration 11 / 30\n","        [20:31:47] Iteration 21 / 30\n","    .. finished (0.2 secs).\n","  Final report\n","    Subject 1 / 5\n","        Parameters estimates (subject-level fit)\n","            [subject] type1_noise: 0.604 ± 0.073 (true: 0.500)\n","            [subject] type1_bias: 0.169 ± 0.065 (true: 0.100)\n","        [subject] Log-likelihood: -90.64 (per sample: -0.4532)\n","        [subject] Fitting time: 0.07 secs\n","        Parameters estimates (group-level fit)\n","            [subject] type1_noise: 0.600 ± 0.071 (true: 0.500)\n","            [group=fixed] type1_bias: 0.109 ± 0.026 (true: 0.100)\n","        [final] Log-likelihood: -91.07 (per sample: -0.4554)\n","        Log-likelihood using true params: -92.56 (per sample: -0.4628)\n","    Subject 2 / 5\n","        Parameters estimates (subject-level fit)\n","            [subject] type1_noise: 0.403 ± 0.030 (true: 0.500)\n","            [subject] type1_bias: 0.077 ± 0.048 (true: 0.100)\n","        [subject] Log-likelihood: -64.10 (per sample: -0.3205)\n","        [subject] Fitting time: 0.07 secs\n","        Parameters estimates (group-level fit)\n","            [subject] type1_noise: 0.406 ± 0.045 (true: 0.500)\n","            [group=fixed] type1_bias: 0.109 ± 0.026 (true: 0.100)\n","        [final] Log-likelihood: -64.31 (per sample: -0.3215)\n","        Log-likelihood using true params: -65.84 (per sample: -0.3292)\n","    Subject 3 / 5\n","        Parameters estimates (subject-level fit)\n","            [subject] type1_noise: 0.510 ± 0.049 (true: 0.500)\n","            [subject] type1_bias: 0.161 ± 0.057 (true: 0.100)\n","        [subject] Log-likelihood: -79.39 (per sample: -0.3969)\n","        [subject] Fitting time: 0.07 secs\n","        Parameters estimates (group-level fit)\n","            [subject] type1_noise: 0.508 ± 0.057 (true: 0.500)\n","            [group=fixed] type1_bias: 0.109 ± 0.026 (true: 0.100)\n","        [final] Log-likelihood: -79.79 (per sample: -0.399)\n","        Log-likelihood using true params: -79.97 (per sample: -0.3998)\n","    Subject 4 / 5\n","        Parameters estimates (subject-level fit)\n","            [subject] type1_noise: 0.636 ± 0.083 (true: 0.500)\n","            [subject] type1_bias: 0.070 ± 0.067 (true: 0.100)\n","        [subject] Log-likelihood: -94.99 (per sample: -0.4749)\n","        [subject] Fitting time: 0.07 secs\n","        Parameters estimates (group-level fit)\n","            [subject] type1_noise: 0.642 ± 0.078 (true: 0.500)\n","            [group=fixed] type1_bias: 0.109 ± 0.026 (true: 0.100)\n","        [final] Log-likelihood: -95.17 (per sample: -0.4758)\n","        Log-likelihood using true params: -97.54 (per sample: -0.4877)\n","    Subject 5 / 5\n","        Parameters estimates (subject-level fit)\n","            [subject] type1_noise: 0.508 ± 0.048 (true: 0.500)\n","            [subject] type1_bias: 0.081 ± 0.056 (true: 0.100)\n","        [subject] Log-likelihood: -80.71 (per sample: -0.4036)\n","        [subject] Fitting time: 0.07 secs\n","        Parameters estimates (group-level fit)\n","            [subject] type1_noise: 0.510 ± 0.058 (true: 0.500)\n","            [group=fixed] type1_bias: 0.109 ± 0.026 (true: 0.100)\n","        [final] Log-likelihood: -80.83 (per sample: -0.4042)\n","        Log-likelihood using true params: -80.78 (per sample: -0.4039)\n","Type 1 level finished\n"]},"children":[],"key":"u9fkbM1h1Y"}],"visibility":"remove","key":"MKzWmrPHl4"}],"visibility":"show","key":"dZ1oXnxEz7"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Now, the parameter ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"ro0L5sT7v9"},{"type":"inlineCode","value":"type1_bias","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"WW6Oj4DvWq"},{"type":"text","value":" is fitted to the entire group dataset and thus the parameter is identical for each participant. The final estimate of ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Qb27lagvVk"},{"type":"inlineCode","value":"0.109","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"waEcaQ9N2i"},{"type":"text","value":" much closer to the ground truth value of ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"NP5wFVLNOS"},{"type":"inlineCode","value":"0.1","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"VFKhY8D2AY"},{"type":"text","value":". We once again print the final parameter more cleanly:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"FOeeyuF0BA"}],"key":"RPyMBT7zys"}],"key":"TwJJxO7Siv"},{"type":"block","kind":"notebook-code","data":{"ExecuteTime":{"end_time":"2026-02-09T15:58:10.517773446Z","start_time":"2026-02-09T15:58:10.441153308Z"}},"children":[{"type":"code","lang":"python","executable":true,"value":"for s in range(result.nsubjects):\n    print(f'Subject {s}')\n    for k, v in result.type1.params[s].items():\n        print(f'\\t{k}: {v:.3f}')","key":"gG3b3FTK1R"},{"type":"outputs","id":"Aq73zv4XlSIf99l6W-OI9","children":[{"type":"output","jupyter_data":{"name":"stdout","output_type":"stream","text":"Subject 0\n\ttype1_noise: 0.600\n\ttype1_bias: 0.109\nSubject 1\n\ttype1_noise: 0.406\n\ttype1_bias: 0.109\nSubject 2\n\ttype1_noise: 0.508\n\ttype1_bias: 0.109\nSubject 3\n\ttype1_noise: 0.642\n\ttype1_bias: 0.109\nSubject 4\n\ttype1_noise: 0.510\n\ttype1_bias: 0.109\n"},"children":[],"key":"qRSDci8NYp"}],"key":"NWSF6YKOl8"}],"key":"jXJAAx26bR"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Note that even though parameter recovery improved, the log-likelihood of this group fit is worse (i.e. lower) than the single-subject fit:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"O57IEqhuoO"}],"key":"QbGtA3X9tx"}],"key":"P6EqUXSm1v"},{"type":"block","kind":"notebook-code","data":{"ExecuteTime":{"end_time":"2026-02-09T15:58:10.596358678Z","start_time":"2026-02-09T15:58:10.518611429Z"}},"children":[{"type":"code","lang":"python","executable":true,"value":"for s in range(result.nsubjects):\n    print(f'Subject {s}')\n    print(f'\\tnegll(subject fit): {result.type1.subject.loglik[s]:.3f}')\n    print(f'\\tnegll(group fit): {result.type1.group.loglik[s]:.3f}')","key":"iPI5MLHXHs"},{"type":"outputs","id":"uiP2xtQmsI07HkQp0v_Fs","children":[{"type":"output","jupyter_data":{"name":"stdout","output_type":"stream","text":"Subject 0\n\tnegll(subject fit): -90.645\n\tnegll(group fit): -91.072\nSubject 1\n\tnegll(subject fit): -64.101\n\tnegll(group fit): -64.308\nSubject 2\n\tnegll(subject fit): -79.385\n\tnegll(group fit): -79.794\nSubject 3\n\tnegll(subject fit): -94.989\n\tnegll(group fit): -95.167\nSubject 4\n\tnegll(subject fit): -80.711\n\tnegll(group fit): -80.834\n"},"children":[],"key":"buVZKohUy9"}],"key":"RqdhP3hrl3"}],"key":"sQS0iePIVF"},{"type":"block","kind":"notebook-content","data":{"ExecuteTime":{"end_time":"2026-01-27T15:26:46.374615841Z","start_time":"2026-01-27T15:26:46.276004093Z"}},"children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Yet, in this case this effectively means that the model is not overfit to random peculiarities of each subject’s data and better fits the broad trends in the group data.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"hoYw96at2e"}],"key":"P4XofJEFGW"}],"key":"WvBIq9uTq9"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Priors","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"FXbCX1s4rM"}],"identifier":"priors","label":"Priors","html_id":"priors","implicit":true,"key":"RLeBMFwxUp"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Priors present another way to inform and regularize point estimates of participants. If there is good reason from prior literature or a prior study to assume a prior distribution for a parameter, one can perform Maximum A Posteriori estimation (MAP) instead of Maximum Likelihood estimation (MLE). In Remeta this is possible by specifying the ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"frKQw0MVdc"},{"type":"inlineCode","value":"prior","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"f0o0rZZkfD"},{"type":"text","value":" attribute of a parameter. In the following example, we delete the previous random effect for ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"gbeSKIzKhe"},{"type":"inlineCode","value":"type1_bias","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"DTnFloGFho"},{"type":"text","value":" and specify a prior instead - a tuple of the form (prior_mean, prior_std).","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"wVICgTI05W"}],"key":"eoFmFWw76v"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"Specifically, we assume that the bias will be on average 0 with a standard deviation 0.05 (under a normal model). This is a unrealistically strong prior, but it serves for demonstration.","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"J4b84lcXLw"}],"key":"Z6qR07DlA6"}],"key":"HxMdAD7EFY"},{"type":"block","kind":"notebook-code","data":{"ExecuteTime":{"end_time":"2026-02-09T15:58:13.861251950Z","start_time":"2026-02-09T15:58:12.931622202Z"},"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"cfg.param_type1_bias.group = None\ncfg.param_type1_bias.prior = (0, 0.05)\nrem = remeta.ReMeta(cfg=cfg)\nrem.fit(data.stimuli, data.choices, data.confidence)\nresult = rem.summary()","visibility":"show","key":"qdWHA77ZEx"},{"type":"outputs","id":"n5YlBb9UDPKYLtjXdZXTO","children":[{"type":"output","jupyter_data":{"name":"stdout","output_type":"stream","text":["Dataset characteristics:\n","    No. subjects: 5\n","    No. samples: [200, 200, 200, 200, 200]\n","    Accuracy: 82.1% correct\n","    d': 1.908\n","    Choice bias: 5.1%\n","\n","+++ Type 1 level +++\n","  Subject-level estimation (MLE)\n","     Subject 1 / 5\n","     Subject 2 / 5\n","     Subject 3 / 5\n","     Subject 4 / 5\n","     Subject 5 / 5\n","    .. finished (0.4 secs).\n","  Final report\n","    Subject 1 / 5\n","        Parameters estimates (subject-level fit)\n","            [subject] type1_noise: 0.605 ± 0.072 (true: 0.500)\n","            [subject+prior=N(0,0.05)] type1_bias: 0.064 ± 0.040 (true: 0.100)\n","        [subject] Log-likelihood: -92.80 (per sample: -0.464)\n","        [subject] Fitting time: 0.05 secs\n","        Log-likelihood using true params: -94.56 (per sample: -0.4728)\n","    Subject 2 / 5\n","        Parameters estimates (subject-level fit)\n","            [subject] type1_noise: 0.403 ± 0.030 (true: 0.500)\n","            [subject+prior=N(0,0.05)] type1_bias: 0.038 ± 0.035 (true: 0.100)\n","        [subject] Log-likelihood: -64.69 (per sample: -0.3235)\n","        [subject] Fitting time: 0.07 secs\n","        Log-likelihood using true params: -67.84 (per sample: -0.3392)\n","    Subject 3 / 5\n","        Parameters estimates (subject-level fit)\n","            [subject] type1_noise: 0.512 ± 0.049 (true: 0.500)\n","            [subject+prior=N(0,0.05)] type1_bias: 0.070 ± 0.037 (true: 0.100)\n","        [subject] Log-likelihood: -81.63 (per sample: -0.4082)\n","        [subject] Fitting time: 0.04 secs\n","        Log-likelihood using true params: -81.97 (per sample: -0.4098)\n","    Subject 4 / 5\n","        Parameters estimates (subject-level fit)\n","            [subject] type1_noise: 0.636 ± 0.082 (true: 0.500)\n","            [subject+prior=N(0,0.05)] type1_bias: 0.025 ± 0.040 (true: 0.100)\n","        [subject] Log-likelihood: -95.34 (per sample: -0.4767)\n","        [subject] Fitting time: 0.10 secs\n","        Log-likelihood using true params: -99.54 (per sample: -0.4977)\n","    Subject 5 / 5\n","        Parameters estimates (subject-level fit)\n","            [subject] type1_noise: 0.509 ± 0.048 (true: 0.500)\n","            [subject+prior=N(0,0.05)] type1_bias: 0.035 ± 0.038 (true: 0.100)\n","        [subject] Log-likelihood: -81.29 (per sample: -0.4064)\n","        [subject] Fitting time: 0.11 secs\n","        Log-likelihood using true params: -82.78 (per sample: -0.4139)\n","Type 1 level finished\n"]},"children":[],"key":"UuqLOc9q1z"}],"visibility":"remove","key":"pE1J1D3Eye"}],"visibility":"show","key":"uoWOfCXAot"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"According to our prior, a null effect for the ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"UDqiCIigmx"},{"type":"inlineCode","value":"type1_bias","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"n4be0TfIbh"},{"type":"text","value":" should be most likely. Indeed, as seen in the following output, the ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"TmPRCx4qIM"},{"type":"inlineCode","value":"type1_bias","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"vGg0YJxB2z"},{"type":"text","value":" is biased towards 0 compared to the original estimates without a prior:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"LJmGSyyCSU"}],"key":"LENfgeNutJ"}],"key":"XP8ihCpF9D"},{"type":"block","kind":"notebook-code","data":{"ExecuteTime":{"end_time":"2026-02-09T15:58:13.986274966Z","start_time":"2026-02-09T15:58:13.914532665Z"}},"children":[{"type":"code","lang":"python","executable":true,"value":"for s in range(result.nsubjects):\n    print(f'Subject {s}')\n    for k, v in result.type1.params[s].items():\n        print(f'\\t{k}: {v:.3f}')","key":"EmB6hPhlid"},{"type":"outputs","id":"e-BryZ4o94OtiBEbhfiMi","children":[{"type":"output","jupyter_data":{"name":"stdout","output_type":"stream","text":"Subject 0\n\ttype1_noise: 0.605\n\ttype1_bias: 0.064\nSubject 1\n\ttype1_noise: 0.403\n\ttype1_bias: 0.038\nSubject 2\n\ttype1_noise: 0.512\n\ttype1_bias: 0.070\nSubject 3\n\ttype1_noise: 0.636\n\ttype1_bias: 0.025\nSubject 4\n\ttype1_noise: 0.509\n\ttype1_bias: 0.035\n"},"children":[],"key":"R4RyHlXBaN"}],"key":"kg9ieMgZGs"}],"key":"JtKt3VQANn"}],"key":"lCCXhEGfoJ"},"references":{"cite":{"order":[],"data":{}}},"footer":{"navigation":{"prev":{"title":"Type 2: the metacognitive stage","url":"/type2","group":"Guide"},"next":{"title":"Parameter estimates and model evidence","url":"/results","group":"Guide"}}},"domain":"http://localhost:3000"}