{"version":"1","records":[{"hierarchy":{"lvl1":"Architecture"},"type":"lvl1","url":"/architecture","position":0},{"hierarchy":{"lvl1":"Architecture"},"content":"The ReMeta toolbox allows researchers to estimate latent parameters of observers that perform a decision-making task involving confidence ratings. Type 1 parameters refer to parameters that describe the decision-making process, while Type 2 parameters refer to parameters that describe the confidence rating process. The focus of Remeta is an estimate of metacognitive noise, i.e. how accurately observers can monitor their own performance, and metacognitive bias, i.e. whether observers tend to be over- or under-confident.\n\nThe basic architecture of the toolbox is shown in the figure below.\n\n\n\nBased on a stimulus input x, the observer computes a decision value y, the sign of which determines a type 1 decision D. This process can be characterized by a variety of type 1 parameters, including type 1 noise \\sigma_{1} (sensory or decisional noise) and a type 1 decision bias \\delta_1.\n\nThe absolute value of the noisy decision value — labeled type 1 evidence z_1 — is the relevant input to the type 2 level. This “readout” may not be perfect though and could be subject to some readout noise \\sigma_2 and a multiplicative bias \\varphi_2. Thus, the evidence at the type 2 stage — type 2 evidence z_2 — may be different from z_1. A model with unreliable readout is referred to as noisy-readout model.\n\nBy design, the model assumes that observers represent confidence as probability correct, thus computing c=p(\\text{correct}\\mid z_2,\\hat{\\sigma}_1). This is sometimes referred to as Bayesian confidence. Nevertheless, for this computation, the observer needs an estimate \\hat{\\sigma}_1 of their own type 1 noise \\sigma_1.\n\nEstimating one’s own type 1 noise \\sigma_1 is far from trivial and may thus plausibly be subject to some noise itself. This is a second form of metacognitive noise that was suggested by \n\nBoundy-Singer et al. (2022). Here, this is referred to as noisy-temperature model.\n\nFinally, internal representations of confidence need to be communicated to the experiementer. This likewise is a lossy process, for two reasons: 1) the most confidence scales are discrete and hence required confidence criteria \\gamma_1, \\dots, \\gamma_n to map a continuous internal estimate to a finite number of response options; 2) the mapping itself may be noisy. This last form of metacognitive noise is referred to as a noisy-report model.\n\nIn ReMeta, the researcher must decide for which of these three sources of metacognitive noise they consider most dominant or most interesting, since only one can be modeled at a time.","type":"content","url":"/architecture","position":1},{"hierarchy":{"lvl1":"Installation"},"type":"lvl1","url":"/install","position":0},{"hierarchy":{"lvl1":"Installation"},"content":"Remeta requires a working Python installation. It should run with Python >=3.9.\n\nThe ReMeta itself can be installed with pip:pip install remeta\n\nOr directly from GitHub:pip install git+https://github.com/m-guggenmos/remeta.git\n\n(this command requires an installed Git, e.g. \n\ngitforwindows)\n\nRequired packages (should be automatically installed with pip):\n\nnumpy (>=1.18.1)\n\nscipy (>=1.3)\n\nmultiprocessing_on_dill (>=3.5.0a4) (only necessary for when the toolbox should be used with multiple cores)\n\nmatplotlib (>=3.1.3)","type":"content","url":"/install","position":1},{"hierarchy":{"lvl1":"ReMeta Guide"},"type":"lvl1","url":"/intro-1","position":0},{"hierarchy":{"lvl1":"ReMeta Guide"},"content":"This guide provides a more detailed introduction to the ReMeta toolbox.\n\nGithub repository: \n\nhttps://​github​.com​/m​-guggenmos​/remeta","type":"content","url":"/intro-1","position":1},{"hierarchy":{"lvl1":"ReMeta Guide"},"type":"lvl1","url":"/intro-1","position":0},{"hierarchy":{"lvl1":"ReMeta Guide"},"content":"This guide provides a more detailed introduction to the ReMeta toolbox.\n\nGithub repository: \n\nhttps://​github​.com​/m​-guggenmos​/remeta","type":"content","url":"/intro-1","position":1},{"hierarchy":{"lvl1":"ReMeta Guide"},"type":"lvl1","url":"/intro-1","position":0},{"hierarchy":{"lvl1":"ReMeta Guide"},"content":"This guide provides a more detailed introduction to the ReMeta toolbox.\n\nGithub repository: \n\nhttps://​github​.com​/m​-guggenmos​/remeta","type":"content","url":"/intro-1","position":1},{"hierarchy":{"lvl1":"Getting started"},"type":"lvl1","url":"/start","position":0},{"hierarchy":{"lvl1":"Getting started"},"content":"Three types of data are required to fit a ReMeta model:-  Table -\n\nVariable\n\nDescription\n\nstimuli\n\nlist/array of signed stimulus intensity values, where the sign codes the stimulus category and the absolute value codes the intensity. The stimuli should be normalized to [-1; 1], although there is a setting (normalize_stimuli_by_max) to auto-normalize stimuli.\n\nchoices\n\nlist/array of choices coded as 0 (or alternatively -1) for the negative stimuli category and 1 for the positive stimulus category.\n\nconfidence\n\nlist/array of confidence ratings. Confidence ratings must be normalized to [0; 1]. Discrete confidence ratings must be normalized accordingly (e.g., if confidence ratings are 1-4, subtract 1 and divide by 3).\n\nWhen fitting individual participants, these are 1d lists / arrays with length ntrials. If 2d lists / arrays are passed, ReMeta treats this as group data with shape nsubjects x ntrials (-> Group data).\n\nTo quickly demonstrate ReMeta, we load a simple build-in dataset as follows.\n\nimport remeta\nds = remeta.load_dataset('default')  \n\n\n\nThe output provides information how the dataset was generated and some descriptive statistics.\n\nrem = remeta.ReMeta()\nrem.fit(ds.stimuli, ds.choices, ds.confidence)\n\n\n\nSince the dataset is based on simulation, we know the true parameters of the underlying generative model (see first output), which are quite close to the fitted parameters.\n\nWe can access the fitted parameters by invoking the summary() method on the ReMeta instance:\n\n# Access fitted parameters\nimport numpy as np\nresult = rem.summary()\nfor k, v in result.params.items():\n    print(f'{k}: {np.array2string(np.array(v), precision=3)}')\n\n\n\nBy default, the model fits parameters for type 1 noise (type1_noise) and a type 1 bias (type1_bias), as well as metacognitive ‘type 2’ noise (type2_noise) and 4 confidence criteria (type2_criteria). Moreover, by default the model assumes that metacognitive noise occurs at the stage of the confidence report (setting type2_noise_type='noisy_report') and that type 2 metacognitive noise can be described by a truncated normal distribution (setting type2_noise_dist='truncated_norm_mode').\n\nAll settings can be changed via the Configuration object which is optionally passed to the ReMeta instance. For example, to change the metacognitive noisy type to “noisy-readout”:\n\ncfg = remeta.Configuration()\ncfg.type2_noise_type = 'noisy_readout'\nrem = remeta.ReMeta(cfg)\n\n","type":"content","url":"/start","position":1},{"hierarchy":{"lvl1":""},"type":"lvl1","url":"/visualize-nonlinear-encoding","position":0},{"hierarchy":{"lvl1":""},"content":"import remeta\nfrom remeta.transform import compute_nonlinear_encoding as nonlinear_encoding, logistic\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import binned_statistic\n\n\n\nnp.random.seed(1)\n\n\n\nnsamples = 100000\ngains = [-0.88, -0.5, -0.25, -0.1, 0, 0.5, 1, 2, 4]\nx = np.arange(-1, 1, 0.001)\n\nparams = dict(\n    type1_noise=0.5,\n    type1_bias=0,\n    type1_nonlinear_encoding_gain=1\n)\ncfg = remeta.Configuration()\ncfg.skip_type2 = True\ncfg.enable_param_type1_nonlinear_encoding_gain = 1\ncfg.type2_noise_dist = 'truncated_norm_mode'\n\n\n\nd = remeta.simu_data(nsubjects=1, nsamples=nsamples, params=params, cfg=cfg, x_stim_external=None, verbosity=True,\n                     squeeze=True, compute_stats=True)\n\n\n\nplt.figure()\n# plt.plot(d.stimuli, d.y_decval, 'o')\n\nedges = np.arange(np.min(d.stimuli), np.max(d.stimuli) + 0.1, 0.1)\nmean, sd = [binned_statistic(d.stimuli, d.choices, statistic=stat, bins=edges)[0] for stat in ('mean', 'std')]\ncenters = (edges[:-1] + edges[1:]) / 2\n\nplt.errorbar(centers, mean, yerr=sd, fmt=\"o-\", capsize=3)\n\n# plt.plot([-1, 1], [0, 1], 'k--')\nplt.plot(x, logistic(x, params['type1_noise']), 'k--')\nplt.plot([0, 0], [-2, 2], 'k', lw=0.75)\nplt.plot([-1, 1], [0.5, 0.5], 'k', lw=0.75)\nplt.xlim(-1, 1)\nplt.ylim(-0.5, 1.5)\n\n\n\n\n\ncolors = plt.get_cmap('gnuplot')(np.linspace(0, 1, len(gains)))\ncolors.shape\n\n\n\nplt.figure()\ncolors = plt.get_cmap('gnuplot')(np.linspace(0, 1, int(len(gains)/2)+1))\ncolors = np.vstack((colors[1:][::-1], colors))\nfor i, gain in enumerate(gains):\n    plt.plot(x, nonlinear_encoding(x, type1_nonlinear_encoding_gain=gain), label=f'{gain}', color=colors[i], ls=':' if gain < 0 else ('--' if gain == 0 else '-'))\nplt.plot([0, 0], [-2, 2], 'k', lw=0.75)\nplt.plot([-1, 1], [0, 0], 'k', lw=0.75)\nplt.xlim(-1, 1)\nplt.ylim(-2, 2)\nplt.legend(title='Gain', bbox_to_anchor=(-0.2, 0.5), loc='center')\n\n\n\nplt.figure()\nx = np.arange(-1, 1, 0.001)\ngains = [-0.88, -0.5, -0.25, -0.1, 0, 0.5, 1, 2, 4]\ncolors = plt.get_cmap('gnuplot')(np.linspace(0, 1, int(len(gains)/2)+1))\ncolors = np.vstack((colors[1:][::-1], colors))\nfor i, gain in enumerate(gains):\n    plt.plot(x, logistic(nonlinear_encoding(x, type1_nonlinear_encoding_gain=gain), params['type1_noise']), label=f'{gain}', color=colors[i], ls=':' if gain < 0 else ('--' if gain == 0 else '-'))\nplt.plot(x, logistic(x, params['type1_noise']), 'k--')\nplt.plot([0, 0], [0, 1], 'k', lw=0.75)\nplt.plot([-1, 1], [0.5, 0.5], 'k', lw=0.75)\nplt.xlim(-1, 1)\nplt.ylim(0, 1)\nplt.ylabel('Choice probability')\nplt.legend(title='Gain', bbox_to_anchor=(-0.2, 0.5), loc='center')\n\n\n\nplt.figure()\nx = np.arange(-1, 1, 0.001)\ntransitions = [0.1, 1, 2]\ncolors = plt.get_cmap('gnuplot')(np.linspace(0, 1, len(transitions)))[::-1]\nfor i, transition in enumerate(transitions):\n    plt.plot(x, nonlinear_encoding(x, type1_nonlinear_encoding_gain=1, type1_nonlinear_encoding_transition=transition), label=f'{transition}', color=colors[i])\nplt.plot([-1, 1], [-1, 1], 'k--')\nplt.plot([0, 0], [-2, 2], 'k', lw=0.75)\nplt.plot([-1, 1], [0, 0], 'k', lw=0.75)\nplt.xlim(-1, 1)\nplt.ylim(-2, 2)\nplt.legend(title='Transition')\n\n","type":"content","url":"/visualize-nonlinear-encoding","position":1}]}