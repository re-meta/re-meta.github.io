{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"API","text":""},{"location":"configuration/","title":"remeta.configuration.Configuration","text":"<p>Configuration for the ReMeta toolbox</p> Usage <pre><code>cfg = remeta.configuration\ncfg.&lt;some_setting&gt; = &lt;some_value&gt;\nrem = remeta.ReMeta(cfg)\n</code></pre> <p>To change parameters use:</p> <pre><code>cfg.param_&lt;param_name&gt;.&lt;param_attribute&gt; = &lt;value&gt;\n</code></pre> <p>See [<code>Parameter</code>][remeta.modelspec.Parameter] for more information.</p> <p>Parameters:</p> Name Type Description Default <code>normalize_stimuli_by_max</code> <code>bool</code> <p>If True, normalize provided stimuli by their maximum value to the range [-1; 1].  Note that stimuli should be roughly in the range [-1; 1] for optimal parameter estimation.</p> <code>False</code> <code>type2_noise_type</code> <code>str</code> <p>Whether the model considers noise at readout, report or for the estimation of type 1 noise (\"temperature\"). Possible values: <code>'readout'</code>, <code>'report'</code>, <code>'temperature'</code>.</p> <code>'report'</code> <code>skip_type2</code> <code>bool</code> <p>If <code>True</code>, only fit type 1 data. No confidence data needs to be passed to <code>fit()</code> in this case.</p> <code>False</code> <code>optim_type1_gridsearch</code> <code>bool</code> <p>If <code>True</code>, perform an initial gridsearch search for type 1 parameter optimization, based on the <code>grid_range</code> attributes of Parameters.</p> <code>False</code> <code>optim_type1_minimize_along_grid</code> <code>bool</code> <p>If <code>True</code>, do sqlqp minimization for type 1 parameter optimization at each grid point.</p> <code>False</code> <code>optim_type1_global_minimization</code> <code>str</code> <p>Use one of 'shgo', 'dual_annealing' 'differential_evolution' to perform type 1 likelihood minimization with a global minimizer.</p> <code>None</code> <code>optim_type1_scipy_solvers</code> <code>str | list[str] | tuple[str, ...]</code> <p>Set scipy.optimize.minimize solver method for type 1 parameter optimization.. If provided as tuple/list, test different solvers and take the best.</p> <code>'trust-constr'</code> <code>optim_type2_gridsearch</code> <code>bool</code> <p>If <code>True</code>, perform an initial gridsearch search for type 2 parameter optimization, based on the <code>grid_range</code> attributes of Parameters.</p> <code>False</code> <code>optim_type2_minimize_along_grid</code> <code>bool</code> <p>If <code>True</code>, do sqlqp minimization for type 2 parameter optimization at each grid point.</p> <code>False</code> <code>optim_type2_global_minimization</code> <code>str</code> <p>Use one of 'shgo', 'dual_annealing' 'differential_evolution' to perform type 2 likelihood minimization with a global minimizer.</p> <code>None</code> <code>optim_type2_scipy_solvers</code> <code>str | list[str] | tuple[str, ...]</code> <p>Set scipy.optimize.minimize solver method for type 2 parameter optimization.. If provided as tuple/list, test different solvers and take the best.</p> <code>('slsqp', 'Nelder-Mead')</code> <code>optim_type2_slsqp_epsilon</code> <code>float</code> <p>Set parameter epsilon parameter for the SLSQP optimization method (type 2). If provided as tuple/list, test different eps parameters and take the best</p> <code>None</code> <code>optim_num_cores</code> <code>int</code> <p>Number of cores used for parameter estimation (-1 for all cores minus 1).</p> <code>1</code> <code>param_type1_noise</code> <code>Parameter</code> <p>Type 1 noise.</p> <code>Parameter \tenable: 1 \tguess: 0.5 \tbounds: (0.001, 10) \tgrid_range: [0.1        0.22857143 0.35714286 0.48571429 0.61428571 0.74285714  0.87142857 1.        ] \tgroup: None \tprior: None \tpreset: None \tdefault: 0.01 \tmodel: normal \t_definition_changed: False</code> <code>param_type1_thresh</code> <code>Parameter</code> <p>Type 1 threshold.</p> <code>Parameter \tenable: 0 \tguess: 0 \tbounds: (0, 1) \tgrid_range: [0.   0.05 0.1  0.15 0.2 ] \tgroup: None \tprior: None \tpreset: None \tdefault: 0 \tmodel: None \t_definition_changed: False</code> <code>param_type1_bias</code> <code>Parameter</code> <p>Type 1 bias.</p> <code>Parameter \tenable: 1 \tguess: 0 \tbounds: (-1, 1) \tgrid_range: [-0.2        -0.14285714 -0.08571429 -0.02857143  0.02857143  0.08571429   0.14285714  0.2       ] \tgroup: None \tprior: None \tpreset: None \tdefault: 0 \tmodel: None \t_definition_changed: False</code> <code>param_type1_nonlinear_gain</code> <code>Parameter</code> <p>Gain parameter for nonlinear encoding (higher values -&gt; stronger nonlinearity).</p> <code>Parameter \tenable: 0 \tguess: 0 \tbounds: (-0.8888888888888888, 10) \tgrid_range: [-0.5   -0.125  0.25   0.625  1.   ] \tgroup: None \tprior: None \tpreset: None \tdefault: 0 \tmodel: None \t_definition_changed: False</code> <code>param_type1_nonlinear_scale</code> <code>Parameter</code> <p>Scale parameter for the nonlinearity (higher values -&gt; non-linearity kicks in later).</p> <code>Parameter \tenable: 0 \tguess: 1 \tbounds: (0.01, 10) \tgrid_range: [0.01   0.5075 1.005  1.5025 2.    ] \tgroup: None \tprior: None \tpreset: None \tdefault: None \tmodel: None \t_definition_changed: False</code> <code>param_type1_noise_heteroscedastic</code> <code>Parameter</code> <p>Signal-dependent type 1 noise. Specify the signal dependency via the <code>.model</code> attribute of the  parameter. Default is <code>'multiplicative'</code>, which corresponds to Weber's law with a noise floor. In this case,  <code>type1_noise</code> is the noise floor and <code>type1_noise_heteroscedastic</code> is the signal scaling factor.</p> <code>Parameter \tenable: 0 \tguess: 0 \tbounds: (0, 10) \tgrid_range: [0.   0.25 0.5  0.75 1.  ] \tgroup: None \tprior: None \tpreset: None \tdefault: 0 \tmodel: multiplicative \t_definition_changed: False</code> <code>param_type2_noise</code> <code>Parameter</code> <p>Metacognitive noise. May characterize metacognitive noise of either a noisy-readout, noisy-report or  noisy-temperature model.</p> <code>Parameter \tenable: 1 \tguess: 0.1 \tbounds: (0.05, 2) \tgrid_range: [0.1        0.22857143 0.35714286 0.48571429 0.61428571 0.74285714  0.87142857 1.        ] \tgroup: None \tprior: None \tpreset: None \tdefault: 0.01 \tmodel: None \t_definition_changed: False</code> <code>param_type2_evidence_bias</code> <code>Parameter</code> <p>Parameter for a multiplicative metacognitive bias loading on evidence.</p> <code>Parameter \tenable: 0 \tguess: 1 \tbounds: (0.5, 2) \tgrid_range: [0.5        0.71428571 0.92857143 1.14285714 1.35714286 1.57142857  1.78571429 2.        ] \tgroup: None \tprior: None \tpreset: None \tdefault: 1 \tmodel: None \t_definition_changed: False</code> <code>param_type2_confidence_bias</code> <code>Parameter</code> <p>Parameter for a power-law metacognitive bias loading on confidence.</p> <code>Parameter \tenable: 0 \tguess: 1 \tbounds: (0.5, 2) \tgrid_range: [0.5        0.71428571 0.92857143 1.14285714 1.35714286 1.57142857  1.78571429 2.        ] \tgroup: None \tprior: None \tpreset: None \tdefault: 1 \tmodel: None \t_definition_changed: False</code> <code>param_type2_criteria</code> <code>Parameter</code> <p>Confidence criteria.</p> <code>Parameter \tenable: 3 \tguess: equispaced \tbounds: (1e-08, 1) \tgrid_range: equispaced \tgroup: None \tprior: None \tpreset: None \tdefault: equispaced \tmodel: None \t_definition_changed: False</code> <code>min_type1_like</code> <code>float</code> <p>Minimum probability used during the type 1 likelihood computation.</p> <code>1e-10</code> <code>min_type2_like</code> <code>float</code> <p>Minimum probability used during the type 2 likelihood computation.</p> <code>1e-10</code> <code>min_type2_like_uni</code> <code>bool</code> <p>Instead of using a minimum probability during the likelihood computation, use a maximum cumulative likelihood based on a uniform 'guessing' model. <code>min_type2_likelihood</code> is ignored in this case.</p> <code>False</code> <code>type2_binsize</code> <code>float</code> <p>Integration bin size for the computation of the likelihood around empirical confidence values. A setting of 0 means that the probability density is assesed instead.</p> <code>0.01</code> <code>type2_binsize_wrap</code> <code>bool</code> <p>Ensure constant window size for likelihood integration at the bounds. Only applies if confidence criteria are disabled and type2_binsize &gt; 0.</p> <code>False</code> <code>type1_marg_z</code> <code>int</code> <p>Number of standard deviations around the mean considered for the marginalization of type 1 uncertainty.</p> <code>5</code> <code>type1_marg_steps</code> <code>int</code> <p>Number of integration steps for the marginalization of type 1 uncertainty.</p> <code>101</code> <code>temperature_marg_res</code> <code>float</code> <p>Quintile resolution for the marginalization of type 1 noise in case of type2_noise_type 'temperature'.</p> <code>0.001</code> <code>type1_likel_incongr</code> <code>bool</code> <p>If <code>True</code>, include incongruent decision values (i.e., sign(actual choice) != sign(decision value)) for the type 2  likelihood computation.</p> <code>False</code> <code>true_params</code> <code>dict</code> <p>Pass true (known) parameter values. This can be useful for testing to compare the likelihood of true and fitted parameters. The likelihood of true parameters is returned (and printed).</p> <code>None</code> <code>initilialize_fitting_at_true_params</code> <code>bool</code> <p>If <code>True</code>, initialize the parameter fitting procedure at the true parameters. True parameters must  have been passed via <code>true_params</code>.</p> <code>False</code> <code>accept_mispecified_model</code> <code>bool</code> <p>If <code>True</code>, ignore warnings about user-specified settings.</p> <code>False</code> <code>print_configuration</code> <code>bool</code> <p>If True, print the configuration at instatiation of the ReMeta class (useful for logging).</p> <code>False</code> Source code in <code>remeta/configuration.py</code> <pre><code>@reset_dataclass_on_init\n@dataclass\nclass Configuration(ReprMixin):\n    \"\"\" Configuration for the ReMeta toolbox\n\n    Usage:\n        ```\n        cfg = remeta.configuration\n        cfg.&lt;some_setting&gt; = &lt;some_value&gt;\n        rem = remeta.ReMeta(cfg)\n        ```\n\n        To change parameters use:\n        ```\n        cfg.param_&lt;param_name&gt;.&lt;param_attribute&gt; = &lt;value&gt;\n        ```\n\n        See [`Parameter`][remeta.modelspec.Parameter] for more information.\n\n\n    \"\"\"\n\n    ### Important settings\n\n    normalize_stimuli_by_max: bool = field(default=False, metadata={'description': \"\"\" \n        If True, normalize provided stimuli by their maximum value to the range [-1; 1]. \n        Note that stimuli should be roughly in the range [-1; 1] for optimal parameter estimation.\"\"\"\n    })\n\n    type2_noise_type: str = field(default='report', metadata={'description': \"\"\" \n        Whether the model considers noise at readout, report or for the estimation of type 1 noise (\"temperature\").\n        Possible values: `'readout'`, `'report'`, `'temperature'`.\"\"\"\n    })\n\n    skip_type2: bool = field(default=False, metadata={'description': \"\"\" \n        If `True`, only fit type 1 data. No confidence data needs to be passed to `fit()` in this case.\"\"\"\n    })\n\n\n\n    ### Type 1 optimization\n\n    optim_type1_gridsearch: bool = field(default=False, metadata={'description': \"\"\" \n        If `True`, perform an initial gridsearch search for type 1 parameter optimization, based on the `grid_range`\n        attributes of Parameters.\"\"\"\n    })\n\n    # optim_type1_fine_gridsearch: bool = field(default=False, metadata={'description': \"\"\"\n    #     Perform a fine-grained grid search for type 1 parameter optimization.\"\"\"\n    # })\n\n    optim_type1_minimize_along_grid: bool = field(default=False, metadata={'description': \"\"\" \n        If `True`, do sqlqp minimization for type 1 parameter optimization at each grid point.\"\"\"\n    })\n\n    optim_type1_global_minimization: str = field(default=None, metadata={'description': \"\"\" \n        Use one of 'shgo', 'dual_annealing' 'differential_evolution' to perform type 1 likelihood minimization with\n        a global minimizer.\"\"\"\n    })\n\n    optim_type1_scipy_solvers: str | list[str] | tuple[str, ...] = field(default='trust-constr', metadata={'description': \"\"\" \n        Set scipy.optimize.minimize solver method for type 1 parameter optimization..\n        If provided as tuple/list, test different solvers and take the best.\"\"\"\n    })\n\n\n\n    ### Type 2 optimization\n\n    optim_type2_gridsearch: bool = field(default=False, metadata={'description': \"\"\" \n        If `True`, perform an initial gridsearch search for type 2 parameter optimization, based on the `grid_range`\n        attributes of Parameters.\"\"\"\n    })\n\n    # optim_type2_fine_gridsearch: bool = field(default=False, metadata={'description': \"\"\"\n    #     Perform a fine-grained grid search for type 2 parameter optimization.\"\"\"\n    # })\n\n    optim_type2_minimize_along_grid: bool = field(default=False, metadata={'description': \"\"\" \n        If `True`, do sqlqp minimization for type 2 parameter optimization at each grid point.\"\"\"\n    })\n\n    optim_type2_global_minimization: str = field(default=None, metadata={'description': \"\"\" \n        Use one of 'shgo', 'dual_annealing' 'differential_evolution' to perform type 2 likelihood minimization with\n        a global minimizer.\"\"\"\n    })\n\n    optim_type2_scipy_solvers: str | list[str] | tuple[str, ...] = field(default=('slsqp', 'Nelder-Mead'), metadata={'description': \"\"\" \n        Set scipy.optimize.minimize solver method for type 2 parameter optimization..\n        If provided as tuple/list, test different solvers and take the best.\"\"\"\n    })\n\n    optim_type2_slsqp_epsilon: float = field(default=None, metadata={'description': \"\"\" \n        Set parameter epsilon parameter for the SLSQP optimization method (type 2).\n        If provided as tuple/list, test different eps parameters and take the best\"\"\"\n    })\n\n    optim_num_cores: int = field(default=1, metadata={'description': \"\"\" \n        Number of cores used for parameter estimation (-1 for all cores minus 1).\"\"\"\n    })\n\n\n\n    ### Parameters\n\n    ## Type 1\n\n    param_type1_noise: Parameter = field(\n        default=Parameter(enable=1, guess=0.5, bounds=(0.001, 10), grid_range=np.linspace(0.1, 1, 8), default=0.01, model='normal'),\n        metadata={'description': \"\"\" \n        Type 1 noise.\"\"\"\n    })\n    param_type1_thresh: Parameter = field(\n        default=Parameter(enable=0, guess=0, bounds=(0, 1), grid_range=np.linspace(0, 0.2, 5), default=0),\n        metadata={'description': \"\"\" \n        Type 1 threshold.\"\"\"\n    })\n    param_type1_bias: Parameter = field(\n        default=Parameter(enable=1, guess=0, bounds=(-1, 1), grid_range=np.linspace(-0.2, 0.2, 8), default=0),\n        metadata={'description': \"\"\" \n        Type 1 bias.\"\"\"\n    })\n    param_type1_nonlinear_gain: Parameter = field(\n        default=Parameter(enable=0, guess=0, bounds=(-8 / 9, 10), grid_range=np.linspace(-0.5, 1, 5), default=0),\n        metadata={'description': \"\"\" \n        Gain parameter for nonlinear encoding (higher values -&gt; stronger nonlinearity).\"\"\"\n    })\n    param_type1_nonlinear_scale: Parameter = field(\n        default=Parameter(enable=0, guess=1, bounds=(0.01, 10), grid_range=np.linspace(0.01, 2, 5), default=None),\n        metadata={'description': \"\"\" \n        Scale parameter for the nonlinearity (higher values -&gt; non-linearity kicks in later).\"\"\"\n    })\n    param_type1_noise_heteroscedastic: Parameter = field(\n        default=Parameter(enable=0, guess=0, bounds=(0, 10), grid_range=np.linspace(0, 1, 5), model='multiplicative', default=0),\n        metadata={'description': \"\"\" \n        Signal-dependent type 1 noise. Specify the signal dependency via the `.model` attribute of the \n        parameter. Default is `'multiplicative'`, which corresponds to Weber's law with a noise floor. In this case, \n        `type1_noise` is the noise floor and `type1_noise_heteroscedastic` is the signal scaling factor.\"\"\"\n    })\n\n\n    ## Type 2\n\n    param_type2_noise: Parameter = field(\n        default=Parameter(enable=1, guess=0.1, bounds=(0.05, 2), grid_range=np.linspace(0.1, 1, 8), default=0.01),\n        metadata={'description': \"\"\" \n        Metacognitive noise. May characterize metacognitive noise of either a noisy-readout, noisy-report or \n        noisy-temperature model.\"\"\"\n    })\n    param_type2_evidence_bias: Parameter = field(\n        default=Parameter(enable=0, guess=1, bounds=(0.5, 2), grid_range=np.linspace(0.5, 2, 8), default=1),\n        metadata={'description': \"\"\" \n        Parameter for a multiplicative metacognitive bias loading on evidence.\"\"\"\n    })\n    param_type2_confidence_bias: Parameter = field(\n        default=Parameter(enable=0, guess=1, bounds=(0.5, 2), grid_range=np.linspace(0.5, 2, 8), default=1),\n        metadata={'description': \"\"\" \n        Parameter for a power-law metacognitive bias loading on confidence.\"\"\"\n    })\n    param_type2_criteria: Parameter = field(\n        default=Parameter(enable=3, guess='equispaced', grid_range='equispaced', default='equispaced', bounds=(1e-8, 1)),\n        metadata={'description': \"\"\" \n        Confidence criteria.\"\"\"\n    })\n\n\n    ### Likelihood computation\n\n    min_type1_like: float = field(default=1e-10, metadata={'description': \"\"\" \n        Minimum probability used during the type 1 likelihood computation.\"\"\"\n                                                           })\n\n    min_type2_like: float = field(default=1e-10, metadata={'description': \"\"\" \n        Minimum probability used during the type 2 likelihood computation.\"\"\"\n                                                           })\n\n    min_type2_like_uni: bool =  field(default=False, metadata={'description': \"\"\" \n        Instead of using a minimum probability during the likelihood computation, use a maximum cumulative\n        likelihood based on a uniform 'guessing' model. `min_type2_likelihood` is ignored in this case.\"\"\"\n                                                               })\n\n    type2_binsize: float = field(default=0.01, metadata={'description': \"\"\" \n        Integration bin size for the computation of the likelihood around empirical confidence values.\n        A setting of 0 means that the probability density is assesed instead.\"\"\"\n    })\n\n    type2_binsize_wrap: bool = field(default=False, metadata={'description': \"\"\" \n        Ensure constant window size for likelihood integration at the bounds.\n        Only applies if confidence criteria are disabled and type2_binsize &gt; 0.\"\"\"\n    })\n\n    type1_marg_z: int = field(default=5, metadata={'description': \"\"\" \n        Number of standard deviations around the mean considered for the marginalization of type 1 uncertainty.\"\"\"\n    })\n\n    type1_marg_steps: int = field(default=101, metadata={'description': \"\"\" \n        Number of integration steps for the marginalization of type 1 uncertainty.\"\"\"\n    })\n\n    temperature_marg_res: float = field(default=0.001, metadata={'description': \"\"\" \n        Quintile resolution for the marginalization of type 1 noise in case of type2_noise_type 'temperature'.\"\"\"\n    })\n\n    type1_likel_incongr: bool = field(default=False, metadata={'description': \"\"\" \n        If `True`, include incongruent decision values (i.e., sign(actual choice) != sign(decision value)) for the type 2 \n        likelihood computation.\"\"\"\n    })\n\n\n    ### Useful for testing\n\n    true_params: dict = field(default=None, metadata={'description': \"\"\" \n        Pass true (known) parameter values. This can be useful for testing to compare the likelihood of true and\n        fitted parameters. The likelihood of true parameters is returned (and printed).\"\"\"\n    })\n\n    initilialize_fitting_at_true_params: bool = field(default=False, metadata={'description': \"\"\" \n        If `True`, initialize the parameter fitting procedure at the true parameters. True parameters must \n        have been passed via `true_params`.\"\"\"\n    })\n\n    accept_mispecified_model: bool = field(default=False, metadata={'description': \"\"\" \n        If `True`, ignore warnings about user-specified settings.\"\"\"\n    })\n\n    print_configuration: bool = field(default=False, metadata={'description': \"\"\" \n        If True, print the configuration at instatiation of the ReMeta class (useful for logging).\"\"\"\n    })\n\n\n    ### Private attributes (do not change)\n\n    _param_type1_noise: Parameter | list[Parameter] = None\n    _param_type1_noise_heteroscedastic: Parameter | list[Parameter] = None\n    _param_type1_nonlinear_scale: Parameter | list[Parameter] = None\n    _param_type1_nonlinear_gain: Parameter | list[Parameter] = None\n    _param_type1_thresh: Parameter | list[Parameter] = None\n    _param_type1_bias: Parameter | list[Parameter] = None\n    _param_type2_noise: Parameter = None\n    _param_type2_evidence_bias: Parameter = None\n    _param_type2_confidence_bias: list[Parameter] = None\n    _param_type2_criteria: list[Parameter] = None\n\n    _paramset_type1: ParameterSet = None\n    _paramset_type2: ParameterSet = None\n    _paramset: ParameterSet = None\n\n    _n_conf_levels: int = None\n\n    _optim_num_cores: int = None\n\n    _fields: set = None\n\n\n    def __post_init__(self):\n        # Define allowed fields\n        self._fields = {f.name for f in fields(self)}\n\n\n    def __setattr__(self, key, value):\n        if self._fields is not None and key not in self._fields:\n            raise AttributeError(f\"'{type(self).__name__}' object has no attribute '{key}'\")\n        # Call the base class setattr to actually set the value\n        super().__setattr__(key, value)\n\n\n    def setup(self, generative_mode=False, silence_warnings=False):\n\n        if (self.optim_num_cores &gt; 1) and find_spec('multiprocessing_on_dill') is None:\n            if not silence_warnings:\n                warnings.warn(f'Multiprocessing on dill is not installed. Setting optim_num_cores to 1.')\n            self.optim_num_cores = 1\n\n        if self.optim_num_cores &gt; 1:\n            from multiprocessing import cpu_count\n            self._optim_num_cores = max(1, (cpu_count() or 1) - 1) if self.optim_num_cores == -1 \\\n                else self.optim_num_cores\n        else:\n            self._optim_num_cores = 1\n\n        self._prepare_params_type1()\n        if self.skip_type2:\n            if self.optim_type2_slsqp_epsilon is None:\n                self.optim_type2_slsqp_epsilon = 1e-5\n        else:\n\n            if self.param_type1_thresh.enable and \\\n                (self.optim_type1_scipy_solvers == self.__dataclass_fields__['optim_type1_scipy_solvers'].default):\n                self.optim_type1_scipy_solvers = ('trust-constr', 'Powell')\n\n\n            if self.param_type2_noise.model is None:\n                if self.type2_noise_type == 'report':\n                    if (self.param_type2_criteria.enable):\n                        self.param_type2_noise.model = 'beta_mode'\n                    else:\n                        self.param_type2_noise.model = 'truncated_normal_mode'\n                elif (self.type2_noise_type == 'readout'):\n                    if self.param_type2_criteria.enable:\n                        self.param_type2_noise.model = 'lognormal_mode_std'\n                    else:\n                        self.param_type2_noise.model = 'truncated_normal_mode'\n                elif self.type2_noise_type == 'temperature':\n                    if self.param_type2_criteria.enable:\n                        self.param_type2_noise.model = 'lognormal_mode_std'\n                    else:\n                        self.param_type2_noise.model = 'truncated_normal_mode'\n\n                # if generative_mode and not silence_warnings:\n                #         warnings.warn('In generative mode, you should to explicitly specify a type 2 noise distribution. '\n                #                       f'Defaulting to \"{self.param_type2_noise.model}\"')\n\n            self._prepare_params_type2()\n            if self.optim_type2_slsqp_epsilon is None:\n                self.optim_type2_slsqp_epsilon = 1e-5\n\n            if self.type2_binsize is None:\n                self.type2_binsize = 0.01\n\n        self._prepare_params_all()\n\n        self._check_compatibility(generative_mode=generative_mode, silence_warnings=silence_warnings)\n\n        if self.print_configuration:\n            self.print()\n        # self.setup_called = True\n\n    def _check_compatibility(self, generative_mode=False, silence_warnings=False):\n\n        if not self.accept_mispecified_model:\n\n            if not self.param_type1_noise.enable:\n                raise ValueError(\"Type 1 noise must be enabled.\")\n\n            if not self.skip_type2:\n\n                if self.param_type2_criteria.enable and self.param_type2_criteria.group is not None:\n                    if not silence_warnings:\n                        warnings.warn('It is not recommended to fit criteria as a random effect or a fixed group effect, '\n                                      'for conceptual reasons, but also because standard errors are not reliable.')\n\n                if not self.param_type2_noise.enable:\n                    if not silence_warnings:\n                        warnings.warn(f'Setting type2_param_noise.enable=False was provided -&gt; type2_param_noise is set to its default value '\n                                      f'({self._type2_param_noise_default}). You may change this value via the configuration.')\n\n                if (self.type2_noise_type == 'temperature') and self.param_type2_noise._definition_changed and \\\n                    (self.param_type2_noise.bounds[0] &lt; 1e-5):\n                    if not silence_warnings:\n                        warnings.warn('You manually changed the lower bound of the type 2 noise parameter for a '\n                                      'noisy-temperature model to a very low value (&lt;1e-5). Be warned that this may result '\n                                      'in numerical instabilities that severely distort the likelihood computation.')\n\n                if not generative_mode:\n                    # If the configuration instance is used for generating data, we should not complain\n                    # about fitting issues.\n\n                    if self.param_type2_criteria.enable and self.param_type2_evidence_bias.enable:\n                        if not silence_warnings:\n                            warnings.warn(\n                                'Fitting type2_param_criteria in combination with type2_param_evidence_bias.enable=1\\n'\n                                'can lead to biased parameter inferences. Use with caution.')\n\n    def _prepare_params_type1(self):\n        # if self.paramset_type1 is None:\n\n            param_names_type1 = []\n            params_type1 = ('noise', 'noise_heteroscedastic', 'nonlinear_gain', 'nonlinear_scale', 'thresh', 'bias')\n            for param in params_type1:\n                if getattr(self, f'param_type1_{param}').enable:\n                    param_names_type1 += [f'type1_{param}']\n                    # if getattr(self, f'_param_type1_{param}') is None:\n                    param_definition = getattr(self, f'param_type1_{param}')\n                    if getattr(self, f'param_type1_{param}').enable == 2:\n                        setattr(self, f'_param_type1_{param}', [param_definition, param_definition])\n                    else:\n                        setattr(self, f'_param_type1_{param}', param_definition)\n                    if self.true_params is not None and self.initilialize_fitting_at_true_params and f'type1_{param}' in self.true_params:\n                        if (param_len := getattr(self, f'param_type1_{param}').enable) &gt; 1:\n                            for i in range(param_len):\n                                getattr(self, f'_param_type1_{param}')[i].guess = self.true_params[f'type1_{param}'][i]\n                        else:\n                            getattr(self, f'_param_type1_{param}').guess = self.true_params[f'type1_{param}']\n\n            parameters = {k: getattr(self, f\"_param_{k}\") for k in param_names_type1}\n            self._paramset_type1 = ParameterSet(parameters, param_names_type1)\n\n    def _prepare_params_type2(self):\n\n        if self.param_type2_noise.enable and self._param_type2_noise is None and not self.param_type2_noise._definition_changed:\n\n            lb = 0.05\n            self.param_type2_noise.bounds = dict(\n                report = dict(\n                    beta_mean_std=(lb, 0.5),\n                    beta_mode_std=(lb, 1 / np.sqrt(12)),\n                    truncated_normal_mode_std=(lb, 1 / np.sqrt(12)),\n                    truncated_gumbel_mode_std=(lb, 1 / np.sqrt(12)),\n                    truncated_lognormal_mode_std=(lb, 1 / np.sqrt(12)),\n                    beta_mode=(lb, 1),\n                    truncated_normal_mode=(lb, 1),\n                    truncated_gumbel_mode=(lb, 1),\n                    truncated_lognormal_mode=(lb, 4),\n                    truncated_lognormal_mean=(lb, 4),\n                    truncated_lognorm=(lb, 4)\n                ),\n                readout = dict(\n                    lognormal_mean=(lb, 1),\n                    lognormal_mode=(lb, 1),\n                    gamma_mean_std=(lb, 1),\n                    lognormal_mean_std=(lb, 2),\n                    lognormal_mode_std=(lb, 2),\n                    lognormal_median_std=(lb, 2),\n                    gamma_mean_cv=(lb, 2),\n                    gamma_mean=(lb, 2),\n                    gamma_mode_std=(lb, 2),\n                    gamma_mode=(lb, 2),\n                    betaprime_mean_std=(lb, 2),\n                    truncated_normal_mode_std=(lb, 2),\n                    truncated_normal_mode=(lb, 2),\n                    truncated_gumbel_mode_std=(lb, 2),\n                    truncated_gumbel_mode=(lb, 2)\n                ),\n                temperature = dict(\n                    lognormal_mean=(lb, 1),\n                    gamma_mean_std=(lb, 1),\n                    lognormal_mean_std=(lb, 2),\n                    lognormal_median_std=(lb, 2),\n                    gamma_mean_cv=(lb, 2),\n                    gamma_mean=(lb, 2),\n                    gamma_mode_std=(lb, 2),\n                    gamma_mode=(lb, 2),\n                    betaprime_mean_std=(lb, 2),\n                    truncated_normal_mode_std=(lb, 2),\n                    truncated_normal_mode=(lb, 2),\n                    truncated_gumbel_mode_std=(lb, 2),\n                    truncated_gumbel_mode=(lb, 2),\n                    lognormal_mode=(lb, 4),\n                    lognormal_mode_std=(lb, 10),\n                )\n            )[self.type2_noise_type][self.param_type2_noise.model]\n            self.param_type2_noise.grid_range = np.exp(np.linspace(np.log(self.param_type2_noise.bounds[0]),\n                                                                   np.log(self.param_type2_noise.bounds[1]), 10)[1:-1])\n\n        param_names_type2 = []\n        params_type2 = ('noise', 'evidence_bias', 'confidence_bias')\n        for param in params_type2:\n            if getattr(self, f'param_type2_{param}').enable:\n                param_names_type2 += [f'type2_{param}']\n                # if getattr(self, f'_param_type2_{param}') is None:\n                param_definition = getattr(self, f'param_type2_{param}')\n                setattr(self, f'_param_type2_{param}', param_definition.copy())\n                if self.true_params is not None and self.initilialize_fitting_at_true_params and f'type2_{param}' in self.true_params:\n                    getattr(self, f'_param_type2_{param}').guess = self.true_params[f'type2_{param}']\n\n\n        if self.param_type2_criteria.preset is not None:\n            self.param_type2_criteria.enable = 0\n            if listlike(self.param_type2_criteria.preset):\n                self._n_conf_levels = len(self.param_type2_criteria.preset) + 1\n            elif isinstance(self.param_type2_criteria.preset, int):\n                self._n_conf_levels = self.param_type2_criteria.preset + 1\n                self.param_type2_criteria.preset = np.arange(1/self._n_conf_levels, 1-1e-10, 1/self._n_conf_levels)\n            else:\n                raise ValueError('param_type2_criteria.preset must either be a list of criteria or '\n                                 'an integer indicating the number of (equispaced) criteria.')\n\n\n        if self.param_type2_criteria.enable:\n            self._n_conf_levels = self.param_type2_criteria.enable + 1\n            param_names_type2 += [f'type2_criteria']\n            initialize_true = (self.initilialize_fitting_at_true_params and\n                               self.true_params is not None and 'type2_criteria' in self.true_params)\n\n            # internally, we handle criteria as criterion gaps!\n            setattr(self, f'_param_type2_criteria',\n                    [Parameter(\n                       guess=self.true_params['type2_criteria'][i] if initialize_true\n                                else (1 / self._n_conf_levels if self.param_type2_criteria.guess == 'equispaced'\n                                      else self.param_type2_criteria_guesses[i]),\n                       bounds=self.param_type2_criteria.bounds,\n                       grid_range=np.linspace(0.05, 2 / self._n_conf_levels, 4) if\n                       self.param_type2_criteria.grid_range == 'equispaced' else self.param_type2_criteria_grid_ranges[i],\n                       default=1/self._n_conf_levels if self.param_type2_criteria.default == 'equispaced' else self.param_type2_criteria_default,\n                    )\n                     for i in range(self._n_conf_levels - 1)]\n                    )\n            if self.true_params is not None:\n                if isinstance(self.true_params, dict):\n                    # if 'type2_criteria' not in self.true_params:\n                    #     raise ValueError('type2_criteria are missing from cfg.true_params')\n                    if 'type2_criteria' in self.true_params:\n                        self.true_params.update(\n                            # type2_criteria_absolute=[np.sum(self.true_params['type2_criteria'][:i+1]) for i in range(len(self.true_params['type2_criteria']))],\n                            type2_criteria_bias=np.mean(self.true_params['type2_criteria']) - 0.5,\n                            type2_criteria_bias_sem=0,\n                            type2_criteria_confidence_bias=0.5 - np.mean(self.true_params['type2_criteria']),\n                            # type2_criteria_bias_mult=np.mean(self.true_params['type2_criteria']) / 0.5,\n                            # type2_criteria_confidence_bias_mult=np.mean(self.true_params['type2_criteria']) / 0.5,\n                            # type2_criteria_absdev=round(np.abs(np.array(self.true_params['type2_criteria']) -\n                            #         np.arange(1/self._n_conf_levels, 1-1e-10, 1/self._n_conf_levels)).mean(), 10)\n                        )\n                elif isinstance(self.true_params, list):\n                    for s in range(len(self.true_params)):\n                        # if 'type2_criteria' not in self.true_params[s]:\n                        #     raise ValueError(f'type2_criteria are missing from cfg.true_params (subject {s})')\n                        if 'type2_criteria' in self.true_params[s]:\n                            self.true_params[s].update(\n                                # type2_criteria_absolute=[np.sum(self.true_params[s]['type2_criteria'][:i+1]) for i in range(len(self.true_params[s]['type2_criteria']))],\n                                type2_criteria_bias=np.mean(self.true_params[s]['type2_criteria']) - 0.5,\n                                type2_criteria_bias_sem=0,\n                                type2_criteria_confidence_bias=0.5 - np.mean(self.true_params[s]['type2_criteria']),\n                                # type2_criteria_absdev=round(np.abs(np.array(self.true_params[s]['type2_criteria']) -\n                                #     np.arange(1/self._n_conf_levels, 1-1e-10, 1/self._n_conf_levels)).mean())\n                            )\n\n        parameters = {k: getattr(self, f\"_param_{k}\") for k in param_names_type2}\n        self._paramset_type2 = ParameterSet(parameters, param_names_type2)\n\n\n        self.check_type2_constraints()\n\n\n    def _prepare_params_all(self):\n\n        if self.skip_type2:\n            self._paramset = self._paramset_type1\n        else:\n            parameters_all = {**self._paramset_type1.parameters, **self._paramset_type2.parameters}\n            param_names_all = self._paramset_type1.param_names + self._paramset_type2.param_names\n            self._paramset = ParameterSet(parameters_all, param_names_all)\n            # for k, attr in self.paramset_type2.__dict__.items():\n            #     attr_old = getattr(self.paramset, k)\n            #     if isinstance(attr, list):\n            #         attr_new = attr_old + attr\n            #     elif isinstance(attr, dict):\n            #         attr_new = {**attr_old, **attr}\n            #     elif isinstance(attr, np.ndarray):\n            #         if attr.ndim == 1:\n            #             attr_new = np.hstack((attr_old, attr))\n            #         else:\n            #             attr_new = np.vstack((attr_old, attr))\n            #     elif isinstance(attr, int):\n            #         attr_new = attr_old + attr\n            #     elif attr is None:\n            #         if attr_old is None:\n            #             attr_new = None\n            #         else:\n            #             raise ValueError(f'Type 2 attribute is None, but type 1 attribute is not.')\n            #     else:\n            #         raise ValueError(f'Unexpected type {type(attr)}')\n            #     setattr(self.paramset, k, attr_new)\n\n\n\n\n    def print(self):\n        # print('***********************')\n        print(f'{self.__class__.__name__}')\n        for k, v in self.__dict__.items():\n            # if not self.skip_type2 or ('type2' not in k):\n            print('\\n'.join([f'\\t{k}: {v}']))\n        # print('***********************')\n\n    def __repr__(self):\n        txt = f'{self.__class__.__name__}\\n'\n        txt += '\\n'.join([f'\\t{k}: {v}' for k, v in self.__dict__.items()])\n        return txt\n\n    def check_type2_constraints(self):\n        pass\n</code></pre>"},{"location":"model/","title":"remeta.model.ReMeta","text":""},{"location":"model/#remeta","title":"ReMeta","text":"Usage <pre><code>rem = remeta.ReMeta()\n</code></pre> <p>for a default model, or otherwise:</p> <pre><code>cfg = remeta.Configuration()\ncfg.&lt;some_setting&gt; = &lt;some_value&gt;\nrem = remeta.ReMeta(cfg)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>cfg</code> <code>Configuration</code> <p>Configuration object. If None is passed, the default configuration (but see kwargs).</p> <code>None</code> <code>**kwargs</code> <p>kwargs entries are passed to the Configuration</p> <code>{}</code> Source code in <code>remeta/model.py</code> <pre><code>def __init__(\n    self,\n    cfg: Configuration = None,\n    **kwargs\n):\n    \"\"\"\n\n    Usage:\n        ```\n        rem = remeta.ReMeta()\n        ```\n\n        for a default model, or otherwise:\n\n        ```\n        cfg = remeta.Configuration()\n        cfg.&lt;some_setting&gt; = &lt;some_value&gt;\n        rem = remeta.ReMeta(cfg)\n        ```\n\n    Args:\n        cfg: Configuration object. If None is passed, the default configuration (but see kwargs).\n        **kwargs: kwargs entries are passed to the Configuration\n\n    \"\"\"\n\n    if cfg is None:\n        # Set configuration attributes that match keyword arguments\n        cfg_kwargs = {k: v for k, v in kwargs.items() if k in Configuration.__dict__}\n        self.cfg = Configuration(**cfg_kwargs)\n    else:\n        self.cfg = cfg\n        for k, v in kwargs.items():\n            if k in Configuration.__dict__:\n                setattr(self.cfg, k, v)\n    self.cfg.setup()\n\n    self.modeldata = ModelData(cfg=self.cfg)\n    self.data = None\n    self.result = None\n\n    self.type1_is_fitted = False\n    self.type2_is_fitted = False\n</code></pre>"},{"location":"model/#fit","title":".fit()","text":"Usage <pre><code>rem = ReMeta()\nrem.fit(stimuli, choices, confidence)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>stimuli</code> <code>list[float] | list[list[float]] | NDArray[float]</code> <p>1d or 2d array or list of signed stimulus intensities</p> required <code>choices</code> <code>list[float] | list[list[float]] | NDArray[float]</code> <p>1d or 2d array or list of choices (coded as -1/1 or 0/1)</p> required <code>confidence</code> <code>list[float] | list[list[float]] | NDArray[float]</code> <p>1d or 2d array or list of confidence ratings (normalized to the range 0-1)</p> <code>None</code> <code>verbosity</code> <code>int</code> <p>verbosity level (possible values: 0, 1, 2)</p> <code>1</code> <code>silence_warnings</code> <code>bool</code> <p>if <code>True</code>, warnings during model fitting are supressed.</p> <code>False</code> Source code in <code>remeta/model.py</code> <pre><code>def fit(\n    self,\n    stimuli: list[float] | list[list[float]]  | np.typing.NDArray[float],\n    choices: list[float] | list[list[float]]  | np.typing.NDArray[float],\n    confidence: list[float] | list[list[float]]  | np.typing.NDArray[float] = None,\n    verbosity: int = 1,\n    silence_warnings: bool = False\n):\n    \"\"\"\n\n    Usage:\n        ```\n        rem = ReMeta()\n        rem.fit(stimuli, choices, confidence)\n        ```\n\n    Args:\n        stimuli: 1d or 2d array or list of signed stimulus intensities\n        choices: 1d or 2d array or list of choices (coded as -1/1 or 0/1)\n        confidence: 1d or 2d array or list of confidence ratings (normalized to the range 0-1)\n        verbosity: verbosity level (possible values: 0, 1, 2)\n        silence_warnings: if `True`, warnings during model fitting are supressed.\n    \"\"\"\n\n    self.data = Data(self.cfg, stimuli, choices, confidence)\n\n    self.result = Summary(self.data, self.cfg)\n\n    self.fit_type1(verbosity=verbosity, store_final_results=self.cfg.skip_type2, silence_warnings=silence_warnings)\n\n    if not self.cfg.skip_type2:\n        self.fit_type2(verbosity=verbosity, silence_warnings=silence_warnings)\n</code></pre>"},{"location":"model/#fit_type1","title":".fit_type1()","text":"Usage <pre><code>rem = ReMeta()\nrem.fit_type1(stimuli, choices)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>stimuli</code> <code>None | list[float] | list[list[float]] | NDArray[float]</code> <p>1d or 2d array or list of signed stimulus intensities</p> <code>None</code> <code>choices</code> <code>None | list[float] | list[list[float]] | NDArray[float]</code> <p>1d or 2d array or list of choices (coded as -1/1 or 0/1)</p> <code>None</code> <code>confidence</code> <code>None | list[float] | list[list[float]] | NDArray[float]</code> <p>1d or 2d array or list of confidence ratings (normalized to the range 0-1)</p> <code>None</code> <code>store_final_results</code> <code>bool</code> <p>if <code>True</code>, save final results. Mostly used internally - will be set to <code>False</code>, if followed by <code>fit_type2</code>.</p> <code>True</code> <code>verbosity</code> <code>int</code> <p>verbosity level (possible values: 0, 1, 2)</p> <code>1</code> <code>silence_warnings</code> <code>bool</code> <p>if <code>True</code>, warnings during model fitting are supressed.</p> <code>False</code> Source code in <code>remeta/model.py</code> <pre><code>def fit_type1(\n    self,\n    stimuli: None | list[float] | list[list[float]]  | np.typing.NDArray[float] = None,\n    choices: None | list[float] | list[list[float]]  | np.typing.NDArray[float] = None,\n    confidence: None | list[float] | list[list[float]]  | np.typing.NDArray[float] = None,\n    store_final_results: bool = True,\n    verbosity: int = 1,\n    silence_warnings: bool = False\n):\n    \"\"\"\n\n    Usage:\n        ```\n        rem = ReMeta()\n        rem.fit_type1(stimuli, choices)\n        ```\n\n    Args:\n        stimuli: 1d or 2d array or list of signed stimulus intensities\n        choices: 1d or 2d array or list of choices (coded as -1/1 or 0/1)\n        confidence: 1d or 2d array or list of confidence ratings (normalized to the range 0-1)\n        store_final_results: if `True`, save final results. Mostly used internally - will be set to `False`,\n            if followed by `fit_type2`.\n        verbosity: verbosity level (possible values: 0, 1, 2)\n        silence_warnings: if `True`, warnings during model fitting are supressed.\n    \"\"\"\n\n    if self.data is None:\n        if stimuli is None or choices is None:\n            raise ValueError('If the data attribute of the ReMeta instance is None, at least stimuli '\n                             'and choices have to be passed to fits_type1_subject()')\n        else:\n            self.data = Data(self.cfg, stimuli, choices, confidence)\n\n    if verbosity &gt;= 1:\n        print(f'Dataset characteristics:')\n        print(f'{TAB}No. subjects: {self.data.nsubjects}')\n        print(f\"{TAB}No. samples: {np.array2string(np.array(self.data.nsamples).squeeze(), separator=', ', threshold=3)}\")\n        print(f'{TAB}Accuracy: {100*self.data.stats.accuracy:.1f}% correct')\n        print(f\"{TAB}d': {self.data.stats.dprime:.3f}\")\n        print(f\"{TAB}Choice bias: {100*self.data.stats.choice_bias:.1f}%\")\n        if not self.cfg.skip_type2 and not store_final_results:\n            print(f\"{TAB}Mean confidence: {self.data.stats.mean_confidence:.3f} \"\n                  f\"(min: {np.min(self.data.c_conf):.3f}, max: {np.max(self.data.c_conf):.3f})\")\n\n    self.result = Summary(self.data, self.cfg)\n\n    if verbosity:\n        print('\\n+++ Type 1 level +++')\n    with warnings.catch_warnings():\n        warnings.filterwarnings('ignore', category=UserWarning, module='scipy.optimize',\n                                message='delta_grad == 0.0. Check if the approximated function is linear. If the '\n                                        'function is linear better results can be obtained by defining the Hessian '\n                                        'as zero instead of using quasi-Newton approximations.')\n\n        fits_type1_subject, fit_type1_group = None, None\n        if self.cfg._paramset_type1.nparams &gt; 0:\n\n            if verbosity:\n                print(f'{SP2}Subject-level estimation (MLE)')\n                tind = timeit.default_timer()\n\n            # Single-subject fits via MLE\n            use_multiproc_for_subject_loop = (self.cfg._optim_num_cores &gt;= 8) and (self.data.nsubjects &gt;= 8)\n            def subject_loop(s):\n                return subject_estimation(\n                    self.compute_type1_negll, self.cfg._paramset_type1, args=[s],\n                    gridsearch=self.cfg.optim_type1_gridsearch,\n                    scipy_solvers=self.cfg.optim_type1_scipy_solvers,\n                    num_cores=1 if use_multiproc_for_subject_loop else self.cfg._optim_num_cores,\n                    minimize_along_grid=self.cfg.optim_type1_minimize_along_grid,\n                    global_minimization=self.cfg.optim_type1_global_minimization,\n                    # fine_gridsearch=self.cfg.optim_type1_fine_gridsearch,\n                    verbosity=verbosity\n                )\n            if use_multiproc_for_subject_loop:\n                with DillPool(self.cfg._optim_num_cores) as pool:\n                    fits_type1_subject = pool.map(subject_loop, range(self.data.nsubjects))\n            else:\n                fits_type1_subject = [None for _ in range(self.data.nsubjects)]\n                for s in range(self.data.nsubjects):\n                    if (verbosity &gt; 0) and (self.data.nsubjects &gt; 1):\n                        print(f'{TAB} Subject {s + 1} / {self.data.nsubjects}')\n                    fits_type1_subject[s] = subject_loop(s)\n            # Store single-subject results\n            params_subject = [fits_type1_subject[s].x for s in range(self.data.nsubjects)]\n            params_hessian_subject = [fits_type1_subject[s].hessian for s in range(self.data.nsubjects)]\n            self.result.type1.subject.store(\n                'type1', self.cfg, self.data, self.compute_type1_negll, params_subject,\n                hessian=params_hessian_subject, fit=fits_type1_subject,\n                execution_time=np.sum([fits_type1_subject[s].execution_time for s in range(self.data.nsubjects)])\n            )\n\n            if verbosity:\n                print(f'{TAB}.. finished ({timeit.default_timer() - tind:.1f} secs).')\n\n            if self.data.nsubjects &gt; 1:\n                idx_fe = np.array([i for i, p in enumerate(self.cfg._paramset_type1.parameters_flat.values()) if p.group == 'fixed'])\n                idx_re = np.array([i for i, p in enumerate(self.cfg._paramset_type1.parameters_flat.values()) if p.group == 'random'])\n                if (len(idx_fe) &gt; 0) or (len(idx_re) &gt; 0):\n\n                    fit_type1_group = group_estimation(\n                        fun=self.compute_type1_negll,\n                        nsubjects=self.data.nsubjects,\n                        params_init=params_subject,\n                        bounds=self.cfg._paramset_type1.bounds,\n                        idx_fe=idx_fe,\n                        idx_re=idx_re,\n                        num_cores=self.cfg._optim_num_cores,\n                        max_iter=30, sigma_floor=1e-3,\n                        verbosity=verbosity,\n                        # tau=0.05\n                    )\n\n                    self.result.type1.init_group()\n                    self.result.type1.group.store(\n                        'type1', self.cfg, self.data, self.compute_type1_negll,\n                        params=[fit_type1_group.x[s] for s in range(self.data.nsubjects)],\n                        params_se=[fit_type1_group.x_se[s] for s in range(self.data.nsubjects)],\n                        params_cov=[fit_type1_group.x_cov[s] for s in range(self.data.nsubjects)],\n                        pop_mean_sd=fit_type1_group.x_re_pop_mean_sd,\n                        execution_time=fit_type1_group.execution_time\n                    )\n\n        self.result.type1.store(cfg=self.cfg, data=self.data, fun=self.compute_type1_negll)\n        if verbosity:\n            self.result.type1.report_fit(self.cfg)\n        self.type1_is_fitted = True\n\n    if store_final_results:\n        self.result.store(store_type1_only=True)\n\n    if verbosity:\n        print('Type 1 level finished')\n</code></pre>"},{"location":"model/#plot_psychometric","title":".plot_psychometric()","text":"<p>Invoke <code>remeta.plotting.plot_psychomtric</code> on the <code>ReMeta</code> instance.</p> Usage <pre><code>rem = ReMeta()\nrem.fit(stimuli, choices, confidence)\nrem.plot_psychometric()\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>sub_ind</code> <code>int</code> <p>subject index (only applicable if group data were fitted)</p> <code>0</code> <code>model_prediction</code> <code>bool</code> <p>if <code>True</code>, plot model predictions</p> <code>True</code> <code>**kwargs</code> <p>Pass parameters to <code>remeta.plotting.plot_psychomtric</code></p> <code>{}</code> Source code in <code>remeta/model.py</code> <pre><code>def plot_psychometric(\n    self,\n    sub_ind: int = 0,\n    model_prediction: bool = True,\n    **kwargs\n):\n    \"\"\"\n    Invoke `remeta.plotting.plot_psychomtric` on the `ReMeta` instance.\n\n    Usage:\n        ```\n        rem = ReMeta()\n        rem.fit(stimuli, choices, confidence)\n        rem.plot_psychometric()\n        ```\n\n    Args:\n        sub_ind: subject index (only applicable if group data were fitted)\n        model_prediction: if `True`, plot model predictions\n        **kwargs: Pass parameters to `remeta.plotting.plot_psychomtric`\n    \"\"\"\n\n    # self._check_fit()\n    plot_psychometric(\n        self.data.x_stim[sub_ind], self.data.d_dec[sub_ind],\n        params=self.result.params[sub_ind] if model_prediction else None,\n        cfg=self.cfg, **kwargs\n    )\n</code></pre>"},{"location":"model/#plot_stimulus_versus_confidence","title":".plot_stimulus_versus_confidence()","text":"<p>Invoke <code>remeta.plotting.plot_stimulus_versus_confidence</code> on the <code>ReMeta</code> instance.</p> Usage <pre><code>rem = ReMeta()\nrem.fit(stimuli, choices, confidence)\nrem.plot_stimulus_versus_confidence()\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>sub_ind</code> <code>int</code> <p>subject index (only applicable if group data were fitted)</p> <code>0</code> <code>model_prediction</code> <code>bool</code> <p>if <code>True</code>, plot model predictions</p> <code>True</code> <code>**kwargs</code> <p>Pass parameters to <code>remeta.plotting.plot_stimulus_versus_confidence</code></p> <code>{}</code> Source code in <code>remeta/model.py</code> <pre><code>def plot_stimulus_versus_confidence(\n    self,\n    sub_ind: int = 0,\n    model_prediction: bool = True,\n    **kwargs\n):\n    \"\"\"\n    Invoke `remeta.plotting.plot_stimulus_versus_confidence` on the `ReMeta` instance.\n\n    Usage:\n        ```\n        rem = ReMeta()\n        rem.fit(stimuli, choices, confidence)\n        rem.plot_stimulus_versus_confidence()\n        ```\n\n    Args:\n        sub_ind: subject index (only applicable if group data were fitted)\n        model_prediction: if `True`, plot model predictions\n        **kwargs: Pass parameters to `remeta.plotting.plot_stimulus_versus_confidence`\n    \"\"\"\n    # self._check_fit()\n    plot_stimulus_versus_confidence(\n        self.data.x_stim[sub_ind], self.data.c_conf[sub_ind],self.data.d_dec[sub_ind],\n        params=self.result.params[sub_ind] if model_prediction else None,\n        model_prediction=model_prediction,\n        cfg=self.cfg, **kwargs\n    )\n</code></pre>"},{"location":"model/#plot_confidence_histogram","title":".plot_confidence_histogram()","text":"<p>Invoke <code>remeta.plotting.plot_confidence_histogram</code> on the <code>ReMeta</code> instance.</p> Usage <pre><code>rem = ReMeta()\nrem.fit(stimuli, choices, confidence)\nrem.plot_confidence_histogram()\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>sub_ind</code> <code>int</code> <p>subject index (only applicable if group data were fitted)</p> <code>0</code> <code>model_prediction</code> <code>bool</code> <p>if <code>True</code>, plot model predictions</p> <code>True</code> <code>**kwargs</code> <p>Pass parameters to <code>remeta.plotting.plot_confidence_histogram</code></p> <code>{}</code> Source code in <code>remeta/model.py</code> <pre><code>def plot_confidence_histogram(\n    self,\n    sub_ind: int = 0,\n    model_prediction: bool = True,\n    **kwargs\n):\n    \"\"\"\n    Invoke `remeta.plotting.plot_confidence_histogram` on the `ReMeta` instance.\n\n    Usage:\n        ```\n        rem = ReMeta()\n        rem.fit(stimuli, choices, confidence)\n        rem.plot_confidence_histogram()\n        ```\n\n    Args:\n        sub_ind: subject index (only applicable if group data were fitted)\n        model_prediction: if `True`, plot model predictions\n        **kwargs: Pass parameters to `remeta.plotting.plot_confidence_histogram`\n    \"\"\"\n    # self._check_fit()\n    plot_confidence_histogram(\n        self.data.c_conf[sub_ind], self.data.x_stim[sub_ind], self.data.d_dec[sub_ind],\n        params=self.result.params[sub_ind] if model_prediction else None,\n        cfg=self.cfg, **kwargs\n    )\n</code></pre>"},{"location":"plot/","title":"remeta.plotting","text":""},{"location":"plot/#plot_psychometric","title":"plot_psychometric","text":"<p>Plot psychometric function.</p> Usage <p>Psychometric curve for empirical data:</p> <p><code>plot_psychometric(stimuli, choices)</code>  # Data only</p> <p><code>plot_psychometric(stimuli, choices, type1_noise, type1_bias, ...)</code>  # Data + model</p> <p><code>plot_psychometric(stimuli, choices, params=params)</code>  # Data + model</p> <p>Psychometric curve for a simulation instance: (<code>remeta.simulation.Simulation</code>):</p> <p><code>plot_psychometric(simulation)</code>  # (Simulated) Data</p> <p><code>plot_psychometric(simulation, model_prediction=True)</code>  # (Simulated) Data + model</p> <p>Model only:</p> <p><code>plot_psychometric(type1_noise=type1_noise, type1_bias=type1_bias, ...)</code>  # Model</p> <p><code>plot_psychometric(params)</code>  # Model</p> <p>Parameters:</p> Name Type Description Default <code>stimuli_or_simulation</code> <code>list[float] | NDArray[float] | Simulation | None</code> <p>1d stimulus array (normalized to [-1; 1]) or [Simulation][remeta.simulation.Simulation] object</p> <code>None</code> <code>choices</code> <code>list[float] | NDArray[float] | None</code> <p>1d choice array</p> <code>None</code> <code>type1_noise</code> <code>float | list[float] | None</code> <p>Type 1 noise.</p> <code>None</code> <code>type1_bias</code> <code>float | None</code> <p>Type 1 bias.</p> <code>None</code> <code>type1_thresh</code> <code>float | list[float] | None</code> <p>Type 1 threshold.</p> <code>None</code> <code>stim_max</code> <code>float | None</code> <p>maximum stimulus intensity.</p> <code>None</code> <code>params</code> <code>dict | None</code> <p>instead of passing parameters as separate parameters, one can pass a parameter dictionary</p> <code>None</code> <code>cfg</code> <code>Configuration | None</code> <p>If a Configuration instance is passed, checks are performed for  <code>cfg.param_type1_bias.enable</code> and <code>cfg.param_type1_thresh.enable</code> model_prediction: whether to show model-predicted values for comparison</p> <code>None</code> <code>model_only</code> <code>bool</code> <p>Show the model prediction only (auto-set to True if no data are passed)</p> <code>False</code> <code>highlight_fit</code> <code>bool</code> <p>Emphasize the fit over the data</p> <code>False</code> <code>errorbars</code> <code>bool</code> <p>Whether to include error bars for empirical data (SD)</p> <code>True</code> Source code in <code>remeta/plotting.py</code> <pre><code>def plot_psychometric(\n        stimuli_or_simulation: list[float] | np.typing.NDArray[float] | Simulation | None = None,\n        choices: list[float] | np.typing.NDArray[float] | None = None,\n        type1_noise: float | list[float] | None = None,\n        type1_bias: float | None = None,\n        type1_thresh: float | list[float] | None = None,\n        stim_max: float | None = None,\n        params: dict | None = None,\n        type1_noise_dist: str = 'normal',\n        cfg: Configuration | None = None,\n        model_prediction: bool = False,\n        model_only: bool = False,\n        highlight_fit: bool = False,\n        errorbars: bool = True,\n        path_export: str | None = None\n) -&gt; None:\n    \"\"\"Plot psychometric function.\n\n    Usage:\n        **Psychometric curve for empirical data:**\n\n        `plot_psychometric(stimuli, choices)`  # Data only\n\n        `plot_psychometric(stimuli, choices, type1_noise, type1_bias, ...)`  # Data + model\n\n        `plot_psychometric(stimuli, choices, params=params)`  # Data + model\n\n        **Psychometric curve for a simulation instance: (`remeta.simulation.Simulation`):**\n\n        `plot_psychometric(simulation)`  # (Simulated) Data\n\n        `plot_psychometric(simulation, model_prediction=True)`  # (Simulated) Data + model\n\n        **Model only:**\n\n        `plot_psychometric(type1_noise=type1_noise, type1_bias=type1_bias, ...)`  # Model\n\n        `plot_psychometric(params)`  # Model\n\n    Args:\n        stimuli_or_simulation: 1d stimulus array (normalized to [-1; 1]) or [Simulation][remeta.simulation.Simulation] object\n        choices: 1d choice array\n        type1_noise: Type 1 noise.\n        type1_bias: Type 1 bias.\n        type1_thresh: Type 1 threshold.\n        stim_max: maximum stimulus intensity.\n        params: instead of passing parameters as separate parameters, one can pass a parameter dictionary\n        cfg: If a [Configuration][remeta.configuration.Configuration] instance is passed, checks are performed for\n             `cfg.param_type1_bias.enable` and `cfg.param_type1_thresh.enable`\n         model_prediction: whether to show model-predicted values for comparison\n        model_only: Show the model prediction only (auto-set to True if no data are passed)\n        highlight_fit: Emphasize the fit over the data\n        errorbars: Whether to include error bars for empirical data (SD)\n    \"\"\"\n\n    if type1_noise is not None or params is not None:\n        model_prediction = True\n\n    if stimuli_or_simulation is not None and choices is None:  # assume a dataset is passed\n        cfg = stimuli_or_simulation.cfg\n        stimuli = stimuli_or_simulation.stimuli\n        choices = stimuli_or_simulation.choices\n        if model_prediction:\n            params = stimuli_or_simulation.params\n            type1_noise = params['type1_noise']\n            type1_bias = params['type1_bias'] if cfg.param_type1_bias.enable else None\n            type1_thresh = params['type1_thresh'] if cfg.param_type1_thresh.enable else None\n    else:\n        if choices is None:\n            model_only = True\n        stimuli = None if model_only else stimuli_or_simulation\n        if model_prediction:\n            if params is None:\n                if type1_noise is None:\n                    raise ValueError('Model predictions requested, but type 1 noise is unspecified.')\n                params = dict(type1_noise=type1_noise)\n            else:\n                type1_noise = params['type1_noise']\n                if 'type1_bias' in params and not (cfg is not None and not cfg.param_type1_bias.enable):\n                    type1_bias = params['type1_bias']\n                if 'type1_thresh' in params and not (cfg is not None and not cfg.param_type1_thresh.enable):\n                    type1_thresh = params['type1_thresh']\n\n    if stim_max is None:\n        stim_max = 1 if stimuli is None else np.max(np.abs(stimuli))\n\n    xrange_neg = np.linspace(-stim_max, 0, 1000)\n    xrange_pos = np.linspace(stim_max / 1000, stim_max, 1000)\n\n    if model_prediction:\n        type1_noise = _check_param(type1_noise)\n        if (cfg is None and type1_thresh is not None) or (cfg is not None and cfg.param_type1_thresh.enable):\n            params['type1_thresh'] = type1_thresh\n            type1_thresh = _check_param(type1_thresh)\n        else:\n            type1_thresh = [0, 0]\n\n        if (cfg is None and type1_bias is not None) or (cfg is not None and cfg.param_type1_bias.enable):\n            params['type1_bias'] = type1_bias\n            type1_bias = _check_param(type1_bias)\n        else:\n            type1_bias = [0, 0]\n\n        if cfg is not None:\n            type1_noise_dist = cfg.param_type1_noise.model\n        cdf = _logistic if type1_noise_dist == 'logistic' else _normal\n        posterior_neg = cdf(xrange_neg, type1_noise[0], type1_thresh[0], type1_bias[0])\n        posterior_pos = cdf(xrange_pos, type1_noise[1], type1_thresh[1], type1_bias[1])\n\n\n    fig = plt.figure(figsize=(6, 3.5))\n    fig.subplots_adjust(bottom=0.2)\n    gs = fig.add_gridspec(1, 2, width_ratios=[1, 0.5], wspace=0)\n    ax = fig.add_subplot(gs[0, 0])\n    ax_leg = fig.add_subplot(gs[0, 1])\n    ax_leg.axis(\"off\")\n    plt.sca(ax)\n\n\n    if not model_only:\n        stimulus_ids = (stimuli &gt; 0).astype(int)\n        levels = np.unique(stimuli)\n        choiceprob_neg = np.array([np.mean(choices[(stimuli == v) &amp; (stimulus_ids == 0)] ==\n                                           stimulus_ids[(stimuli == v) &amp; (stimulus_ids == 0)])\n                                   for v in levels[levels &lt; 0]])\n        choiceprob_pos = np.array([np.mean(choices[(stimuli == v) &amp; (stimulus_ids == 1)] ==\n                                           stimulus_ids[(stimuli == v) &amp; (stimulus_ids == 1)])\n                                   for v in levels[levels &gt; 0]])\n        if errorbars:\n            choiceprob_neg_se = np.array([sem(choices[(stimuli == v) &amp; (stimulus_ids == 0)] ==\n                                               stimulus_ids[(stimuli == v) &amp; (stimulus_ids == 0)])\n                                       for v in levels[levels &lt; 0]])\n            choiceprob_pos_se = np.array([sem(choices[(stimuli == v) &amp; (stimulus_ids == 1)] ==\n                                               stimulus_ids[(stimuli == v) &amp; (stimulus_ids == 1)])\n                                       for v in levels[levels &gt; 0]])\n        else:\n            choiceprob_neg_se, choiceprob_pos_se = np.nan, np.nan\n        plt.errorbar(levels[levels &lt; 0], 1-choiceprob_neg, yerr=choiceprob_neg_se, fmt='o', color=color_data, mec='k', ls='' if model_prediction else '-',\n                     label=f'Data $S^-$ (mean{[\"\", \"\u00b1SE\"][int(errorbars)]})', clip_on=False, zorder=11, alpha=(1, 0.2)[highlight_fit])\n        if not model_prediction:\n            plt.plot([levels[levels &lt; 0][-1], levels[levels &gt; 0][0]], [1-choiceprob_neg[-1], choiceprob_pos[0]], color=color_data)\n        plt.errorbar(levels[levels &gt; 0], choiceprob_pos, yerr=choiceprob_pos_se, fmt='s', color=color_data, mec='k', ls='' if model_prediction else '-',\n                     label=f'Data $S^+$ (mean{[\"\", \"\u00b1SE\"][int(errorbars)]})', clip_on=False, zorder=11, alpha=(1, 0.2)[highlight_fit])\n\n    if model_prediction:\n        plt.plot(xrange_neg, posterior_neg, '-', lw=(2, 5)[highlight_fit], color=color_model, clip_on=False,\n                 zorder=(10, 12)[highlight_fit], label=f'Model')\n        plt.plot(xrange_pos, posterior_pos, '-', lw=(2, 5)[highlight_fit], color=color_model, clip_on=False,\n                 zorder=(10, 12)[highlight_fit])\n\n    plt.plot([-stim_max, stim_max], [0.5, 0.5], 'k-', lw=0.5)\n    plt.plot([0, 0], [-0.02, 1.02], 'k-', lw=0.5)\n\n    ax.yaxis.grid('on', color=[0.9, 0.9, 0.9])\n    plt.xlim((-stim_max, stim_max))\n    plt.ylim((0, 1))\n    plt.xlabel('Stimulus ($x$)')\n    plt.ylabel('Choice probability $S^+$')\n    ax.xaxis.set_major_formatter(FormatStrFormatter('%.2g'))\n\n    if model_prediction:\n        anot_type1 = []\n        for i, (k, v) in enumerate(params.items()):\n            # if (cfg is None and k in params) or (cfg is not None and getattr(cfg, f\"enable_param_{k}\")) and k.startswith('type1_'):\n            if k.startswith('type1') and (cfg is None or (cfg is not None and getattr(cfg, f\"param_{k}\").enable)):\n                if hasattr(v, '__len__'):\n                    val = ', '.join([fmp(p) for p in v])\n                    anot_type1 += [f\"${symbols[k][1:-1]}=\" + f\"[{val}]$\"]\n                else:\n                    anot_type1 += [f\"${symbols[k][1:-1]}={fmp(v)}$\"]\n        plt.text(1.045, 0.1, r'Parameters:' + '\\n' + '\\n'.join(anot_type1), transform=ax.transAxes,\n                 bbox=dict(fc=[1, 1, 1], ec=[0.5, 0.5, 0.5], lw=1, pad=5), fontsize=11)\n    set_fontsize(label='default', tick='default')\n\n    # ax_leg.legend(bbox_to_anchor=(1.01, 1), loc=\"upper left\", fontsize=11, handlelength=1)\n    ax_leg.legend(*ax.get_legend_handles_labels(), loc=\"upper left\", fontsize=11, handlelength=1)\n\n    if path_export is not None:\n        plt.savefig(path_export, bbox_inches='tight', pad_inches=0.02)\n</code></pre>"},{"location":"plot/#plot_stimulus_versus_confidence","title":"plot_stimulus_versus_confidence","text":"<p>Plot the relationship between stimulus levels and confidence.</p> Usage <p>Plot for empirical data:</p> <p><code>plot_stimulus_versus_confidence(stimuli, choices)</code>  # Data</p> <p><code>plot_stimulus_versus_confidence(stimuli, choices, type1_noise, type2_noise, ...)</code>  # Data + Model</p> <p><code>plot_stimulus_versus_confidence(stimuli, choices, params, ...)</code>  # Data + Model</p> <p>Plot for simulation instance: (<code>remeta.simulation.Simulation</code>):</p> <p><code>plot_stimulus_versus_confidence(simulation)</code>  # (Simulated) Data</p> <p><code>plot_stimulus_versus_confidence(simulation, model_prediction=True)</code>  # (Simulated) Data + model</p> <p>Model only:</p> <p><code>plot_confidence_histogram(type1_noise=type1_noise, type2_noise=type2_noise, ...)</code>  # Model</p> <p><code>plot_stimulus_versus_confidence(params)</code>  # Model</p> <p>Parameters:</p> Name Type Description Default <code>stimuli_or_simulation</code> <code>list[float] | NDArray[float] | Simulation | None</code> <p>1d stimulus array (normalized to [-1; 1]) or [Simulation][remeta.simulation.Simulation] object</p> <code>None</code> <code>confidence</code> <code>list[float] | NDArray[float] | None</code> <p>1d confidence array</p> <code>None</code> <code>choices</code> <code>list[float] | NDArray[float] | None</code> <p>1d choice array</p> <code>None</code> <code>params</code> <code>dict | None</code> <p>pass parameters as a dictionary</p> <code>None</code> <code>type1_noise</code> <code>float | list[float] | None</code> <p>Type 1 noise.</p> <code>None</code> <code>type1_bias</code> <code>float | list[float] | None</code> <p>Type 1 bias.</p> <code>None</code> <code>type1_thresh</code> <code>float | list[float] | None</code> <p>Type 1 threshold.</p> <code>None</code> <code>type2_noise</code> <code>float | None</code> <p>Metacognitive noise. Required</p> <code>None</code> <code>type2_evidence_bias_mult</code> <code>float | None</code> <p>Multiplicative metacognitive bias</p> <code>None</code> <code>type2_criteria</code> <code>float | list[float] | None</code> <p>Confidence criteria</p> <code>None</code> <code>cfg</code> <code>Configuration | None</code> <p>Place holder - checking the configuration object is not yet implemented</p> <code>None</code> <code>stim_max</code> <code>float | None</code> <p>maximum stimulus intensity</p> <code>None</code> <code>errorbar_type</code> <code>str | None</code> <p>either None (disable), 'SD' (standard deviation) or 'SEM' (standard error)</p> <code>'SEM'</code> <code>probability_correct</code> <code>bool</code> <p>if True, convert confidence (range 0-1) to subjective probability correct (range 0.5-1),</p> <code>False</code> <code>separate_by_accuracy</code> <code>bool</code> <p>separate plots for correct and incorrect responses</p> <code>False</code> <code>model_prediction</code> <code>bool</code> <p>whether to show model-predicted values for comparison</p> <code>False</code> <code>model_prediction_nsamples</code> <code>int</code> <p>number of samples used to generate model predictions</p> <code>10000</code> <code>model_only</code> <code>bool</code> <p>Show the model prediction only (auto-set to True if no data are passed)</p> <code>False</code> <code>model_prediction_disable_type2_noise</code> <code>bool</code> <p>plot model prediction with ~0 metacognitive noise</p> <code>False</code> Source code in <code>remeta/plotting.py</code> <pre><code>def plot_stimulus_versus_confidence(\n        stimuli_or_simulation: list[float] | np.typing.NDArray[float] | Simulation | None = None,\n        confidence: list[float] | np.typing.NDArray[float] | None = None,\n        choices: list[float] | np.typing.NDArray[float] | None = None,\n        params: dict | None = None,\n        type1_noise: float | list[float] | None = None,\n        type1_bias: float | list[float] | None = None,\n        type1_thresh: float | list[float] | None = None,\n        type2_noise: float | None = None,\n        type2_evidence_bias_mult: float | None = None,\n        type2_criteria: float | list[float] | None = None,\n        cfg: Configuration | None = None,\n        stim_max: float | None = None,\n        errorbar_type: str | None = 'SEM',\n        probability_correct: bool = False,\n        separate_by_accuracy: bool = False,\n        model_prediction: bool = False,\n        model_prediction_nsamples: int = 10000,\n        model_only: bool = False,\n        model_prediction_disable_type2_noise: bool = False,\n        path_export: str | None = None\n) -&gt; None:\n    \"\"\" Plot the relationship between stimulus levels and confidence.\n\n    Usage:\n        **Plot for empirical data:**\n\n        `plot_stimulus_versus_confidence(stimuli, choices)`  # Data\n\n        `plot_stimulus_versus_confidence(stimuli, choices, type1_noise, type2_noise, ...)`  # Data + Model\n\n        `plot_stimulus_versus_confidence(stimuli, choices, params, ...)`  # Data + Model\n\n        **Plot for simulation instance: (`remeta.simulation.Simulation`):**\n\n        `plot_stimulus_versus_confidence(simulation)`  # (Simulated) Data\n\n        `plot_stimulus_versus_confidence(simulation, model_prediction=True)`  # (Simulated) Data + model\n\n        **Model only:**\n\n        `plot_confidence_histogram(type1_noise=type1_noise, type2_noise=type2_noise, ...)`  # Model\n\n        `plot_stimulus_versus_confidence(params)`  # Model\n\n    Args:\n        stimuli_or_simulation: 1d stimulus array (normalized to [-1; 1]) or [Simulation][remeta.simulation.Simulation] object\n        confidence: 1d confidence array\n        choices: 1d choice array\n        params: pass parameters as a dictionary\n        type1_noise: Type 1 noise.\n        type1_bias: Type 1 bias.\n        type1_thresh: Type 1 threshold.\n        type2_noise: Metacognitive noise. Required\n        type2_evidence_bias_mult: Multiplicative metacognitive bias\n        type2_criteria: Confidence criteria\n        cfg: Place holder - checking the configuration object is not yet implemented\n        stim_max: maximum stimulus intensity\n        errorbar_type: either None (disable), 'SD' (standard deviation) or 'SEM' (standard error)\n        probability_correct: if True, convert confidence (range 0-1) to subjective probability correct (range 0.5-1),\n        separate_by_accuracy: separate plots for correct and incorrect responses\n        model_prediction: whether to show model-predicted values for comparison\n        model_prediction_nsamples: number of samples used to generate model predictions\n        model_only: Show the model prediction only (auto-set to True if no data are passed)\n        model_prediction_disable_type2_noise: plot model prediction with ~0 metacognitive noise\n    \"\"\"\n\n    if stimuli_or_simulation is not None and confidence is None:  # assume first parameter is a simulated dataset\n        from copy import deepcopy\n        cfg = deepcopy(stimuli_or_simulation.cfg)\n        stimuli, confidence, choices = stimuli_or_simulation.stimuli, stimuli_or_simulation.confidence, stimuli_or_simulation.choices\n        params = stimuli_or_simulation.params.copy()\n    else:\n\n        if separate_by_accuracy and choices is None and not model_only:\n            raise ValueError('If separate_by_accuracy is True, choices must be passed.')\n\n        if confidence is None or params is not None or (type1_noise is not None and type2_noise is not None):\n            model_prediction = True\n        stimuli = None if model_only else stimuli_or_simulation\n        choices = None if model_only else choices\n        if stimuli is None:\n            model_only = True\n        if model_prediction:\n            if params is None:\n                if type1_noise is None:\n                    raise ValueError('Type 1 noise is unspecified.')\n                if type2_noise is None:\n                    raise ValueError('Type 2 noise is unspecified.')\n                params = dict(type1_noise=type1_noise, type2_noise=type2_noise)\n                for param in ('type1_bias', 'type1_thresh', 'type2_evidence_bias_mult', 'type2_criteria'):\n                    if (value := eval(param)) is not None and not (cfg is not None and not getattr(cfg, f'param_{param}').enable):\n                        params[param] = value\n            else:\n                params = params.copy()\n                if 'type1_noise' not in params:\n                    raise ValueError('Type 1 noise is unspecified.')\n                if 'type2_noise' not in params:\n                    raise ValueError('Type 2 noise is unspecified.')\n                for param in ('type1_bias', 'type1_thresh', 'type2_evidence_bias_mult', 'type2_criteria'):\n                    if param in params and (cfg is not None and not getattr(cfg, f'param_{param}').enable):\n                        params.pop(param)\n\n    if model_prediction and model_prediction_disable_type2_noise:\n        params['type2_noise'] = 1e-5\n\n\n    if probability_correct:\n        confidence = (confidence + 1) / 2\n\n    fig = plt.figure(figsize=(6, 3.5))\n    fig.subplots_adjust(bottom=0.2)\n    gs = fig.add_gridspec(1, 2, width_ratios=[1, 0.5], wspace=0)\n    ax = fig.add_subplot(gs[0, 0])\n    ax_leg = fig.add_subplot(gs[0, 1])\n    ax_leg.axis(\"off\")\n    plt.sca(ax)\n    ax.xaxis.set_major_formatter(FormatStrFormatter('%.2g'))\n\n    if stim_max is None:\n        stim_max = 1 if stimuli is None else np.max(np.abs(stimuli))\n\n\n    if errorbar_type is not None:\n        if errorbar_type == 'SD':\n            errorfun = np.std\n        elif errorbar_type == 'SEM':\n            errorfun = sem\n        else:\n            raise ValueError(f\"Unknown errorbar type '{errorbar_type}' (valid: 'SD', 'SEM')\")\n\n    chance_level_ref = 0.75 if probability_correct else 0.5\n    if not separate_by_accuracy:\n        plt.plot([-1.05*stim_max, 1.05*stim_max], [chance_level_ref, chance_level_ref], lw=1, color=[0.2, 0.2, 0.2],\n                 ls=':', label='Theoretical value\\nat chance level')\n    plt.plot([0, 0], [0, 1], 'k-', lw=0.5)\n\n    if not model_only:\n        stim_levels = sorted(np.unique(stimuli))\n        if separate_by_accuracy:\n            accuracy = np.sign(stimuli) == np.sign(choices - 0.5)\n            conf_av_inc = np.array([np.nan if (cnd :=(~accuracy &amp; (stimuli == stim_level))).sum() == 0 else np.mean(confidence[cnd]) for stim_level in stim_levels])\n            conf_av_cor = np.array([np.nan if (cnd :=(accuracy &amp; (stimuli == stim_level))).sum() == 0 else np.mean(confidence[cnd]) for stim_level in stim_levels])\n            if errorbar_type is not None:\n                with warnings.catch_warnings():\n                    warnings.filterwarnings('ignore', category=RuntimeWarning)\n                    conf_err_inc = np.array([np.nan if (cnd :=(~accuracy &amp; (stimuli == stim_level))).sum() == 0 else errorfun(confidence[cnd]) for stim_level in stim_levels])\n                    conf_err_cor = np.array([np.nan if (cnd :=(accuracy &amp; (stimuli == stim_level))).sum() == 0 else errorfun(confidence[cnd]) for stim_level in stim_levels])\n            else:\n                conf_err_inc = np.zeros(len(stim_levels))\n                conf_err_cor = np.zeros(len(stim_levels))\n            plt.errorbar(\n                stim_levels,\n                conf_av_cor,\n                yerr=None if errorbar_type is None else conf_err_cor,\n                marker='o', markersize=5, mew=1, mec='k', color='None', ecolor=color_cor, mfc=color_cor, clip_on=False,\n                elinewidth=1.5, capsize=5, label=f'Data (correct,\\nmean{\"\" if errorbar_type is None else f\"\u00b1{errorbar_type}\"})'\n            )\n            plt.errorbar(\n                stim_levels,\n                conf_av_inc,\n                yerr=None if errorbar_type is None else conf_err_inc,\n                marker='o', markersize=5, mew=1, mec='k', color='None', ecolor=color_inc, mfc=color_inc, clip_on=False,\n                elinewidth=1.5, capsize=5, label=f'Data (incorrect,\\nmean{\"\" if errorbar_type is None else f\"\u00b1{errorbar_type}\"})'\n            )\n            conf_min_data = min(np.nanmin(conf_av_inc - conf_err_inc), np.nanmin(conf_av_cor - conf_err_cor))\n        else:\n            conf_av = np.array([np.mean(confidence[stimuli == stim_level]) for stim_level in stim_levels])\n            if errorbar_type is not None:\n                conf_err = np.array([errorfun(confidence[stimuli == stim_level]) for stim_level in stim_levels])\n            else:\n                conf_err = np.zeros(len(stim_levels))\n\n            plt.errorbar(\n                stim_levels,\n                conf_av,\n                ls='' if model_prediction else '-',\n                yerr=None if errorbar_type is None else conf_err,\n                marker='o', markersize=5, mew=1, mec='k', color=color_data, ecolor='k', mfc=color_data, clip_on=False,\n                elinewidth=1.5, capsize=5, label=f'Data (mean{\"\" if errorbar_type is None else f\"\u00b1{errorbar_type}\"})'\n            )\n            conf_min_data = np.min(conf_av - conf_err)\n\n    if model_prediction:\n\n        # nlevels = 100\n        # nrows_per_level = int(np.ceil(model_prediction_nsamples / nlevels / 2))\n        # stim_min = stim_max / nlevels\n        # levels = np.hstack((np.linspace(-stim_max, -stim_min, nlevels), np.linspace(stim_min, stim_max, nlevels)))\n        # x_stim = np.tile(levels, (nrows_per_level, 1))\n        #\n        # y_decval = stimulus_to_decision_value(x_stim, params, return_only_decval=True)\n        # c_conf = type1_evidence_to_confidence(\n        #     z1_type1_evidence=np.abs(y_decval), y_decval=y_decval,\n        #     **params\n        # ).mean(axis=0)\n\n        _nsamples = int(np.ceil(model_prediction_nsamples / 2))\n        stim_min = stim_max / _nsamples\n        levels = np.hstack((np.linspace(-stim_max, -stim_min, _nsamples), np.linspace(stim_min, stim_max, _nsamples)))\n        # y_decval = stimulus_to_decision_value(levels, params, return_only_decval=True)\n        # c_conf = type1_evidence_to_confidence(\n        #     z1_type1_evidence=np.abs(y_decval), x_stim=levels,\n        #     **params\n        # )\n        ds = simulate(\n            nsubjects=100,\n            params=params, cfg=cfg, custom_stimuli=levels, verbosity=False,\n            stim_max=stim_max, squeeze=True, compute_stats=False,\n            silence_warnings=True\n        )\n        c_conf = (ds.confidence + 1) / 2 if probability_correct else ds.confidence\n\n        # from scipy.interpolate import UnivariateSpline\n\n        if 'type1_bias' in params:\n            if listlike(params['type1_bias']):\n                warnings.warn(f'Stimulus-dependent bias is currently not supported for this plot.')\n                bias = params['type1_bias'][0]\n            else:\n                bias = params['type1_bias']\n        else:\n            bias = 0\n\n        # Constrain the spline in a way that it is exactly chance_level_ref for x_stim = -bias\n        # We do this by weighting an additional datapoint at x_stim = -bias very highly\n        # ind_levels_min = np.argmin(np.abs(levels + bias))\n        # # insert data point at the position that is closest to already present values, while not\n        # # preserving ordering\n        # insert_idx = ind_levels_min + 1 if (levels[ind_levels_min] + bias &lt; 0) else ind_levels_min\n        # weights = np.insert(np.ones_like(c_conf), insert_idx, 1e8)\n        # c_conf_aug = np.insert(c_conf, insert_idx, chance_level_ref)\n        # levels_aug = np.insert(levels, insert_idx, -bias)\n        # c_conf_final = UnivariateSpline(levels_aug, c_conf_aug, k=3, w=weights)(levels)\n\n        from scipy.ndimage import gaussian_filter1d\n        if separate_by_accuracy:\n            accuracy = np.sign(ds.choices - 0.5) == np.sign(ds.stimuli)\n            c_conf_inc_, c_conf_cor_ = c_conf.copy(), c_conf.copy()\n            c_conf_inc_[accuracy] = np.nan\n            c_conf_cor_[~accuracy] = np.nan\n            with warnings.catch_warnings():\n                warnings.simplefilter('ignore', category=RuntimeWarning)\n                c_conf_inc_mean, c_conf_cor_mean = np.nanmean(c_conf_inc_, axis=0), np.nanmean(c_conf_cor_, axis=0)\n            # Interpolate nans\n            isnan_inc, isnan_cor = np.isnan(c_conf_inc_mean), np.isnan(c_conf_cor_mean)\n            c_conf_inc_mean[isnan_inc] = np.interp(np.arange(2*_nsamples)[isnan_inc], np.arange(2*_nsamples)[~isnan_inc], c_conf_inc_mean[~isnan_inc])\n            c_conf_cor_mean[isnan_cor] = np.interp(np.arange(2*_nsamples)[isnan_cor], np.arange(2*_nsamples)[~isnan_cor], c_conf_cor_mean[~isnan_cor])\n            c_conf_inc = gaussian_filter1d(c_conf_inc_mean, sigma=model_prediction_nsamples/20)\n            c_conf_cor = gaussian_filter1d(c_conf_cor_mean, sigma=model_prediction_nsamples/20)\n            plt.plot(levels, c_conf_cor, '-', lw=2, color=color_cor, clip_on=False,\n                     label='Model prediction\\n(correct)', alpha=0.5)\n                     # label='Model prediction' + (r\"($\\sigma_2=0$)\" if model_prediction_disable_type2_noise else \"\")+'\\n(correct)', alpha=0.5)\n            plt.plot(levels, c_conf_inc, '-', lw=2, color=color_inc, clip_on=False,\n                     label='Model prediction\\n(incorrect)', alpha=0.5)\n                     # label='Model prediction' + (r\"($\\sigma_2=0$)\" if model_prediction_disable_type2_noise else \"\")+'\\n(incorrect)', alpha=0.5)\n            conf_min_model = min(min(c_conf_inc), min(c_conf_cor))\n        else:\n            c_conf_final = gaussian_filter1d(c_conf.mean(axis=0), sigma=model_prediction_nsamples/20)\n            plt.plot(levels, c_conf_final, '-', lw=2, color=color_model, clip_on=False,\n                     label=f'Model prediction')\n                     # label=f'Model prediction' + (r\"($\\sigma_2=0$)\" if model_prediction_disable_type2_noise else \"\"))\n            conf_min_model = min(c_conf_final)\n\n    plt.xlim(-1.05*stim_max, 1.05*stim_max)\n    conf_min = conf_min_model if model_only else (min(conf_min_data, conf_min_model) if model_prediction else conf_min_data)\n    step = 0.05 if probability_correct else 0.1\n    ymin = (np.floor(conf_min / step) * step) if conf_min &lt; chance_level_ref else chance_level_ref - step / 2\n    plt.ylim(ymin, 1)\n    plt.xlabel('Stimulus ($x$)')\n    plt.ylabel('Subjective prob. correct' if probability_correct else 'Confidence ($C$)')\n\n    if model_prediction:\n        anot_type2 = []\n        for i, (k, v) in enumerate(params.items()):\n            if k.startswith('type2_'):\n                if listlike(v):\n                    val = ', '.join([fmp(p) for p in v])\n                    anot_type2 += [f\"${symbols[k][1:-1]}=\" + f\"[{val}]$\"]\n                else:\n                    anot_type2 += [f\"${symbols[k][1:-1]}={fmp(v)}$\"]\n        plt.text(1.045, 0.1-0.2*separate_by_accuracy, r'Type 2 parameters:' + '\\n' + '\\n'.join(anot_type2), transform=ax.transAxes,\n                 bbox=dict(fc=[1, 1, 1], ec=[0.5, 0.5, 0.5], lw=1, pad=5), fontsize=11)\n\n    # plt.legend(bbox_to_anchor=(1.01, 1), loc=\"upper left\", fontsize=11, handlelength=1)\n    ax_leg.legend(*ax.get_legend_handles_labels(), loc=\"upper left\", fontsize=11, handlelength=1)\n\n    set_fontsize(label='default', tick='default')\n    if path_export is not None:\n        plt.savefig(path_export, bbox_inches='tight', pad_inches=0.02)\n</code></pre>"},{"location":"plot/#plot_confidence_histogram","title":"plot_confidence_histogram","text":"<p>Plot the relationship between stimulus levels and confidence.</p> Usage <p>Plot for empirical data:</p> <p><code>plot_confidence_histogram(confidence)</code>  # Data</p> <p><code>plot_confidence_histogram(confidence, stimuli, choices, separate_by_accuracy=True)</code>  # Data</p> <p><code>plot_confidence_histogram(confidence, type1_noise, type2_noise, ...)</code>  # Data + Model</p> <p><code>plot_confidence_histogram(confidence, params, ...)</code>  # Data + Model</p> <p>Plot for simulation instance: (<code>remeta.simulation.Simulation</code>):</p> <p><code>plot_confidence_histogram(simulation)</code>  # (Simulated) Data</p> <p><code>plot_confidence_histogram(simulation, model_prediction=True)</code>  # (Simulated) Data + model</p> <p>Model only:</p> <p><code>plot_confidence_histogram(type1_noise=type1_noise, type2_noise=type2_noise, ...)</code>  # Model</p> <p><code>plot_confidence_histogram(params)</code>  # Model</p> <p>Parameters:</p> Name Type Description Default <code>confidence_or_simulation</code> <code>list[float] | NDArray[float] | Simulation | None</code> <p>1d stimulus array (normalized to [-1; 1]) or [Simulation][remeta.simulation.Simulation] object</p> <code>None</code> <code>stimuli</code> <code>list[float] | NDArray[float] | None</code> <p>1d stimulus array</p> <code>None</code> <code>choices</code> <code>list[float] | NDArray[float] | None</code> <p>1d choice array</p> <code>None</code> <code>params</code> <code>dict[str, float] | None</code> <p>pass parameters as a dictionary</p> <code>None</code> <code>type1_noise</code> <code>float | list[float] | None</code> <p>Type 1 noise.</p> <code>None</code> <code>type1_bias</code> <code>float | list[float] | None</code> <p>Type 1 bias.</p> <code>None</code> <code>type1_thresh</code> <code>float | list[float] | None</code> <p>Type 1 threshold.</p> <code>None</code> <code>type2_noise</code> <code>float | None</code> <p>Metacognitive noise. Required</p> <code>None</code> <code>type2_evidence_bias_mult</code> <code>float | None</code> <p>Multiplicative metacognitive bias</p> <code>None</code> <code>type2_criteria</code> <code>list[float] | None</code> <p>Confidence criteria</p> <code>None</code> <code>cfg</code> <code>Configuration | None</code> <p>Place holder - checking the configuration object is not yet implemented</p> <code>None</code> <code>stim_max</code> <code>float | None</code> <p>float | None = None,</p> <code>None</code> <code>probability_correct</code> <code>bool</code> <p>if True, convert confidence (range 0-1) to subjective probability correct (range 0.5-1)</p> <code>False</code> <code>model_prediction</code> <code>bool</code> <p>whether to show model-predicted values for comparison</p> <code>False</code> <code>model_only</code> <code>bool</code> <p>Show the model prediction only (auto-set to True if no data are passed)</p> <code>False</code> <code>separate_by_category</code> <code>bool</code> <p>separate histograms for the two stimulus categories</p> <code>False</code> <code>separate_by_accuracy</code> <code>bool</code> <p>separate histograms for correct and incorrect responses</p> <code>False</code> <code>model_prediction_nsamples</code> <code>int</code> <p>number of samples used to generate model predictions</p> <code>10000</code> Source code in <code>remeta/plotting.py</code> <pre><code>def plot_confidence_histogram(\n        confidence_or_simulation: list[float] | np.typing.NDArray[float] | Simulation | None = None,\n        stimuli: list[float] | np.typing.NDArray[float] | None = None,\n        choices: list[float] | np.typing.NDArray[float] | None = None,\n        params: dict[str, float] | None = None,\n        type1_noise: float | list[float] | None = None,\n        type1_bias: float | list[float] | None = None,\n        type1_thresh: float | list[float] | None = None,\n        type2_noise: float | None = None,\n        type2_evidence_bias_mult: float | None = None,\n        type2_criteria: list[float] | None = None,\n        cfg: Configuration | None = None,\n        stim_max: float | None = None,\n        probability_correct: bool = False,\n        model_prediction: bool = False,\n        model_only: bool = False,\n        separate_by_category: bool = False,\n        separate_by_accuracy: bool = False,\n        model_prediction_nsamples: int = 10000,\n        path_export: str | None = None\n) -&gt; None:\n    \"\"\" Plot the relationship between stimulus levels and confidence.\n\n    Usage:\n        **Plot for empirical data:**\n\n        `plot_confidence_histogram(confidence)`  # Data\n\n        `plot_confidence_histogram(confidence, stimuli, choices, separate_by_accuracy=True)`  # Data\n\n        `plot_confidence_histogram(confidence, type1_noise, type2_noise, ...)`  # Data + Model\n\n        `plot_confidence_histogram(confidence, params, ...)`  # Data + Model\n\n        **Plot for simulation instance: (`remeta.simulation.Simulation`):**\n\n        `plot_confidence_histogram(simulation)`  # (Simulated) Data\n\n        `plot_confidence_histogram(simulation, model_prediction=True)`  # (Simulated) Data + model\n\n        **Model only:**\n\n        `plot_confidence_histogram(type1_noise=type1_noise, type2_noise=type2_noise, ...)`  # Model\n\n        `plot_confidence_histogram(params)`  # Model\n\n    Args:\n        confidence_or_simulation: 1d stimulus array (normalized to [-1; 1]) or [Simulation][remeta.simulation.Simulation] object\n        stimuli: 1d stimulus array\n        choices: 1d choice array\n        params: pass parameters as a dictionary\n        type1_noise: Type 1 noise.\n        type1_bias: Type 1 bias.\n        type1_thresh: Type 1 threshold.\n        type2_noise: Metacognitive noise. Required\n        type2_evidence_bias_mult: Multiplicative metacognitive bias\n        type2_criteria: Confidence criteria\n        cfg: Place holder - checking the configuration object is not yet implemented\n        stim_max: float | None = None,\n        probability_correct: if True, convert confidence (range 0-1) to subjective probability correct (range 0.5-1)\n        model_prediction: whether to show model-predicted values for comparison\n        model_only: Show the model prediction only (auto-set to True if no data are passed)\n        separate_by_category: separate histograms for the two stimulus categories\n        separate_by_accuracy: separate histograms for correct and incorrect responses\n        model_prediction_nsamples: number of samples used to generate model predictions\n    \"\"\"\n\n    if separate_by_accuracy:\n        separate_by_category = False\n\n    if model_only:\n        model_prediction = True\n\n    if isinstance(confidence_or_simulation, Simulation):\n        from copy import deepcopy\n        cfg = deepcopy(confidence_or_simulation.cfg)\n        stimuli, confidence, choices = confidence_or_simulation.stimuli, confidence_or_simulation.confidence, confidence_or_simulation.choices\n        params = confidence_or_simulation.params.copy()\n    else:\n\n        if params is not None or (type1_noise is not None and type2_noise is not None):\n            model_prediction = True\n        confidence = None if model_only else confidence_or_simulation\n        stimuli = None if model_only else stimuli\n        choices = None if model_only else choices\n        if confidence is None:\n            model_only = True\n\n        if separate_by_accuracy and choices is None and not model_only:\n            raise ValueError('If separate_by_accuracy is True, choices must be passed.')\n\n        if model_prediction:\n            if params is None:\n                if type1_noise is None:\n                    raise ValueError('Type 1 noise is unspecified.')\n                if type2_noise is None:\n                    raise ValueError('Type 2 noise is unspecified.')\n                params = dict(type1_noise=type1_noise, type2_noise=type2_noise)\n                for param in ('type1_bias', 'type1_thresh', 'type2_evidence_bias_mult', 'type2_criteria'):\n                    if (value := eval(param)) is not None and not (cfg is not None and not getattr(cfg, f'param_{param}').enable):\n                        params[param] = value\n            else:\n                params = params.copy()\n                if 'type1_noise' not in params:\n                    raise ValueError('Type 1 noise is unspecified.')\n                if 'type2_noise' not in params:\n                    raise ValueError('Type 2 noise is unspecified.')\n                for param in ('type1_bias', 'type1_thresh', 'type2_evidence_bias_mult', 'type2_criteria'):\n                    if param in params and (cfg is not None and not getattr(cfg, f'param_{param}').enable):\n                        params.pop(param)\n\n\n    if probability_correct:\n        confidence = (confidence + 1) / 2\n\n    if stim_max is None:\n        stim_max = 1 if stimuli is None else np.max(np.abs(stimuli))\n\n    fig = plt.figure(figsize=(6, 3.5))\n    fig.subplots_adjust(bottom=0.2)\n    gs = fig.add_gridspec(1, 2, width_ratios=[1, 0.5], wspace=0)\n    ax = fig.add_subplot(gs[0, 0])\n    ax_leg = fig.add_subplot(gs[0, 1])\n    ax_leg.axis(\"off\")\n    plt.sca(ax)\n    ax.xaxis.set_major_formatter(FormatStrFormatter('%.3g'))\n\n    if not model_only:\n        conf_levels = np.sort(np.unique(confidence))\n        n_conf_levels = len(conf_levels)\n        bins = np.linspace(0, 1, n_conf_levels+1) if n_conf_levels &gt;= 8 else np.hstack((0, conf_levels[1:] - np.diff(conf_levels) / 2, 1))\n\n        if separate_by_category:\n            counts0 = np.histogram(confidence[np.sign(stimuli) == -1], bins=bins)[0]\n            counts1 = np.histogram(confidence[np.sign(stimuli) == 1], bins=bins)[0]\n            centers = 0.5 * (bins[:-1] + bins[1:])\n            widths  = bins[1:] - bins[:-1]\n            for i, (x, w, c0, c1) in enumerate(zip(centers, widths, counts0, counts1)):\n                if c0 &lt; c1:\n                    plt.bar(x, c1, width=w, color=(0.8, 0.8, 0.8), ec='grey', align='center', zorder=1, label='Data ($S^+$)' if i == 0 else None)\n                    plt.bar(x, c0, width=w, color=(0.4, 0.4, 0.4), ec='grey', align='center', zorder=2, label='Data ($S^-$)' if i == 0 else None)\n                else:\n                    plt.bar(x, c0, width=w, color=(0.4, 0.4, 0.4), ec='grey', align='center', zorder=1, label='Data ($S^-$)' if i == 0 else None)\n                    plt.bar(x, c1, width=w, color=(0.8, 0.8, 0.8), ec='grey', align='center', zorder=2, label='Data ($S^+$)' if i == 0 else None)\n        elif separate_by_accuracy:\n            accuracy = np.sign(stimuli) == np.sign(choices - 0.5)\n            counts_inc = np.histogram(confidence[~accuracy], bins=bins)[0]\n            counts_cor = np.histogram(confidence[accuracy], bins=bins)[0]\n            centers = 0.5 * (bins[:-1] + bins[1:])\n            widths  = bins[1:] - bins[:-1]\n            for i, (x, w, c0, c1) in enumerate(zip(centers, widths, counts_inc, counts_cor)):\n                if c0 &lt; c1:\n                    plt.bar(x, c1, width=w, color=color_cor, ec='grey', align='center', zorder=1, label='Data (correct)' if i == 0 else None)\n                    plt.bar(x, c0, width=w, color=color_inc, ec='grey', align='center', zorder=2, label='Data (incorrect)' if i == 0 else None)\n                else:\n                    plt.bar(x, c0, width=w, color=color_inc, ec='grey', align='center', zorder=1, label='Data (incorrect)' if i == 0 else None)\n                    plt.bar(x, c1, width=w, color=color_cor, ec='grey', align='center', zorder=2, label='Data (correct)' if i == 0 else None)\n        else:\n            plt.hist(confidence, bins=bins, color=(0.8, 0.8, 0.8), edgecolor='grey', clip_on=False, label='Data')\n\n    if model_prediction:\n        if model_only:\n            _nsamples = int(np.ceil(model_prediction_nsamples / 2))\n            bins = np.linspace(0, 1, 5)\n        else:\n            _nsamples = len(confidence)\n        stim_min = stim_max / _nsamples\n        levels = np.hstack((np.linspace(-stim_max, -stim_min, _nsamples), np.linspace(stim_min, stim_max, _nsamples)))\n        # y_decval = stimulus_to_decision_value(levels, params, return_only_decval=True)\n        # c_conf = type1_evidence_to_confidence(\n        #     z1_type1_evidence=np.abs(y_decval), x_stim=levels,\n        #     **params\n        # )\n        nsubjects = 100 if model_only else 500\n        ds = simulate(\n            nsubjects=nsubjects,\n            params=params, cfg=cfg, custom_stimuli=levels, verbosity=False,\n            stim_max=stim_max, squeeze=True, compute_stats=False,\n            silence_warnings=True\n        )\n        c_conf = (ds.confidence + 1) / 2 if probability_correct else ds.confidence\n\n        if separate_by_category:\n            counts0_ = [np.histogram(c_conf[s][np.sign(ds.stimuli[s]) == -1], bins=bins)[0] for s in range(nsubjects)]\n            counts1_ = [np.histogram(c_conf[s][np.sign(ds.stimuli[s]) == 1], bins=bins)[0] for s in range(nsubjects)]\n            counts0 = np.array([(counts0_[s] / (2*_nsamples if model_only else counts0_[s].sum())) * (1 if model_only else (stimuli &lt; 0).sum()) for s in range(nsubjects)])\n            counts1 = np.array([(counts1_[s] / (2*_nsamples if model_only else counts1_[s].sum())) * (1 if model_only else (stimuli &gt; 0).sum()) for s in range(nsubjects)])\n            plt.errorbar(\n                bins[:-1] + np.diff(bins) / 2 - 0.04, counts0.mean(axis=0),\n                yerr=np.percentile(counts0, 97.5, axis=0) - np.percentile(counts0, 2.5, axis=0),\n                mew=2, elinewidth=2, capsize=7, capthick=2, fmt='o', markersize=8, mec=color_model, mfc=(0.4, 0.4, 0.4),\n                color=color_model, lw=2, label='Model prediction ($S^-$)'\n            )\n            plt.errorbar(\n                bins[:-1] + np.diff(bins) / 2 + 0.04, counts1.mean(axis=0),\n                yerr=np.percentile(counts1, 97.5, axis=0) - np.percentile(counts1, 2.5, axis=0),\n                mew=2, elinewidth=2, capsize=7, capthick=2, fmt='o', markersize=8, mec=color_model, mfc=(0.8, 0.8, 0.8),\n                color=color_model, lw=2, label='Model prediction ($S^+$)'\n            )\n        elif separate_by_accuracy:\n            acc = [np.sign(ds.stimuli[s]) == np.sign(ds.choices[s] - 0.5) for s in range(nsubjects)]\n            counts_inc_ = [np.histogram(c_conf[s][~acc[s]], bins=bins)[0] for s in range(nsubjects)]\n            counts_cor_ = [np.histogram(c_conf[s][acc[s]], bins=bins)[0] for s in range(nsubjects)]\n            print(_nsamples, counts_inc_[0].sum()+counts_cor_[0].sum())\n            counts_inc = np.array([(counts_inc_[s] / (2*_nsamples if model_only else counts_inc_[s].sum())) * (1 if model_only else (~accuracy).sum())for s in range(nsubjects)])\n            counts_cor = np.array([(counts_cor_[s] / (2*_nsamples if model_only else counts_cor_[s].sum())) * (1 if model_only else accuracy.sum()) for s in range(nsubjects)])\n            plt.errorbar(\n                bins[:-1] + np.diff(bins) / 2 - 0.04, counts_inc.mean(axis=0),\n                yerr=np.percentile(counts_inc, 97.5, axis=0) - np.percentile(counts_inc, 2.5, axis=0),\n                mew=2, elinewidth=2, capsize=7, capthick=2, fmt='o', markersize=8, mec=color_model, mfc=color_inc,\n                color=color_model, lw=2, label='Model prediction\\n(incorrect)'\n            )\n            plt.errorbar(\n                bins[:-1] + np.diff(bins) / 2 + 0.04, counts_cor.mean(axis=0),\n                yerr=np.percentile(counts_cor, 97.5, axis=0) - np.percentile(counts_cor, 2.5, axis=0),\n                mew=2, elinewidth=2, capsize=7, capthick=2, fmt='o', markersize=8, mec=color_model, mfc=color_cor,\n                color=color_model, lw=2, label='Model prediction\\n(correct)'\n            )\n        else:\n            counts_ = [np.histogram(c_conf[s], bins=bins)[0] for s in range(nsubjects)]\n            counts = np.array([(counts_[s] / (2*_nsamples)) * (1 if model_only else len(confidence)) for s in range(nsubjects)])\n            plt.errorbar(\n                bins[:-1] + np.diff(bins) / 2, counts.mean(axis=0),\n                yerr=np.percentile(counts, 97.5, axis=0) - np.percentile(counts, 2.5, axis=0),\n                mew=2, elinewidth=2, capsize=7, capthick=2, fmt='o', markersize=8, mec=color_model, mfc=(0.8, 0.8, 0.8),\n                color=color_model, lw=2, label='Model prediction'\n            )\n\n\n    plt.xticks(bins)\n    plt.xlabel('Confidence')\n    plt.ylabel('Probability' if model_only else 'Count')\n    plt.xlim(0, 1)\n\n    if model_prediction:\n        anot_type2 = []\n        cfg = None  # keep in case cfg is implemented in the future\n        for i, (k, v) in enumerate(params.items()):\n            if k.startswith('type2_'):\n                if listlike(v):\n                    val = ', '.join([fmp(p) for p in v])\n                    anot_type2 += [f\"${symbols[k][1:-1]}=\" + f\"[{val}]$\"]\n                else:\n                    anot_type2 += [f\"${symbols[k][1:-1]}={fmp(v)}$\"]\n        plt.text(1.055, 0.1-0.2*(separate_by_accuracy | separate_by_category), r'Type 2 parameters:' + '\\n' + '\\n'.join(anot_type2), transform=ax.transAxes,\n                 bbox=dict(fc=[1, 1, 1], ec=[0.5, 0.5, 0.5], lw=1, pad=5), fontsize=11)\n\n    # plt.legend(bbox_to_anchor=(1.01, 1), loc=\"upper left\", fontsize=11, handlelength=1)\n    ax_leg.legend(*ax.get_legend_handles_labels(), loc=\"upper left\", fontsize=11, handlelength=1)\n\n    set_fontsize(label='default', tick='default')\n\n    if path_export is not None:\n        plt.savefig(path_export, bbox_inches='tight', pad_inches=0.02)\n</code></pre>"},{"location":"simulation/","title":"remeta.simulation","text":""},{"location":"simulation/#simulate","title":"simulate","text":"<p>Simulate data for ReMeta</p> Usage <p><code>sim = simulate(params=dict(type1_noise=0.5, type2_noise=0.3))</code></p> <p><code>sim = simulate(params=dict(type1_noise=0.5, type2_noise=0.3), nsamples=500)</code></p> <p><code>sim = simulate(params=dict(type1_noise=0.5, type2_noise=0.3), cfg=cfg)</code></p> <p>Parameters:</p> Name Type Description Default <code>params</code> <code>dict</code> <p>Parameter values (dictionary with {param_name: param_value} entries)</p> <code>None</code> <code>nsubjects</code> <code>int</code> <p>Number of subjects</p> <code>1</code> <code>nsamples</code> <code>int</code> <p>Number of samples per subject</p> <code>1000</code> <code>cfg</code> <code>Configuration</code> <p><code>remeta.configuration.Configuration</code> instance (for model specification)</p> <code>None</code> <code>stim_min</code> <code>float | None</code> <p>minimum stimulus intensity</p> <code>None</code> <code>stim_max</code> <code>float | None</code> <p>maximum stimulus intensity</p> <code>1</code> <code>stim_levels</code> <code>int</code> <p>number of different stimulus intensity levels</p> <code>10</code> <code>custom_stimuli</code> <code>list[float] | ndarray</code> <p>(optional) pass a custom array or list of signed stimulus intensities</p> <code>None</code> <code>squeeze</code> <code>bool</code> <p>if <code>True</code> and only 1 subject is simulated, remove the subject dimension</p> <code>False</code> <code>compute_stats</code> <code>bool</code> <p>if <code>True</code>, compute some descriptive statistics on the simulated dataset</p> <code>True</code> <code>silence_warnings</code> <code>bool</code> <p>if <code>True</code>, silences a few (custom) warnings</p> <code>False</code> <code>verbosity</code> <code>int</code> <p>verbosity level (possible values: 0, 1, 2)</p> <code>1</code> <code>**kwargs</code> <p>extra arguments will be passed to the configuration</p> <code>{}</code> <p>Returns: a <code>remeta.simulation.Simulation</code> instance</p> Source code in <code>remeta/simulation.py</code> <pre><code>def simulate(\n    params: dict = None,\n    nsubjects: int = 1,\n    nsamples: int = 1000,\n    cfg: Configuration = None,\n    stim_min: float | None = None,\n    stim_max: float | None = 1,\n    stim_levels: int = 10,\n    custom_stimuli: list[float] | np.ndarray = None,\n    squeeze: bool = False,\n    compute_stats: bool = True,\n    silence_warnings: bool = False,\n    verbosity: int = 1,\n    **kwargs\n) -&gt; Simulation:\n    \"\"\"\n    Simulate data for ReMeta\n\n    Usage:\n        `sim = simulate(params=dict(type1_noise=0.5, type2_noise=0.3))`\n\n        `sim = simulate(params=dict(type1_noise=0.5, type2_noise=0.3), nsamples=500)`\n\n        `sim = simulate(params=dict(type1_noise=0.5, type2_noise=0.3), cfg=cfg)`\n\n\n    Args:\n        params: Parameter values (dictionary with {param_name: param_value} entries)\n        nsubjects: Number of subjects\n        nsamples: Number of samples per subject\n        cfg: `remeta.configuration.Configuration` instance (for model specification)\n        stim_min: minimum stimulus intensity\n        stim_max: maximum stimulus intensity\n        stim_levels: number of different stimulus intensity levels\n        custom_stimuli: (optional) pass a custom array or list of signed stimulus intensities\n        squeeze: if `True` and only 1 subject is simulated, remove the subject dimension\n        compute_stats: if `True`, compute some descriptive statistics on the simulated dataset\n        silence_warnings: if `True`, silences a few (custom) warnings\n        verbosity: verbosity level (possible values: 0, 1, 2)\n        **kwargs: extra arguments will be passed to the configuration\n\n    Returns: a `remeta.simulation.Simulation` instance\n\n    \"\"\"\n\n    params = params.copy()  # this variable can be modifed, better make a copy\n    if cfg is None:\n        # Set configuration attributes that match keyword arguments\n        cfg_dict = Configuration.__dict__\n        cfg_kwargs = {k: v for k, v in kwargs.items() if k in cfg_dict}\n        cfg = Configuration(**cfg_kwargs)\n        for k, v in params.items():\n            if f'param_{k}' in cfg_dict:\n                setattr(getattr(cfg, f'param_{k}'), 'enable', len(v) if listlike(v) else 1)\n            else:\n                raise ValueError(f'Unknown parameter {k}')\n        for k, v in cfg_dict.items():\n            if isinstance(v, Parameter):\n                if k.split('param_')[1] not in params:\n                    setattr(getattr(cfg, k), 'enable', 0)\n\n        # for setting in cfg.__dict__:\n        #     if setting.startswith('param_'):\n        #         if setting.split('param_')[1] not in params:\n        #             setattr(getattr(cfg, setting), 'enable', 0)\n    # if not cfg.setup_called:\n    cfg.setup(generative_mode=True, silence_warnings=silence_warnings)\n\n    if cfg.param_type2_noise.model is None:\n        cfg.param_type2_noise.model = dict(report='truncated_norm_mode', readout='truncated_norm_mode', temperature='lognorm_mode')[cfg.type2_noise_type]\n\n    # Make sure no unwanted parameters have been passed\n    for p in ('thresh', 'bias', 'noise_heteroscedastic', 'nonlinear_gain', 'nonlinear_scale'):\n        if not getattr(cfg, f'param_type1_{p}').enable:\n            params.pop(f'type1_{p}', None)\n    for p in ('evidence_bias', 'confidence_bias', 'criteria'):\n        if not getattr(cfg, f'param_type2_{p}').enable:\n            params.pop(f'type2_{p}', None)\n\n    if custom_stimuli is None:\n        x_stim = generate_stimuli(nsubjects, nsamples, stim_min=stim_min, stim_max=stim_max, stim_levels=stim_levels)\n    else:\n        custom_stimuli = np.array(custom_stimuli)\n        if custom_stimuli.ndim == 1:\n            custom_stimuli = custom_stimuli.reshape(1, -1)\n        nsamples = custom_stimuli.shape[1]\n        x_stim = custom_stimuli / np.max(np.abs(custom_stimuli))\n        if (x_stim.shape[0] == 1) and (nsubjects &gt; 1):\n            x_stim = np.tile(x_stim, (nsubjects, 1))\n    x_stim_category = (np.sign(x_stim) &gt; 0).astype(int)\n    y_decval_latent, y_decval, d_dec = stimulus_to_decision_value(x_stim, params, cfg)\n\n    if not cfg.skip_type2:\n\n        z1_type1_evidence_latent = np.abs(y_decval_latent)\n        z1_type1_evidence_base = np.abs(y_decval)\n\n        if cfg.type2_noise_type == 'readout':\n            dist = get_type2_dist(cfg.param_type2_noise.model, type2_center=z1_type1_evidence_base, type2_noise=params['type2_noise'],\n                                  type2_noise_type=cfg.type2_noise_type)\n\n            z1_type1_evidence = np.maximum(0, dist.rvs((nsubjects, nsamples)))\n        elif cfg.type2_noise_type == 'temperature':\n            dist = get_type2_dist(cfg.param_type2_noise.model, type2_center=params['type1_noise'] * np.ones_like(z1_type1_evidence_base),\n                                  type2_noise=params['type2_noise'], type2_noise_type=cfg.type2_noise_type)\n            type1_noise_estimated = dist.rvs()\n            z1_type1_evidence = z1_type1_evidence_base\n        elif cfg.type2_noise_type == 'report':\n            z1_type1_evidence = z1_type1_evidence_base\n        else:\n            raise ValueError('Unknown type 2 noise type')\n\n        c_conf_latent = type1_evidence_to_confidence(\n            z1_type1_evidence=z1_type1_evidence_latent, y_decval=y_decval,\n            x_stim=x_stim,\n            type1_noise_signal_dependency=cfg.param_type1_noise_heteroscedastic.model if cfg.param_type1_noise_heteroscedastic.enable else None,\n            **({**params, **dict(type1_noise=type1_noise_estimated)} if cfg.type2_noise_type == 'temperature' else params)\n        )\n\n        c_conf_base = type1_evidence_to_confidence(\n            z1_type1_evidence=z1_type1_evidence, y_decval=y_decval,\n            x_stim=x_stim,\n            type1_noise_signal_dependency=cfg.param_type1_noise_heteroscedastic.model if cfg.param_type1_noise_heteroscedastic.enable else None,\n            **({**params, **dict(type1_noise=type1_noise_estimated)} if cfg.type2_noise_type == 'temperature' else params)\n        )\n\n        if cfg.type2_noise_type == 'report':\n            dist = get_type2_dist(cfg.param_type2_noise.model, type2_center=c_conf_base, type2_noise=params['type2_noise'],\n                                  type2_noise_type=cfg.type2_noise_type)\n            c_conf = np.maximum(0, np.minimum(1, dist.rvs((nsubjects, nsamples))))\n        else:\n            c_conf = c_conf_base\n\n        if cfg.param_type2_criteria.enable or cfg.param_type2_criteria.preset is not None:\n            if cfg.param_type2_criteria.enable:\n                if not np.all(np.diff(params['type2_criteria']) &gt; 0) or (min(params['type2_criteria']) &lt; 0) or (max(params['type2_criteria']) &gt; 1):\n                    raise ValueError('Type 2 criteria must be provided in an ascending manner and be between 0 and 1.\\n'\n                                     f\"Provided criteria: {np.array2string(np.array(params['type2_criteria']), precision=3)}\")\n\n                # convert to criterion gaps\n                # old_criteria = np.array(params['type2_criteria']).copy()\n                # params['type2_criteria'] = np.diff(np.hstack((0, params['type2_criteria'])))\n                # criteria_gaps = params['type2_criteria']\n                # criteria = [v if i == 0 else np.sum(criteria_gaps[:i+1]) for i, v in enumerate(criteria_gaps)]\n                criteria = params['type2_criteria']\n            elif cfg.param_type2_criteria.preset is not None:\n                criteria = np.arange(1 / cfg._n_conf_levels, 1-1e-10,  1 / cfg._n_conf_levels)\n\n            c_conf = (np.digitize(c_conf, criteria) + 0.5) / cfg._n_conf_levels\n            c_conf_base = (np.digitize(c_conf_base, criteria) + 0.5) / cfg._n_conf_levels\n\n    if squeeze:\n        x_stim_category = x_stim_category.squeeze()\n        x_stim = x_stim.squeeze()\n        d_dec = d_dec.squeeze()\n        y_decval_latent = y_decval_latent.squeeze()\n        y_decval = y_decval.squeeze()\n        if not cfg.skip_type2:\n            z1_type1_evidence_base = z1_type1_evidence_base.squeeze()  # noqa\n            z1_type1_evidence = z1_type1_evidence.squeeze()  # noqa\n            c_conf_base = c_conf_base.squeeze()  # noqa\n            c_conf = c_conf.squeeze()  # noqa\n\n    simargs = dict(\n        nsubjects=nsubjects, nsamples=nsamples, params=params, cfg=cfg,\n        x_stim_category=x_stim_category, x_stim=x_stim, d_dec=d_dec,\n        y_decval=y_decval, y_decval_latent=y_decval_latent\n    )\n    if not cfg.skip_type2:\n        simargs.update(\n            z1_type1_evidence_latent=z1_type1_evidence_latent, z1_type1_evidence_base=z1_type1_evidence_base, z1_type1_evidence=z1_type1_evidence,\n            c_conf_latent=c_conf_latent, c_conf_base=c_conf_base, c_conf=c_conf\n        )\n\n    if compute_stats:\n        accuracy = (x_stim_category == d_dec).astype(int)\n        type1_stats = dict(\n            accuracy=np.mean(accuracy),\n            dprime = norm.ppf(min(1 - 1e-3, max(1e-3, d_dec[x_stim_category == 1].mean()))) - \\\n                 norm.ppf(min(1 - 1e-3, max(1e-3, d_dec[x_stim_category == 0].mean().mean()))),\n            choice_bias=d_dec.mean() - x_stim_category.mean(),\n        )\n        simargs.update(type1_stats=type1_stats)\n        if not cfg.skip_type2:\n            bounds = np.arange(0, 0.81, 0.2)\n            fit = type2_SDT_MLE(x_stim_category.flatten(), d_dec.flatten(), discretize_confidence_with_bounds(c_conf.flatten(), bounds), len(bounds))\n            type2_stats = dict(\n                confidence=c_conf.mean(),\n                auroc2=type2roc(accuracy.flatten(), c_conf.flatten()),\n                mratio=fit.M_ratio\n            )\n            simargs.update(type2_stats=type2_stats)\n            if 'type2_criteria' in params:\n                params_extra = dict(\n                    # type2_criteria_absolute=[np.sum(params['type2_criteria'][:i + 1]) for i in range(len(params['type2_criteria']))],\n                    # type2_criteria_bias=np.mean(params['type2_criteria']) * (len(params['type2_criteria']) + 1) - 1\n                    type2_criteria_bias=np.mean(params['type2_criteria']) - 0.5,\n                    type2_criteria_confidence_bias=0.5 - np.mean(params['type2_criteria']),\n                    # type2_criteria_bias_mult=np.mean(params['type2_criteria']) / 0.5,\n                    # type2_criteria_confidence_bias_mult=0.5 / np.mean(params['type2_criteria']),\n                    # type2_criteria_absdev=round(np.abs(np.array(params['type2_criteria']) -\n                    #    np.arange(1/cfg._n_conf_levels, 1-1e-10, 1/cfg._n_conf_levels)).mean(), 10)\n                )\n                simargs.update(params_extra=params_extra)\n\n\n    simulation = Simulation(**simargs)\n    if verbosity:\n        print_dataset_characteristics(simulation)\n\n    return simulation\n</code></pre>"},{"location":"simulation/#simulation","title":"Simulation","text":"<p>Class to store simulated data. This class is created by the <code>remeta.simulation.simulate()</code>. Manual creation is discouraged.</p> <p>Parameters:</p> Name Type Description Default <code>nsubjects</code> <code>int</code> <p>Number of subjects</p> <code>None</code> <code>nsamples</code> <code>int</code> <p>Number of samples per subject</p> <code>None</code> <code>params</code> <code>dict</code> <p>Dictionary of model parameters</p> <code>None</code> <code>params_extra</code> <code>dict | None</code> <p>Optional dictionary of extra parameters</p> <code>None</code> <code>cfg</code> <code>Configuration</code> <p><code>remeta.configuration.Configuration</code> instance</p> <code>None</code> <code>x_stim</code> <code>list[float] | ndarray</code> <p>stimuli (array or list of signed stimulus intensities) (x)</p> <code>None</code> <code>x_stim_category</code> <code>list[int] | ndarray</code> <p>stimulus category</p> <code>None</code> <code>d_dec</code> <code>list[int] | ndarray</code> <p>choices (D)</p> <code>None</code> <code>y_decval_latent</code> <code>list[int] | ndarray</code> <p>latent, i.e. noise-free decision values</p> <code>None</code> <code>y_decval</code> <code>list[int] | ndarray</code> <p>observed decision values (hat{y})</p> <code>None</code> <code>z1_type1_evidence_latent</code> <code>list[int] | ndarray</code> <p>latent, i.e. noise-free type 1 evidence (z_1)</p> <code>None</code> <code>z1_type1_evidence_base</code> <code>list[int] | ndarray</code> <p>absolute values of observed decision values (|hat{y}|)</p> <code>None</code> <code>z1_type1_evidence</code> <code>list[int] | ndarray</code> <p>observed type 1 evidence (z2=hat{z_1})</p> <code>None</code> <code>c_conf_latent</code> <code>list[int] | ndarray</code> <p>probability correct based on z1_type1_evidence_latent</p> <code>None</code> <code>c_conf_base</code> <code>list[int] | ndarray</code> <p>probability correct based on z1_type1_evidence_base</p> <code>None</code> <code>c_conf</code> <code>list[int] | ndarray</code> <p>probability correct based on z1_type1_evidence</p> <code>None</code> <code>type1_stats</code> <code>dict</code> <p>descriptive type 1 statistics</p> <code>None</code> <code>type2_stats</code> <code>dict</code> <p>descriptive type 2 statistics</p> <code>None</code> Source code in <code>remeta/simulation.py</code> <pre><code>class Simulation:\n    \"\"\"Class to store simulated data.\n    This class is created by the `remeta.simulation.simulate()`. Manual creation is discouraged.\n\n    Args:\n        nsubjects: Number of subjects\n        nsamples: Number of samples per subject\n        params: Dictionary of model parameters\n        params_extra: Optional dictionary of extra parameters\n        cfg: `remeta.configuration.Configuration` instance\n        x_stim: stimuli (array or list of signed stimulus intensities) (x)\n        x_stim_category: stimulus category\n        d_dec: choices (D)\n        y_decval_latent: latent, i.e. noise-free decision values\n        y_decval: observed decision values (hat{y})\n        z1_type1_evidence_latent: latent, i.e. noise-free type 1 evidence (z_1)\n        z1_type1_evidence_base: absolute values of observed decision values (|hat{y}|)\n        z1_type1_evidence: observed type 1 evidence (z2=hat{z_1})\n        c_conf_latent: probability correct based on z1_type1_evidence_latent\n        c_conf_base: probability correct based on z1_type1_evidence_base\n        c_conf: probability correct based on z1_type1_evidence\n        type1_stats: descriptive type 1 statistics\n        type2_stats: descriptive type 2 statistics\n    \"\"\"\n\n    def __init__(self,\n        nsubjects: int = None,\n        nsamples: int = None,\n        params: dict = None,\n        params_extra: dict | None = None,\n        cfg: Configuration = None,\n        x_stim: list[float] | np.ndarray = None,\n        x_stim_category: list[int] | np.ndarray = None,\n        d_dec: list[int] | np.ndarray = None,\n        y_decval_latent: list[int] | np.ndarray = None,\n        y_decval: list[int] | np.ndarray = None,\n        z1_type1_evidence_latent: list[int] | np.ndarray = None,\n        z1_type1_evidence_base: list[int] | np.ndarray = None,\n        z1_type1_evidence: list[int] | np.ndarray = None,\n        c_conf_latent: list[int] | np.ndarray = None,\n        c_conf_base: list[int] | np.ndarray = None,\n        c_conf: list[int] | np.ndarray = None,\n        type1_stats: dict = None,\n        type2_stats: dict = None\n    ):\n\n        self.nsubjects = nsubjects\n        self.nsamples = nsamples\n        self.params = params\n        self.params_type1 = {k: v for k, v in self.params.items() if k.startswith('type1_')}\n        self.params_type2 = {k: v for k, v in self.params.items() if k.startswith('type2_')}\n        self.params_extra = params_extra\n        self.cfg = cfg\n        self.stimuli = x_stim\n        self.stimuli_category = x_stim_category\n        self.choices = d_dec\n        self.accuracy = x_stim_category == d_dec\n        self.y_decval_latent = y_decval_latent\n        self.y_decval = y_decval\n        self.z1_type1_evidence_latent = z1_type1_evidence_latent\n        self.z1_type1_evidence_base = z1_type1_evidence_base\n        self.z1_type1_evidence = z1_type1_evidence\n        self.confidence_latent = c_conf_latent\n        self.confidence_base = c_conf_base\n        self.confidence = c_conf\n        self.type1_stats = type1_stats\n        self.type2_stats = type2_stats\n\n    def squeeze(self):\n        # for var in ('x_stim', 'x_stim_category', 'd_dec', 'accuracy'):\n        #     if getattr(self, var) is not None:\n        #         setattr(self, var, getattr(self, var).squeeze())\n        for name, value in self.__dict__.items():\n            if isinstance(value, np.ndarray):\n                setattr(self, name, value.squeeze())\n        return self\n\n    def plot_psychometric(self, **kwargs):\n        import remeta\n        remeta.plot_psychometric(self, **kwargs)\n\n    def plot_stimulus_versus_confidence(self, **kwargs):\n        import remeta\n        remeta.plot_stimulus_versus_confidence(self, **kwargs)\n\n    def plot_confidence_histogram(self, **kwargs):\n        import remeta\n        remeta.plot_confidence_histogram(self, **kwargs)\n</code></pre>"}]}