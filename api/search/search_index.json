{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"ReMeta API","text":""},{"location":"configuration/","title":"remeta.configuration","text":""},{"location":"configuration/#remeta.configuration.Configuration","title":"Configuration  <code>dataclass</code>","text":"<p>Configuration for the ReMeta toolbox</p>"},{"location":"configuration/#remeta.configuration.Configuration--parameters","title":"Parameters","text":"<p>*** Basic definition of the model *** type2_fitting_type : str (default: 'criteria')     Whether confidence is fitted with discrete criteria or as a continuous variable.     Possible values: 'criteria', 'continuous' type2_noise_type : str (default: 'noisy-report)     Whether the model considers noise at readout or report.     Possible values: 'noisy_report', 'noisy_readout', 'noisy_temperature' type2_noise_dist : str         (default: noisy-report + criteria -&gt; 'truncated_norm_mode'                   noisy-report + continuous -&gt; 'truncated_norm_mode'                   noisy-readout + criteria -&gt; 'truncated_norm_mode'                   noisy-readout + continuous -&gt; 'truncated_norm_mode'                   noisy-temperature + criteria -&gt; 'lognorm_mode'                   noisy-temperature + continuous -&gt; 'truncated_norm_mode'         )     Metacognitive noise distribution.     Possible values:         noisy_report: 'beta_mean_std', 'beta_mode_std', 'beta_mode',                       'truncated_norm_mode_std', 'truncated_norm_mode' (default),                       'truncated_gumbel_mode_std', 'truncated_gumbel_mode',                       'truncated_lognorm_mode_std', 'truncated_lognorm', 'truncated_lognorm_mode',                       'truncated_lognorm_mean'         noisy_readout: 'lognorm_median_std', 'lognorm_mean', 'lognorm_mode', 'lognorm_mode_std', 'lognorm_mean_std',                        'gamma_mode_std', 'gamma_mean_std', 'gamma_mean', 'gamma_mode', 'gamma_mean_cv',                        'betaprime_mean_std',                        'truncated_norm_mode_std', 'truncated_norm_mode',                        'truncated_gumbel_mode_std', 'truncated_gumbel_mode'         noisy_temperature: same as noisy_readout</p> <p>*** Enable or disable specific parameters *** * Each setting can take the values 0, 1 or 2: *    0: Disable parameter. *    1: Enable parameter. *    2: Enable parameter and fit separate values for the negative and positive stimulus category         (works only for type 1 parameters!) enable_type1_param_noise : int (default: 1)     Fit separate type 1 noise parameters for both stimulus categories. enable_type1_param_noise_heteroscedastic : int (default: 0)     Fit an additional type 1 noise parameter for signal-dependent type 1 noise (the type of dependency is     defined via <code>type1_noise_signal_dependency</code>). enable_type1_param_nonlinear_encoding_gain : int (default: 0) enable_type1_param_nonlinear_encoding_transition : int (default: 0) enable_type1_param_thresh : int (default: 0)     Fit a type 1 threshold. enable_type1_param_bias : int (default: 1)     Fit a type 1 bias towards one of the stimulus categories. enable_type2_param_noise : int (default: 1)     Fit a metacognitive noise parameter enable_type2_param_evidence_bias_mult : int (default: 0)     Fit a multiplicative metacognitive bias loading on evidence. enable_type2_param_criteria : int (default: 0)     Fit confidence criteria.</p> <p>*** Additional options to specify the nature of type 2 fitting *** n_discrete_confidence_levels : int (default: 5)     Number of confidence criteria. Only applies in case of type2_fitting_type='criteria'.</p> <p>*** Define fitting characteristics of the parameters *** * The fitting of each parameter is characzerized as follows: *     1) An initial guess. *     2) Lower and upper bound. *     3) Grid range, i.e. list of values that are tested during the initial gridsearch search. * Sensible default values are provided for all parameters. To tweak those, one can either define an entire * ParameterSet, which is a container for a set of parameters, or each parameter individually. Note that the * parameters must be either defined as a Parameter instance or as List[Parameter] in case when separate values are * fitted for the positive and negative stimulus category/decision value). paramset_type1 : ParameterSet     Parameter set for the type 1 stage. paramset_type2 : ParameterSet     Parameter set for the type 2 stage. paramset : ParameterSet     Parameter set for both stages.</p> Union[Parameter, List[Parameter]]  (default: 1) <p>Parameter for type 1 noise.</p> <p>_type1_param_noise_heteroscedastic : Union[Parameter, List[Parameter]]  (default: 0)     Parameter for signal-dependent type 1 noise. _type1_param_nonlinear_encoding_gain : Union[Parameter, List[Parameter]]  (default: 0)     Gain parameter for nonlinear encoding (higher values -&gt; stronger nonlinearity). _type1_param_nonlinear_encoding_transition : Union[Parameter, List[Parameter]]  (default: 0)     Transition Parameter for nonlinear encoding (). type1_noise_signal_dependency: str (default: 'none')     Can be one of 'none', 'multiplicative', 'power', 'exponential' or 'logarithm'. _type1_param_thresh : Union[Parameter, List[Parameter]] (default: 0)     Parameter for the type 1 threshold. _type1_param_bias : Union[Parameter, List[Parameter]]  (default: 1)     Parameter for the type 1 bias. _type2_param_noise : Union[Parameter, List[Parameter]]  (default: 1)     Parameter for metacognitive noise. _type2_param_evidence_bias_mult : Union[Parameter, List[Parameter]]  (default: 0)     Parameter for a multiplicative metacognitive bias loading on evidence. type2_param_confidence_criteria : List[Parameter]  (default: 1)     List of parameter specifying the confidence criteria.</p> <p>*** Skip type 2 fitting *** skip_type2 : bool (default: False)     If True, ignore type 2 settings in the setup of the model configuration &amp; don't fit type 2 stage.</p> <p>*** Methodoligcal aspects of parameter fitting *** optim_type1_gridsearch : bool (default: False)     If True, perform initial (usually coarse) gridsearch search for type 1 fitting, based on the gridsearch defined     for a Parameter. optim_type1_fine_gridsearch : bool (default: False)     If True, perform an iteratively finer gridsearch search for each parameter (type 1). optim_type1_minimize_along_grid : bool (default: False)     If True, do sqlqp minimization for at each grid point (type 1). optim_type1_global_minimization : str (default: None)     Use one of 'shgo', 'dual_annealing' 'differential_evolution' to start likelihood minimization with     a global minimizer (type 1). optim_type1_scipy_solvers : str or Tuple/List (default: 'trust-constr')     Set scipy.optimize.minimize gradient method (type 1)     If provided as Tuple/List, test different gradient methods and take the best optim_type2_gridsearch : bool (default: True)     If True, perform initial (usually coarse) gridsearch search for type 2 fitting, based on the gridsearch defined     for a Parameter. optim_type2_fine_gridsearch : bool (default: False)     If True, perform an iteratively finer gridsearch search for each parameter (type 2). optim_type2_minimize_along_grid : bool (default: False)     If True, do sqlqp minimization for at each grid point (type 2). optim_type2_global_minimization : str (default: None)     Use one of 'shgo', 'dual_annealing' 'differential_evolution' to start likelihood minimization with     a global minimizer (type 2). optim_type2_scipy_solvers : str or Tuple/List (default: ('slsqp', 'Nelder-Mead'))     Set scipy.optimize.minimize gradient method (type 2)     If provided as Tuple/List, test different gradient methods and take the best optim_type2_slsqp_epsilon : float or Tuple/List (default: None)     Set parameter epsilon parameter for the SLSQP optimization method (type 2).     If provided as Tuple/List, test different eps parameters and take the best optim_multiproc : bool (default: False)     If True, use all optim_multiproc_cores cores for parameter estimation. If False, use a single core. optim_multiproc_cores : int (default: -1)     If multicore processing es enabled via optim_multiproc, use optim_multiproc_cores cores for parameter estimation     (-1 for all cores minus 1).</p> <p>*** Preprocessing *** normalize_stimuli_by_max : bool (default: True)     If True, normalize provided stimuli by their maximum value.</p> <p>*** Parameters for the type 2 likelihood computation *** min_type1_likelihood : float     Minimum probability used during the type 1 likelihood computation min_type2_likelihood : float     Minimum probability used during the type 2 likelihood computation type2_binsize : float     Integration bin size for the computation of the likelihood around empirical confidence values y_decval_range_nsds : int     Number of standard deviations around the mean considered for type 1 uncertainty. y_decval_range_nbins : int     Number of discrete decision values bins that are considered to represent type 1 uncertainty. resolution_noisy_temperature : float     Quintile resolution for the marginalization of type 1 noise in case of type2_noise_type 'noisy_temperature'. experimental_min_uniform_type2_likelihood : bool     Instead of using a minimum probability during the likelihood computation, use a maximum cumulative     likelihood based on a 'guessing' model experimental_wrap_type2_integration_window : bool (default: False)     Ensure constant window size for likelihood integration at the bounds.     Only applies in case of type2_fitting_type='continuous' and experimental_disable_type2_binsize=False experimental_include_incongruent_y_decval : bool (default: False)     Include incongruent decision values (i.e., sign(actual choice) != sign(decision value)) for the likelihood     computation experimental_disable_type2_binsize : bool (default: None)     Do not use an integegration window for likelihood computation.     Only applies in case of type2_fitting_type='continuous'</p> <p>*** Other *** true_params : Dict     Pass true (known) parameter values. This can be useful for testing to compare the likelihood of true and     fitted parameters. The likelihood of true parameters is returned (and printed). initilialize_fitting_at_true_params : bool (default: False)     Option to initialize the parameter fitting procedure at the true parameters; this can be helpful for testing. silence_configuration_warnings : bool (default: False)     If True, ignore warnings about user-specified settings. print_configuration : bool (default: True)     If True, print the configuration at instatiation of the ReMeta class.</p> Source code in <code>remeta/configuration.py</code> <pre><code>@reset_dataclass_on_init\n@dataclass\nclass Configuration(ReprMixin):\n    \"\"\"\n    Configuration for the ReMeta toolbox\n\n    Parameters\n    ----------\n    *** Basic definition of the model ***\n    type2_fitting_type : str (default: 'criteria')\n        Whether confidence is fitted with discrete *criteria* or as a continuous variable.\n        Possible values: 'criteria', 'continuous'\n    type2_noise_type : str (default: 'noisy-report)\n        Whether the model considers noise at readout or report.\n        Possible values: 'noisy_report', 'noisy_readout', 'noisy_temperature'\n    type2_noise_dist : str\n            (default: noisy-report + criteria -&gt; 'truncated_norm_mode'\n                      noisy-report + continuous -&gt; 'truncated_norm_mode'\n                      noisy-readout + criteria -&gt; 'truncated_norm_mode'\n                      noisy-readout + continuous -&gt; 'truncated_norm_mode'\n                      noisy-temperature + criteria -&gt; 'lognorm_mode'\n                      noisy-temperature + continuous -&gt; 'truncated_norm_mode'\n            )\n        Metacognitive noise distribution.\n        Possible values:\n            noisy_report: 'beta_mean_std', 'beta_mode_std', 'beta_mode',\n                          'truncated_norm_mode_std', 'truncated_norm_mode' (default),\n                          'truncated_gumbel_mode_std', 'truncated_gumbel_mode',\n                          'truncated_lognorm_mode_std', 'truncated_lognorm', 'truncated_lognorm_mode',\n                          'truncated_lognorm_mean'\n            noisy_readout: 'lognorm_median_std', 'lognorm_mean', 'lognorm_mode', 'lognorm_mode_std', 'lognorm_mean_std',\n                           'gamma_mode_std', 'gamma_mean_std', 'gamma_mean', 'gamma_mode', 'gamma_mean_cv',\n                           'betaprime_mean_std',\n                           'truncated_norm_mode_std', 'truncated_norm_mode',\n                           'truncated_gumbel_mode_std', 'truncated_gumbel_mode'\n            noisy_temperature: same as noisy_readout\n\n\n    *** Enable or disable specific parameters ***\n    * Each setting can take the values 0, 1 or 2:\n    *    0: Disable parameter.\n    *    1: Enable parameter.\n    *    2: Enable parameter and fit separate values for the negative and positive stimulus category\n            (works only for type 1 parameters!)\n    enable_type1_param_noise : int (default: 1)\n        Fit separate type 1 noise parameters for both stimulus categories.\n    enable_type1_param_noise_heteroscedastic : int (default: 0)\n        Fit an additional type 1 noise parameter for signal-dependent type 1 noise (the type of dependency is\n        defined via `type1_noise_signal_dependency`).\n    enable_type1_param_nonlinear_encoding_gain : int (default: 0)\n    enable_type1_param_nonlinear_encoding_transition : int (default: 0)\n    enable_type1_param_thresh : int (default: 0)\n        Fit a type 1 threshold.\n    enable_type1_param_bias : int (default: 1)\n        Fit a type 1 bias towards one of the stimulus categories.\n    enable_type2_param_noise : int (default: 1)\n        Fit a metacognitive noise parameter\n    enable_type2_param_evidence_bias_mult : int (default: 0)\n        Fit a multiplicative metacognitive bias loading on evidence.\n    enable_type2_param_criteria : int (default: 0)\n        Fit confidence criteria.\n\n    *** Additional options to specify the nature of type 2 fitting ***\n    n_discrete_confidence_levels : int (default: 5)\n        Number of confidence criteria. Only applies in case of type2_fitting_type='criteria'.\n\n    *** Define fitting characteristics of the parameters ***\n    * The fitting of each parameter is characzerized as follows:\n    *     1) An initial guess.\n    *     2) Lower and upper bound.\n    *     3) Grid range, i.e. list of values that are tested during the initial gridsearch search.\n    * Sensible default values are provided for all parameters. To tweak those, one can either define an entire\n    * ParameterSet, which is a container for a set of parameters, or each parameter individually. Note that the\n    * parameters must be either defined as a Parameter instance or as List[Parameter] in case when separate values are\n    * fitted for the positive and negative stimulus category/decision value).\n    paramset_type1 : ParameterSet\n        Parameter set for the type 1 stage.\n    paramset_type2 : ParameterSet\n        Parameter set for the type 2 stage.\n    paramset : ParameterSet\n        Parameter set for both stages.\n\n    _type1_param_noise : Union[Parameter, List[Parameter]]  (default: 1)\n        Parameter for type 1 noise.\n    _type1_param_noise_heteroscedastic : Union[Parameter, List[Parameter]]  (default: 0)\n        Parameter for signal-dependent type 1 noise.\n    _type1_param_nonlinear_encoding_gain : Union[Parameter, List[Parameter]]  (default: 0)\n        Gain parameter for nonlinear encoding (higher values -&gt; stronger nonlinearity).\n    _type1_param_nonlinear_encoding_transition : Union[Parameter, List[Parameter]]  (default: 0)\n        Transition Parameter for nonlinear encoding ().\n    type1_noise_signal_dependency: str (default: 'none')\n        Can be one of 'none', 'multiplicative', 'power', 'exponential' or 'logarithm'.\n    _type1_param_thresh : Union[Parameter, List[Parameter]] (default: 0)\n        Parameter for the type 1 threshold.\n    _type1_param_bias : Union[Parameter, List[Parameter]]  (default: 1)\n        Parameter for the type 1 bias.\n    _type2_param_noise : Union[Parameter, List[Parameter]]  (default: 1)\n        Parameter for metacognitive noise.\n    _type2_param_evidence_bias_mult : Union[Parameter, List[Parameter]]  (default: 0)\n        Parameter for a multiplicative metacognitive bias loading on evidence.\n    type2_param_confidence_criteria : List[Parameter]  (default: 1)\n        List of parameter specifying the confidence criteria.\n\n    *** Skip type 2 fitting ***\n    skip_type2 : bool (default: False)\n        If True, ignore type 2 settings in the setup of the model configuration &amp; don't fit type 2 stage.\n\n    *** Methodoligcal aspects of parameter fitting ***\n    optim_type1_gridsearch : bool (default: False)\n        If True, perform initial (usually coarse) gridsearch search for type 1 fitting, based on the gridsearch defined\n        for a Parameter.\n    optim_type1_fine_gridsearch : bool (default: False)\n        If True, perform an iteratively finer gridsearch search for each parameter (type 1).\n    optim_type1_minimize_along_grid : bool (default: False)\n        If True, do sqlqp minimization for at each grid point (type 1).\n    optim_type1_global_minimization : str (default: None)\n        Use one of 'shgo', 'dual_annealing' 'differential_evolution' to start likelihood minimization with\n        a global minimizer (type 1).\n    optim_type1_scipy_solvers : str or Tuple/List (default: 'trust-constr')\n        Set scipy.optimize.minimize gradient method (type 1)\n        If provided as Tuple/List, test different gradient methods and take the best\n    optim_type2_gridsearch : bool (default: True)\n        If True, perform initial (usually coarse) gridsearch search for type 2 fitting, based on the gridsearch defined\n        for a Parameter.\n    optim_type2_fine_gridsearch : bool (default: False)\n        If True, perform an iteratively finer gridsearch search for each parameter (type 2).\n    optim_type2_minimize_along_grid : bool (default: False)\n        If True, do sqlqp minimization for at each grid point (type 2).\n    optim_type2_global_minimization : str (default: None)\n        Use one of 'shgo', 'dual_annealing' 'differential_evolution' to start likelihood minimization with\n        a global minimizer (type 2).\n    optim_type2_scipy_solvers : str or Tuple/List (default: ('slsqp', 'Nelder-Mead'))\n        Set scipy.optimize.minimize gradient method (type 2)\n        If provided as Tuple/List, test different gradient methods and take the best\n    optim_type2_slsqp_epsilon : float or Tuple/List (default: None)\n        Set parameter epsilon parameter for the SLSQP optimization method (type 2).\n        If provided as Tuple/List, test different eps parameters and take the best\n    optim_multiproc : bool (default: False)\n        If True, use all optim_multiproc_cores cores for parameter estimation. If False, use a single core.\n    optim_multiproc_cores : int (default: -1)\n        If multicore processing es enabled via optim_multiproc, use optim_multiproc_cores cores for parameter estimation\n        (-1 for all cores minus 1).\n\n    *** Preprocessing ***\n    normalize_stimuli_by_max : bool (default: True)\n        If True, normalize provided stimuli by their maximum value.\n\n    *** Parameters for the type 2 likelihood computation ***\n    min_type1_likelihood : float\n        Minimum probability used during the type 1 likelihood computation\n    min_type2_likelihood : float\n        Minimum probability used during the type 2 likelihood computation\n    type2_binsize : float\n        Integration bin size for the computation of the likelihood around empirical confidence values\n    y_decval_range_nsds : int\n        Number of standard deviations around the mean considered for type 1 uncertainty.\n    y_decval_range_nbins : int\n        Number of discrete decision values bins that are considered to represent type 1 uncertainty.\n    resolution_noisy_temperature : float\n        Quintile resolution for the marginalization of type 1 noise in case of type2_noise_type 'noisy_temperature'.\n    experimental_min_uniform_type2_likelihood : bool\n        Instead of using a minimum probability during the likelihood computation, use a maximum cumulative\n        likelihood based on a 'guessing' model\n    experimental_wrap_type2_integration_window : bool (default: False)\n        Ensure constant window size for likelihood integration at the bounds.\n        Only applies in case of type2_fitting_type='continuous' and experimental_disable_type2_binsize=False\n    experimental_include_incongruent_y_decval : bool (default: False)\n        Include incongruent decision values (i.e., sign(actual choice) != sign(decision value)) for the likelihood\n        computation\n    experimental_disable_type2_binsize : bool (default: None)\n        Do not use an integegration window for likelihood computation.\n        Only applies in case of type2_fitting_type='continuous'\n\n\n    *** Other ***\n    true_params : Dict\n        Pass true (known) parameter values. This can be useful for testing to compare the likelihood of true and\n        fitted parameters. The likelihood of true parameters is returned (and printed).\n    initilialize_fitting_at_true_params : bool (default: False)\n        Option to initialize the parameter fitting procedure at the true parameters; this can be helpful for testing.\n    silence_configuration_warnings : bool (default: False)\n        If True, ignore warnings about user-specified settings.\n    print_configuration : bool (default: True)\n        If True, print the configuration at instatiation of the ReMeta class.\n    \"\"\"\n\n    type2_fitting_type: str = 'criteria'\n    type2_noise_type: str = 'noisy_report'\n    type2_noise_dist: str = None\n        # noisy-report + criteria -&gt; 'truncated_norm_mode'\n        # noisy-report + continuous -&gt; 'truncated_norm_mode'\n        # noisy-readout + criteria -&gt; 'truncated_norm_mode'\n        # noisy-readout + continuous -&gt; 'truncated_norm_mode'\n        # noisy-temperature + criteria -&gt; 'lognorm_mode'\n        # noisy-temperature + continuous -&gt; 'truncated_norm_mode'\n\n    enable_type1_param_noise: int = 1\n    enable_type1_param_thresh: int = 0\n    enable_type1_param_bias: int = 1\n    enable_type2_param_noise: int = 1\n    enable_type2_param_evidence_bias_mult: int = 0\n    enable_type2_param_criteria: int = 1\n    # Experimental:\n    enable_type1_param_noise_heteroscedastic: int = 0\n    enable_type1_param_nonlinear_encoding_gain: int = 0\n    enable_type1_param_nonlinear_encoding_transition: int = 0\n\n    n_discrete_confidence_levels: int = 5\n\n    paramset_type1: ParameterSet = None\n    paramset_type2: ParameterSet = None\n    paramset_all: ParameterSet = None\n\n    type1_param_noise_heteroscedastic: Parameter = Parameter(guess=0, bounds=(0, 10), grid_range=np.linspace(0, 1, 5))\n    type1_param_nonlinear_encoding_gain: Parameter = Parameter(guess=0, bounds=(-8/9, 10), grid_range=np.linspace(-0.5, 1, 5))\n    type1_param_nonlinear_encoding_transition: Parameter = Parameter(guess=1, bounds=(0.01, 10), grid_range=np.linspace(0.01, 2, 5))\n    type1_param_noise: Parameter = Parameter(guess=0.5, bounds=(0.001, 100), grid_range=np.linspace(0.1, 1, 8))\n    type1_param_thresh: Parameter = Parameter(guess=0, bounds=(0, 1), grid_range=np.linspace(0, 0.2, 5))\n    type1_param_bias: Parameter = Parameter(guess=0, bounds=(-1, 1), grid_range=np.linspace(-0.2, 0.2, 8))\n    type2_param_noise: Parameter = Parameter(guess=0.1, bounds=(0.05, 2), grid_range=np.linspace(0.1, 1, 8))\n    type2_param_evidence_bias_mult: Parameter = Parameter(guess=1, bounds=(0.5, 2), grid_range=np.linspace(0.5, 2, 8))\n    type2_param_criteria: Parameter = Parameter(bounds=(1e-8, 1))\n    type2_param_criteria_guesses: str | List[float] = 'equidistant'\n    type2_param_criteria_grid_ranges: str | List[np.ndarray] = 'equidistant'\n\n    type1_noise_signal_dependency: str = 'none'\n\n    skip_type2 = False\n\n    optim_type1_gridsearch: bool = False\n    optim_type1_fine_gridsearch: bool = False\n    optim_type1_minimize_along_grid: bool = False\n    optim_type1_global_minimization: str = None\n    _optim_type1_scipy_solvers_default = 'trust-constr'\n    optim_type1_scipy_solvers: str | List[str] | Tuple[str, ...] = 'trust-constr'\n    optim_type2_gridsearch: bool = True\n    optim_type2_fine_gridsearch: bool = False\n    optim_type2_minimize_along_grid: bool = False\n    optim_type2_global_minimization: str = None\n    optim_type2_scipy_solvers: str | List[str] | Tuple[str, ...] = ('slsqp', 'Nelder-Mead')\n    optim_type2_slsqp_epsilon: float = None\n    optim_multiproc: bool = False\n    optim_multiproc_cores: int = -1\n    _optim_multiproc_cores_effective: int = None\n\n    normalize_stimuli_by_max: bool = True\n    confidence_bounds_error: float = 0\n\n    min_type2_likelihood: float = 1e-10\n    min_type1_likelihood: float = 1e-10\n    type2_binsize: float = 0.01\n    y_decval_range_nsds: int = 5\n    y_decval_range_nbins: int = 101\n    resolution_noisy_temperature: float = 0.001\n\n    experimental_min_uniform_type2_likelihood: bool = False\n    experimental_wrap_type2_integration_window: bool = False\n    experimental_include_incongruent_y_decval: bool = False\n    experimental_disable_type2_binsize: bool = False\n\n    true_params: Dict = None\n    initilialize_fitting_at_true_params: bool = False\n    silence_configuration_warnings: bool = False\n    print_configuration: bool = False\n\n    type2_param_noise_min: float = 0.001\n\n    # setup_called = False\n\n    _type1_param_noise: Parameter | List[Parameter] = None\n    _type1_param_noise_heteroscedastic: Parameter | List[Parameter] = None\n    _type1_param_nonlinear_encoding_transition: Parameter | List[Parameter] = None\n    _type1_param_nonlinear_encoding_gain: Parameter | List[Parameter] = None\n    _type1_param_thresh: Parameter | List[Parameter] = None\n    _type1_param_bias: Parameter | List[Parameter] = None\n    _type2_param_noise: Parameter = None\n    _type2_param_evidence_bias_mult: Parameter = None\n    _type2_param_criteria: List[Parameter] = None\n\n    def setup(self, generative_mode=False):\n\n        if find_spec('multiprocessing_on_dill') is None:\n            warnings.warn(f'Multiprocessing on dill is not installed. Setting grid_multiproc is changed to False.')\n            self.optim_multiproc = False\n\n        if self.optim_multiproc:\n            from multiprocessing import cpu_count\n            self._optim_multiproc_cores_effective = max(1, (cpu_count() or 1) - 1) if self.optim_multiproc_cores == -1 \\\n                else self.optim_multiproc_cores\n\n        self._prepare_params_type1()\n        if self.skip_type2:\n            if self.optim_type2_slsqp_epsilon is None:\n                self.optim_type2_slsqp_epsilon = 1e-5\n        else:\n\n            if self.enable_type1_param_thresh and \\\n                (self.optim_type1_scipy_solvers == self._optim_type1_scipy_solvers_default):\n                self.optim_type1_scipy_solvers = ('trust-constr', 'Powell')\n\n\n            if self.type2_noise_dist is None:\n                if generative_mode:\n                    raise ValueError('In generative mode, you need to explicitly specify a type 2 noise distribution.')\n                else:\n                    if self.type2_noise_type == 'noisy_report':\n                        if (self.type2_fitting_type == 'criteria'):\n                            self.type2_noise_dist = 'truncated_norm_mode'\n                        else:\n                            self.type2_noise_dist = 'truncated_norm_mode'\n                    elif (self.type2_noise_type == 'noisy_readout'):\n                        if self.type2_fitting_type == 'criteria':\n                            self.type2_noise_dist = 'truncated_norm_mode'\n                        else:\n                            self.type2_noise_dist = 'truncated_norm_mode'\n                    elif self.type2_noise_type == 'noisy_temperature':\n                        if self.type2_fitting_type == 'criteria':\n                            self.type2_noise_dist = 'lognorm_mode'\n                        else:\n                            self.type2_noise_dist = 'truncated_norm_mode'\n\n            self._prepare_params_type2()\n            if self.optim_type2_slsqp_epsilon is None:\n                self.optim_type2_slsqp_epsilon = 1e-5\n\n            if self.type2_binsize is None:\n                self.type2_binsize = 0.01\n\n        self._prepare_params_all()\n\n        self._check_compatibility(generative_mode=generative_mode)\n\n        if self.print_configuration:\n            self.print()\n        # self.setup_called = True\n\n    def _check_compatibility(self, generative_mode=False):\n\n        if not self.silence_configuration_warnings:\n\n            if not self.skip_type2:\n                if not self.enable_type2_param_noise:\n                    warnings.warn(f'Setting enable_type2_param_noise=False was provided -&gt; type2_param_noise is set to its default value '\n                                  f'({self._type2_param_noise_default}). You may change this value via the configuration.')\n\n                if (self.type2_noise_type == 'noisy_temperature') and self.type2_param_noise.default_changed and \\\n                    (self.type2_param_noise.bounds[0] &lt; 1e-5):\n                    warnings.warn('You manually changed the lower bound of the type 2 noise parameter for a '\n                                  'noisy-temperature model to a very low value (&lt;1e-5). Be warned that this may result '\n                                  'in numerical instabilities that severely distort the likelihood computation.')\n\n                if not generative_mode:\n                    # If the configuration instance is used for generating data, we should not complain\n                    # about fitting issues.\n\n                    if self.enable_type2_param_criteria and self.enable_type2_param_evidence_bias_mult:\n                        warnings.warn(\n                            'enable_type2_param_criteria=True in combination with enable_type2_param_evidence_bias_mult=True\\n'\n                            'can lead to biased parameter inferences. Use with caution.')\n\n                    if (self.type2_fitting_type == 'continuous') and self.enable_type2_param_criteria:\n                        raise ValueError(\"Setting type2_fitting_type='continuous' conflicts with enable_type2_param_criteria=1.'\")\n\n                    if (self.type2_fitting_type == 'criteria') and not self.enable_type2_param_criteria:\n                        warnings.warn(\"You selected type2_fitting_type='criteria', but did not enable type 2 criteria\\n\"\n                                      \"(enable_type2_param_criteria=0). This works, but be mindful that the model\\n\"\n                                      \"will assume equispaced ideal Bayesian observer criteria (respecting \\n\"\n                                      \"the setting n_discrete_confidence_levels).\")\n\n    def _prepare_params_type1(self):\n        # if self.paramset_type1 is None:\n\n            param_names_type1 = []\n            params_type1 = ('noise', 'noise_heteroscedastic', 'nonlinear_encoding_gain', 'nonlinear_encoding_transition', 'thresh', 'bias')\n            for param in params_type1:\n                if getattr(self, f'enable_type1_param_{param}'):\n                    param_names_type1 += [f'type1_{param}']\n                    if getattr(self, f'_type1_param_{param}') is None:\n                        param_definition = getattr(self, f'type1_param_{param}')\n                        if getattr(self, f'enable_type1_param_{param}') == 2:\n                            setattr(self, f'_type1_param_{param}', [param_definition, param_definition])\n                        else:\n                            setattr(self, f'_type1_param_{param}', param_definition)\n                        if self.true_params is not None and self.initilialize_fitting_at_true_params and f'type1_{param}' in self.true_params:\n                            getattr(self, f'_type1_param_{param}').guess = self.true_params[f'type1_{param}']\n\n            parameters = {k: getattr(self, f\"_type1_param_{k.split('type1_')[1]}\") for k in param_names_type1}\n            self.paramset_type1 = ParameterSet(parameters, param_names_type1)\n\n    def _prepare_params_type2(self):\n\n        # if self.paramset_type2 is None:\n\n            if self.enable_type2_param_noise and self._type2_param_noise is None and not self.type2_param_noise.default_changed:\n\n                lb = 0.05\n                self.type2_param_noise.bounds = dict(\n                    noisy_report = dict(\n                        beta_mean_std=(lb, 0.5),\n                        beta_mode_std=(lb, 1 / np.sqrt(12)),\n                        truncated_norm_mode_std=(lb, 1 / np.sqrt(12)),\n                        truncated_gumbel_mode_std=(lb, 1 / np.sqrt(12)),\n                        truncated_lognorm_mode_std=(lb, 1 / np.sqrt(12)),\n                        beta_mode=(lb, 1),\n                        truncated_norm_mode=(lb, 1),\n                        truncated_gumbel_mode=(lb, 1),\n                        truncated_lognorm_mode=(lb, 4),\n                        truncated_lognorm_mean=(lb, 4),\n                        truncated_lognorm=(lb, 4)\n                    ),\n                    noisy_readout = dict(\n                        lognorm_mean=(lb, 1),\n                        lognorm_mode=(lb, 1),\n                        gamma_mean_std=(lb, 1),\n                        lognorm_mean_std=(lb, 2),\n                        lognorm_mode_std=(lb, 2),\n                        lognorm_median_std=(lb, 2),\n                        gamma_mean_cv=(lb, 2),\n                        gamma_mean=(lb, 2),\n                        gamma_mode_std=(lb, 2),\n                        gamma_mode=(lb, 2),\n                        betaprime_mean_std=(lb, 2),\n                        truncated_norm_mode_std=(lb, 2),\n                        truncated_norm_mode=(lb, 2),\n                        truncated_gumbel_mode_std=(lb, 2),\n                        truncated_gumbel_mode=(lb, 2)\n                    ),\n                    noisy_temperature = dict(\n                        lognorm_mean=(lb, 1),\n                        gamma_mean_std=(lb, 1),\n                        lognorm_mean_std=(lb, 2),\n                        lognorm_median_std=(lb, 2),\n                        gamma_mean_cv=(lb, 2),\n                        gamma_mean=(lb, 2),\n                        gamma_mode_std=(lb, 2),\n                        gamma_mode=(lb, 2),\n                        betaprime_mean_std=(lb, 2),\n                        truncated_norm_mode_std=(lb, 2),\n                        truncated_norm_mode=(lb, 2),\n                        truncated_gumbel_mode_std=(lb, 2),\n                        truncated_gumbel_mode=(lb, 2),\n                        lognorm_mode=(lb, 4),\n                        lognorm_mode_std=(lb, 10),\n                    )\n                )[self.type2_noise_type][self.type2_noise_dist]\n                self.type2_param_noise.grid_range = np.exp(np.linspace(np.log(self.type2_param_noise.bounds[0]),\n                                                                       np.log(self.type2_param_noise.bounds[1]), 10)[1:-1])\n\n            param_names_type2 = []\n            params_type2 = ('noise', 'evidence_bias_mult')\n            for param in params_type2:\n                if getattr(self, f'enable_type2_param_{param}'):\n                    param_names_type2 += [f'type2_{param}']\n                    if getattr(self, f'_type2_param_{param}') is None:\n                        param_definition = getattr(self, f'type2_param_{param}')\n                        setattr(self, f'_type2_param_{param}', param_definition.copy())\n                        if self.true_params is not None and self.initilialize_fitting_at_true_params and f'type2_{param}' in self.true_params:\n                            getattr(self, f'_type2_param_{param}').guess = self.true_params[f'type2_{param}']\n\n\n            if self.enable_type2_param_criteria:\n                param_names_type2 += [f'type2_criteria']\n                initialize_true = (self.initilialize_fitting_at_true_params and\n                                   self.true_params is not None and 'type2_criteria' in self.true_params)\n                setattr(self, f'_type2_param_criteria',\n                        [Parameter(\n                           guess=self.true_params['type2_criteria'][i] if initialize_true\n                                    else (1 / self.n_discrete_confidence_levels if self.type2_param_criteria_guesses == 'equidistant'\n                                          else self.type2_param_criteria_guesses[i]),\n                           bounds=self.type2_param_criteria.bounds,\n                           grid_range=np.linspace(0.05, 2 / self.n_discrete_confidence_levels, 4) if\n                                self.type2_param_criteria_grid_ranges == 'equidistant' else self.type2_param_criteria_grid_ranges[i]\n                        )\n                         for i in range(self.n_discrete_confidence_levels - 1)]\n                        )\n                if self.true_params is not None:\n                    if isinstance(self.true_params, dict):\n                        # if 'type2_criteria' not in self.true_params:\n                        #     raise ValueError('type2_criteria are missing from cfg.true_params')\n                        if 'type2_criteria' in self.true_params:\n                            self.true_params.update(\n                                type2_criteria_absolute=[np.sum(self.true_params['type2_criteria'][:i+1]) for i in range(len(self.true_params['type2_criteria']))],\n                                type2_criteria_bias=np.mean(self.true_params['type2_criteria'])*(len(self.true_params['type2_criteria'])+1)-1\n                            )\n                    elif isinstance(self.true_params, list):\n                        for s in range(len(self.true_params)):\n                            # if 'type2_criteria' not in self.true_params[s]:\n                            #     raise ValueError(f'type2_criteria are missing from cfg.true_params (subject {s})')\n                            if 'type2_criteria' in self.true_params[s]:\n                                self.true_params[s].update(\n                                    type2_criteria_absolute=[np.sum(self.true_params[s]['type2_criteria'][:i+1]) for i in range(len(self.true_params[s]['type2_criteria']))],\n                                    type2_criteria_bias=np.mean(self.true_params[s]['type2_criteria'])*(len(self.true_params[s]['type2_criteria'])+1)-1\n                                )\n\n            parameters = {k: getattr(self, f\"_type2_param_{k.split('type2_')[1]}\") for k in param_names_type2}\n            self.paramset_type2 = ParameterSet(parameters, param_names_type2)\n\n\n            self.check_type2_constraints()\n\n\n    def _prepare_params_all(self):\n\n        if self.skip_type2:\n            self.paramset = self.paramset_type1\n        else:\n            parameters_all = {**self.paramset_type1.parameters, **self.paramset_type2.parameters}\n            param_names_all = self.paramset_type1.param_names + self.paramset_type2.param_names\n            self.paramset = ParameterSet(parameters_all, param_names_all)\n            # for k, attr in self.paramset_type2.__dict__.items():\n            #     attr_old = getattr(self.paramset, k)\n            #     if isinstance(attr, list):\n            #         attr_new = attr_old + attr\n            #     elif isinstance(attr, dict):\n            #         attr_new = {**attr_old, **attr}\n            #     elif isinstance(attr, np.ndarray):\n            #         if attr.ndim == 1:\n            #             attr_new = np.hstack((attr_old, attr))\n            #         else:\n            #             attr_new = np.vstack((attr_old, attr))\n            #     elif isinstance(attr, int):\n            #         attr_new = attr_old + attr\n            #     elif attr is None:\n            #         if attr_old is None:\n            #             attr_new = None\n            #         else:\n            #             raise ValueError(f'Type 2 attribute is None, but type 1 attribute is not.')\n            #     else:\n            #         raise ValueError(f'Unexpected type {type(attr)}')\n            #     setattr(self.paramset, k, attr_new)\n\n\n\n\n    def print(self):\n        # print('***********************')\n        print(f'{self.__class__.__name__}')\n        for k, v in self.__dict__.items():\n            # if not self.skip_type2 or ('type2' not in k):\n            print('\\n'.join([f'\\t{k}: {v}']))\n        # print('***********************')\n\n    def __repr__(self):\n        txt = f'{self.__class__.__name__}\\n'\n        txt += '\\n'.join([f'\\t{k}: {v}' for k, v in self.__dict__.items()])\n        return txt\n\n    def check_type2_constraints(self):\n        pass\n</code></pre>"},{"location":"gendata/","title":"remeta.gendata","text":""},{"location":"plot/","title":"remeta.plot","text":""},{"location":"simulation/","title":"remeta.gendata","text":""}]}